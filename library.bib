Automatically generated by Mendeley Desktop 1.16.1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Song2013,
author = {Song, Qinbao and Ni, Jingjie and Wang, Guangtao},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = {jan},
number = {1},
pages = {1--14},
title = {{A fast clustering-based feature subset selection algorithm for high-dimensional data}},
volume = {25},
year = {2013}
}

@article{Maung2013,
author = {Maung, Crystal and Schweitzer, Haim},
journal = {Proceedings of the 26th International Conference on Neural Information Processing Systems},
pages = {1--9},
title = {{Pass-Efficient Unsupervised Feature Selection}},
year = {2013}
}

@article{Yang2013,
author = {Yang, Haiqin and Lyu, Michael R. and King, Irwin},
journal = {ACM Transactions on Knowledge Discovery from Data},
month = {jul},
number = {2},
pages = {1--27},
publisher = {ACM},
title = {{Efficient online learning for multitask feature selection}},
volume = {7},
year = {2013}
}

@article{Barbara2002,
  title={Requirements for clustering data streams},
  author={Barbar{\'a}, Daniel},
  journal={ACM sIGKDD Explorations Newsletter},
  volume={3},
  number={2},
  pages={23--27},
  year={2002},
  publisher={ACM}
}

@article{Eckley2011,
abstract = {Locally stationary process representations have recently been proposed and applied to both time series and image analysis applications. This article describes an implementation of the locally stationary two-dimensional wavelet process approach in R. This package permits construction of estimates of spatially localized spectra and localized autocovariance which can be used to characterize structure within images.},
author = {Eckley, I. A. and Nason, G. P.},
doi = {10.18637/jss.v043.i03},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {LS2W,Locally stationary,N,Wavelet,[Local autocovariance},
mendeley-tags = {Wavelet},
number = {3},
pages = {1--23},
title = {{LS2W}: Implementing the locally stationary 2d wavelet process approach in {R}},
volume = {43},
year = {2011}
}
@incollection{Studenmund2005b,
address = {London},
author = {Studenmund, A H},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {3},
edition = {Fifth},
editor = {Clinton, Denise},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {63--83},
publisher = {Pearson Education, Inc.},
title = {3. Learning to Use Regression Analysis.},
year = {2005}
}

@inproceedings{Guha2000,
 author = {Guha, S. and Mishra, N. and Motwani, R. and O'Callaghan, L.},
 title = {Clustering Data Streams},
 booktitle = {Proceedings of the 41st Annual Symposium on Foundations of Computer Science},
  year = {2000},
 pages = {359--},
 publisher = {IEEE Computer Society},
} 


@inproceedings{OCallaghan2002,
  title={Streaming-data algorithms for high-quality clustering},
  author={O'Callaghan, Liadan and Mishra, Nina and Meyerson, Adam and Guha, Sudipto and Motwani, Rajeev},
  booktitle={Data Engineering, 2002. Proceedings. 18th International Conference on},
  pages={685--694},
  year={2002},
  organization={IEEE}
}

@inproceedings{Asbagh2009,
  title={Feature-Based Data Stream Clustering},
  author={Asbagh, Mohsen Jafari and Abolhassani, Hassan},
  booktitle={Computer and Information Science, 2009. ICIS 2009. Eighth IEEE/ACIS International Conference on},
  pages={363--368},
  year={2009},
  organization={IEEE}
}

@inproceedings{bradley1998refining,
  title={Refining Initial Points for K-Means Clustering.},
  author={Bradley, Paul S and Fayyad, Usama M},
  booktitle={ICML},
  volume={98},
  pages={91--99},
  year={1998}
}

@article{kranen2011clustree,
  title={The ClusTree: indexing micro-clusters for anytime stream mining},
  author={Kranen, Philipp and Assent, Ira and Baldauf, Corinna and Seidl, Thomas},
  journal={Knowledge and information systems},
  volume={29},
  number={2},
  pages={249--272},
  year={2011},
  publisher={Springer}
}

@inproceedings{cao2006density,
  title={Density-based clustering over an evolving data stream with noise},
  author={Cao, Feng and Estert, Martin and Qian, Weining and Zhou, Aoying},
  booktitle={Proceedings of the 2006 SIAM international conference on data mining},
  pages={328--339},
  year={2006},
  organization={SIAM}
}

@inproceedings{chen2007density,
  title={Density-based clustering for real-time stream data},
  author={Chen, Yixin and Tu, Li},
  booktitle={Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={133--142},
  year={2007},
  organization={ACM}
}

@article{Warnell2012,
author = {Warnell, Garrett},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Warnell - 2012 - Adaptive rate compressive sensing for background subtraction.pdf:pdf},
journal = {Acoustics, Speech and {\ldots}},
title = {Adaptive rate compressive sensing for background subtraction},
url = {http://ieeexplore.ieee.org/xpls/abs{\{}{\_}{\}}all.jsp?arnumber=6288170 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6288170},
year = {2012}
}
@article{Jiang2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1302.1942v1},
author = {Jiang, H and Deng, W and Shen, Z},
eprint = {arXiv:1302.1942v1},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang, Deng, Shen - 2013 - Surveillance video processing using compressive sensing.pdf:pdf},
journal = {arXiv preprint arXiv:1302.1942},
keywords = {alternating direction method,and phrases,background subtraction,compressive sensing,low-,rank and sparse decomposition,surveillance video,tight frames},
number = {0},
title = {Surveillance video processing using compressive sensing},
url = {http://arxiv.org/abs/1302.1942},
volume = {X},
year = {2013}
}
@article{Schwartz2011,
abstract = {Patterns of interaction in any social system are accompanied by counter-patterns of withdrawal, one highly institutionalized (but unexplored) mode of which is privacy. There exists a threshold beyond which social contact becomes irritating for all parties; therefore, some provision for removing oneself from interaction and observation must be built into every establishment. Such provisions subserve the action patterns for which they provide intermission. Privacy, which is bought and sold in social establishments, reflects and affirms status divisions, and permits "localized" deviation which is invisible to the group as a whole. Privacy thereby unsulates against dysfunctional knowledge. Rules governing entrance into and exit from privacy are most clearly articulated on the level of the establishment and are reflected in its physical structure and in proprieties concerning the uses of space, doors, windows, drawers, etc. The report ends with a discussion of identity and its relation to the freedoms of engagement and disengagement.},
author = {Schwartz, Barry},
journal = {The American Journal of Sociology},
keywords = {Privacy},
mendeley-tags = {Privacy},
number = {6},
pages = {741--752},
title = {The Social Psychology of Privacy},
url = {http://www.jstor.org/stable/2775779},
volume = {73},
year = {2011}
}
@article{Bingham2001,
abstract = {Random projections have recently emerged as a powerful method for dimensionality reduction. Theoretical results indicate that the method preserves distances quite nicely; however, empirical results are sparse. We present experimental results on using random projection as a dimensionality reduction tool in a number of cases, where the high dimensionality of the data would otherwise lead to burdensome computations. Our application areas are the processing of both noisy and noiseless images, and information retrieval in text documents. We show that projecting the data onto a random lower-dimensional subspace yields results comparable to conventional dimensionality reduction methods such as principal component analysis: the similarity of data vectors is preserved well under random projection. However, using random projections is computationally signiﬁcantly less expensive than using, e.g., principal component analysis. We also show experimentally that using a sparse random matrix gives additional computational savings in random projection.},
author = {Bingham, Ella and Mannila, Heikki},
doi = {10.1145/502512.502546},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bingham, Mannila - 2001 - Random projection in dimensionality reduction Applications to image and text data.pdf:pdf},
isbn = {158113391X},
journal = {Foundations},
keywords = {dimensionality reduction,high dimensional data,image data,random projection,text document data},
pages = {245--250},
title = {Random projection in dimensionality reduction : Applications to image and text data},
url = {http://portal.acm.org/citation.cfm?id=502546},
volume = {pages},
year = {2001}
}
@inproceedings{Kong2011,
abstract = {Spectral clustering is an emerging research topic that has numerous applications, such as data dimension reduction and image segmentation. In spectral clustering, as new data points are added continuously, dynamic data sets are processed in an on-line way to avoid costly re-computation. In this paper, we propose a new representative measure to compress the original data sets and maintain a set of representative points by continuously updating Eigen-system with the incidence vector. According to these extracted points we generate instant cluster labels as new data points arrive. Our method is effective and able to process large data sets due to its low time complexity. Experimental results over various real evolutional data sets show that our method provides fast and relatively accurate results.},
author = {Kong, Tengteng and Tian, Ye and Shen, Hong},
booktitle = {International Conference on Parallel and Distributed Computing, Applications and Technologies},
doi = {10.1109/PDCAT.2011.4},
isbn = {978-1-4577-1807-6},
keywords = {Accuracy,Algorithm design and analysis,Clustering algorithms,Eigen-Gap,Eigenvalues and eigenfunctions,Incremental,Laplace equations,Representative Point,Sparse matrices,Spectral Clustering,Vectors,cluster labels,computational complexity,data compression,data dimension reduction,data reduction,data structures,dynamic data sets compression,eigen system,fast incremental spectral clustering,image segmentation,incidence vector,large data sets compression,pattern clustering,real evolutional data sets,set theory,spectral analysis,time complexity},
mendeley-tags = {Spectral Clustering},
month = {oct},
pages = {1--5},
shorttitle = {Parallel and Distributed Computing, Applications a},
title = {A Fast Incremental Spectral Clustering for Large Data Sets},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6118531},
year = {2011}
}
@article{Neal1999,
abstract = {The EM algorithm performs maximum likelihood estimation for data in which some variables are unobserved. We present a function that resembles negative free energy and show that the M step maximizes this function with respect to the model parameters and the E step maximizes it with respect to the distribution over the unobserved variables. From this perspective, it is easy to justify an incremental variant of the EM algorithm in which the distribution for only one of the unobserved variables is recalculated in each E step. This variant is shown empirically to give faster convergence in a mixture estimation problem. A variant of the algorithm that exploits sparse conditional distributions is also described, and a wide range of other variant algorithms are also seen to be possible.},
author = {Neal, Radford M. and Hinton, Geoffrey E.},
doi = {10.1007/978-94-011-5014-9_12},
isbn = {0262600323},
issn = {978-1-932432-41-1},
journal = {Learning in Graphical Models},
month = {feb},
pages = {355--368},
publisher = {MIT Press},
title = {A View of the EM Algorithm that Justifies Incremental, Sparse, and Other Variants},
url = {http://dl.acm.org/citation.cfm?id=308574.308679},
year = {1998}
}
@article{Candamo2010,
author = {Candamo, Joshua and Shreve, Matthew and Goldgof, Dmitry B and Sapper, Deborah B and Kasturi, Rangachar},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Candamo et al. - 2010 - Understanding Transit Scenes A Survey on Human Behavior-Recognition Algorithms.pdf:pdf},
number = {1},
pages = {206--224},
title = {Understanding Transit Scenes : A Survey on Human Behavior-Recognition Algorithms},
volume = {11},
year = {2010}
}
@article{King2000,
abstract = {Social scientists rarely take full advantage of the information available in their statistical results. As a consequence, they miss opportunities to present quantities that are of greatest substantive interest for their research and express the appropriate degree of certainty about these quantities. In this article, we offer an approach, built on the technique of statistical simulation, to extract the currently overlooked information from any statistical method and to interpret and present it in a reader-friendly manner. Using this technique requires some expertise, which we try to provide herein, but its application should make the results of quantitative articles more informative and transparent. To illustrate our recommendations, we replicate the results of several published works, showing in each case how the authors' own conclusions can be expressed more sharply and informatively, and, without changing any data or statistical assumptions, how our approach reveals important new information about the research questions at hand. We also offer very easy-to-use software that implements our suggestions.},
author = {King, Gary (Harvard University) and Tomz, Michael (Harvard University) and Wittenberg, Jason (Harvard University)},
journal = {American Journal of Political Science},
number = {2},
pages = {341--355},
title = {Making the Most of Statistical Analyses: Improving Interpretation and Presentation},
volume = {44},
year = {2000}
}
@article{Fawcett2006,
author = {Fawcett, Tom},
doi = {10.1016/j.patrec.2005.10.010},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Classifier evaluation,Evaluation metrics,ROC analysis},
month = {jun},
number = {8},
pages = {861--874},
publisher = {Elsevier Science Inc.},
title = {An introduction to ROC analysis},
url = {http://dl.acm.org/citation.cfm?id=1159473.1159475},
volume = {27},
year = {2006}
}
@article{Chen2006a,
author = {Chen, Bo and Gao, Bin and Liu, Tie-Yan and Chen, Yu-Fu and Ma, Wei-Ying},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2006 - Fast spectral clustering of data using sequential matrix compression.pdf:pdf},
journal = {European Conference on Machine Learning},
pages = {590--597},
title = {Fast spectral clustering of data using sequential matrix compression},
year = {2006}
}
@article{Droogenbroeck2012,
author = {Droogenbroeck, M Van and Paquot, O},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Droogenbroeck, Paquot - 2012 - Background subtraction experiments and improvements for vibe.pdf:pdf},
journal = {Computer Vision and {\{}{\ldots}{\}}},
number = {June},
title = {Background subtraction: experiments and improvements for vibe},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6238924 http://ieeexplore.ieee.org/xpls/abs{\{}{\_}{\}}all.jsp?arnumber=6238924},
year = {2012}
}
@article{Rudin1992,
author = {Rudin, LI I and Osher, S and Fatemi, E},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rudin, Osher, Fatemi - 1992 - Nonlinear total variation based noise removal algorithms.pdf:pdf},
journal = {Physica D: Nonlinear Phenomena},
pages = {259--268},
title = {Nonlinear total variation based noise removal algorithms},
url = {http://www.sciencedirect.com/science/article/pii/016727899290242F},
volume = {60},
year = {1992}
}
@article{Rosenberg2007,
abstract = {We present V-measure, an external entropy- based cluster evaluation measure. V- measure provides an elegant solution to many problems that affect previously de- fined cluster evaluation measures includ- ing 1) dependence on clustering algorithm or data set, 2) the problem of matching, where the clustering of only a portion of data points are evaluated and 3) accurate evalu- ation and combination of two desirable as- pects of clustering, homogeneity and com- pleteness. We compare V-measure to a num- ber of popular cluster evaluation measures and demonstrate that it satisfies several de- sirable properties of clustering solutions, us- ing simulated clustering results. Finally, we use V-measure to evaluate two clustering tasks: document clustering and pitch accent type clustering.},
author = {Rosenberg, Andrew and Hirschberg, Julia},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosenberg, Hirschberg - 2007 - V-measure A conditional entropy-based external cluster evaluation measure.pdf:pdf},
journal = {Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
keywords = {Computer science,Information technology},
pages = {410--420},
title = {V-measure: A conditional entropy-based external cluster evaluation measure},
url = {http://acl.ldc.upenn.edu/D/D07/D07-1043.pdf},
year = {2007}
}

@article{Candes2006a,
abstract = {This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f∈CN and a randomly chosen set of frequencies $\Omega$. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set $\Omega$? A typical result of this paper is as follows. Suppose that f is a superposition of |T| spikes f(t)=$\sigma$$\tau$∈Tf($\tau$)$\delta$(t-$\tau$) obeying |T|≤CM{\textperiodcentered}(log N)-1 {\textperiodcentered} |$\Omega$| for some constant CM{\textgreater}0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N-M), f can be reconstructed exactly as the solution to the ℓ1 minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for CM which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of |T| spikes may be recovered by convex programming from almost every set of frequencies of size O(|T|{\textperiodcentered}logN). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N-M) would in general require a number of frequency samples at least proportional to |T|{\textperiodcentered}logN. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.},
author = {Cand{\`{e}}s, Emmanuel and Romberg, J. and Tao, T.},
doi = {10.1109/TIT.2005.862083},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
keywords = {Biomedical imaging,Convex optimization,Fourier analysis,Fourier coefficient,Frequency,Image reconstruction,Linear programming,Mathematics,Robustness,Sampling methods,Signal processing,Signal reconstruction,Uncertainty,convex programming,discrete-time signal,duality in optimization,free probability,image sampling,incomplete frequency information,indeterminancy,minimisation,minimization problem,nonlinear sampling theorem,piececise constant object,piecewise constant techniques,probability,probability value,random matrices,robust uncertainty principle,signal sampling,sparse matrices,sparse random matrix,sparsity,total-variation minimization,trigonometric expansion,trigonometric expansions,uncertainty principle},
month = {feb},
number = {2},
pages = {489--509},
shorttitle = {Information Theory, IEEE Transactions on},
title = {Robust uncertainty principles: {Exact} signal reconstruction from highly incomplete frequency information},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1580791},
volume = {52},
year = {2006}
}
@article{Bouwmans2011,
abstract = {Background modeling is often used in the context of moving objects detection from static cameras. Numerous methods have been developed over the recent years and the most used are the statistical ones. The purpose of this chapter is to provide a recent survey of these different statistical methods. For this, we have classified them in term of generation following the years of publication and the statistical tools used. We then focus on the first generation methods: Single Gaussian, Mixture of Gaussians, Kernel Density Estimation and Subspace Learning using PCA. These original methods are reminded and then we have classified their different improvements in term of strategies. After analyzing the strategies and identifying their limitations, we conclude with several promising directions for future research.},
author = {Bouwmans, Thierry},
doi = {10.2174/2213275911104030147},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouwmans - 2011 - Recent advanced statistical background modeling for foreground detection A systematic survey.pdf:pdf},
issn = {22132759},
journal = {Recent Patents on Computer Science},
keywords = {background modeling,kernel density estimation,mixture of gaussians,single gaussian,subspace learning},
number = {3},
pages = {147--176},
title = {Recent Advanced Statistical Background Modeling for Foreground Detection - A Systematic Survey},
url = {http://www.researchgate.net/publication/215737713{\_}Recent{\_}Advanced{\_}Statistical{\_}Background{\_}Modeling{\_}for{\_}Foreground{\_}Detection{\_}A{\_}Systematic{\_}Survey/file/d922b4f6984eedda06.pdf http://www.researchgate.net/publication/215737713{\{}{\_}{\}}Recent{\{}{\_}{\}}Advanced{\{}{\_}{\}}Statistical{\{}}},
volume = {4},
year = {2011}
}
@article{Mayo2009,
author = {Mayo, Zane and Tapamo, JR R},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mayo, Tapamo - 2009 - Background subtraction survey for highway surveillance.pdf:pdf},
journal = {Proc. of the Annual Symposium of the Pattern {\{}{\ldots}{\}}},
title = {Background subtraction survey for highway surveillance},
url = {http://www.prasa.org/proceedings/2009/prasa09-14.pdf},
year = {2009}
}
@book{Rumsey2009,
address = {Indianapolis},
author = {Rumsey, Deborah},
booktitle = {Director},
keywords = {Statistics},
mendeley-tags = {Statistics},
pages = {1--413},
publisher = {For Dummies},
title = {Statistics II for Dummies},
url = {http://books.google.com/books?hl=en{\{}{\&}{\}}lr={\{}{\&}{\}}id={\{}{\_}{\}}UzkbN{\{}{\_}{\}}QRuUC{\{}{\&}{\}}oi=fnd{\{}{\&}{\}}pg=PA1{\{}{\&}{\}}dq=Statistics+II+for+Dummies{\{}{\&}{\}}ots=0CFwi7vheg{\{}{\&}{\}}sig=a1ee7gEns9jmxZ{\{}{\_}{\}}Mg5qfkDyZ6mM},
year = {2009}
}
@misc{Qiu2012,
author = {Qiu, Chenlu and Vaswani, Namrata},
booktitle = {( submitted to CVPR 2012 )},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qiu, Vaswani - 2012 - Automated Recursive Projected CS ( ReProCS ) for Real-time Video Layering.pdf:pdf},
pages = {1--8},
title = {Automated Recursive Projected CS ( ReProCS ) for Real-time Video Layering},
year = {2012}
}
@article{Cakir2013,
abstract = {The compressive sensing (CS) framework states that a signal that has a sparse representation in a known basis may be reconstructed from samples obtained at a sub-Nyquist sampling rate. The Fourier domain is widely used in CS applications due to its inherent properties. Sparse signal recovery applications using a small number of Fourier transform coefficients have made solutions to large-scale data recovery problems, including image recovery problems, more practical. The sparse reconstruction of 2D images is performed using the sampling patterns generated by taking the general frequency characteristics of the images into account. In this work, instead of forming a general sampling pattern for infrared (IR) images, a special sampling pattern is obtained by gathering a database to extract the frequency characteristics of IR sea-surveillance images. Experimental results show that the proposed sampling pattern provides better sparse recovery results compared to the widely used patterns proposed in the literature. It is also shown that, together with a certain image dataset, the sampling pattern generated by the proposed scheme can be generalized for various image sparse recovery applications.},
author = {Cakir, Serdar and Uzeler, Hande and Ayta{\c{c}}, Tayfun},
issn = {1539-4522},
journal = {Applied optics},
month = {oct},
number = {28},
pages = {6858--67},
pmid = {24085199},
title = {Sampling strategy for the sparse recovery of infrared images.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24085199},
volume = {52},
year = {2013}
}
@article{Candes2005b,
author = {Cand{\`{e}}s, Emmanuel and Romberg, Justin},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cand{\`{e}}s, Romberg - 2005 - Recovery of Sparse Signals via Convex Programming Seven problems.pdf:pdf},
pages = {1--19},
title = {Recovery of Sparse Signals via Convex Programming Seven problems},
year = {2005}
}
@misc{Maidstone2016,
abstract = {There is an increasing need for algorithms that can accurately detect changepoints in long time-series, or equivalent, data. Many common approaches to detecting changepoints, for example based on penalised likelihood or minimum description length, can be formulated in terms of minimising a cost over segmentations. Dynamic programming methods exist to solve this minimisation problem exactly, but these tend to scale at least quadratically in the length of the time-series. Algorithms, such as Binary Segmentation, exist that have a computational cost that is close to linear in the length of the time-series, but these are not guaranteed to find the optimal segmentation. Recently pruning ideas have been suggested that can speed up the dynamic programming algorithms, whilst still being guaranteed to find true minimum of the cost function. Here we extend these pruning methods, and introduce two new algorithms for segmenting data, FPOP and SNIP. Empirical results show that FPOP is substantially faster than existing dynamic programming methods, and unlike the existing methods its computational efficiency is robust to the number of changepoints in the data. We evaluate the method at detecting Copy Number Variations and observe that FPOP has a computational cost that is competitive with that of Binary Segmentation.},
archivePrefix = {arXiv},
arxivId = {1409.1842},
author = {Maidstone, Robert and Hocking, Toby and Rigaill, Guillem and Fearnhead, Paul},
booktitle = {Statistics and Computing},
doi = {10.1007/s11222-016-9636-3},
eprint = {1409.1842},
issn = {15731375},
keywords = {Breakpoints,Dynamic Programming,FPOP,Optimal Partitioning,PELT,SNIP,Segment Neighbourhood,pDPA},
month = {sep},
pages = {1--15},
title = {On optimal multiple changepoint algorithms for large data},
url = {http://arxiv.org/abs/1409.1842},
year = {2016}
}
@inproceedings{Valgren2008,
abstract = {The problem of appearance-based mapping and navigation in outdoor environments is far from trivial. In this paper, an appearance-based topological map, covering a large, mixed indoor and outdoor environment, is built incrementally by using panoramic images. The map is based on image similarity, so that the resulting segmentation of the world corresponds closely to the human concept of a place. Using high-resolution images and the epipolar constraint, the resulting map is shown to be very suitable for localization, even when the environment has undergone seasonal changes.},
author = {Valgren, Christoffer and Lilienthal, Achim},
booktitle = {IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2008.4543477},
isbn = {978-1-4244-1646-2},
issn = {1050-4729},
keywords = {Clustering algorithms,Detectors,Humans,Image matching,Image segmentation,Navigation,Partitioning algorithms,Robotics and automation,Robustness,Spectral Clustering,USA Councils,appearance-based localization,appearance-based mapping,high-resolution images,image segmentation,image similarity,incremental spectral clustering,mobile robots,panoramic images,path planning,robot vision},
mendeley-tags = {Spectral Clustering},
month = {may},
pages = {1856--1861},
shorttitle = {Robotics and Automation, 2008. ICRA 2008. IEEE Int},
title = {Incremental spectral clustering and seasons: Appearance-based localization in outdoor environments},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4543477},
year = {2008}
}
@article{Shannon1949,
abstract = {A method is developed for representing any communication system geometrically. Messages and the corresponding signals are points in two "function spaces," and the modulation process is a mapping of one space into the other. Using this representation, a number of results in communication theory are deduced concerning expansion and compression of bandwidth and the threshold effect. Formulas are found for the maxmum rate of transmission of binary digits over a system when the signal is perturbed by various types of noise. Some of the properties of "ideal" systems which transmit at this maxmum rate are discussed. The equivalent number of binary digits per second for certain information sources is calculated.},
author = {Shannon, C.E.},
journal = {Proceedings of the IRE},
keywords = {Bandwidth,Circuits,Communication systems,Electron tubes,Frequency measurement,Gain measurement,Klystrons,Shape,Telephony,Voltage},
month = {jan},
number = {1},
pages = {10--21},
shorttitle = {Proceedings of the IRE},
title = {Communication in the Presence of Noise},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1697831},
volume = {37},
year = {1949}
}
@article{McFarlane1995,
author = {McFarlane, N. J. B. and Schofield, C. P.},
doi = {10.1007/BF01215814},
issn = {0932-8092},
journal = {Machine Vision and Applications},
month = {may},
number = {3},
pages = {187--193},
title = {Segmentation and tracking of piglets in images},
url = {http://link.springer.com/10.1007/BF01215814},
volume = {8},
year = {1995}
}
@article{Stankovi,
author = {Stankovi, Vladimir and Stankovi, Lina and Cheng, Samuel},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stankovi, Stankovi, Cheng - Unknown - Compressive video sampling.pdf:pdf},
pages = {2--6},
title = {Compressive video sampling}
}
@book{Buhlmann2016,
abstract = {Handbook of Big Data provides a state-of-the-art overview of the analysis of large-scale datasets. Featuring contributions from well-known experts in statistics and computer science, this handbook presents a carefully curated collection of techniques from both industry and academia. Thus, the text instills a working understanding of key statistical and computing ideas that can be readily applied in research and practice. Offering balanced coverage of methodology, theory, and applications, this handbook: Describes modern, scalable approaches for analyzing increasingly large datasets Defines the underlying concepts of the available analytical tools and techniques Details intercommunity advances in computational statistics and machine learning Handbook of Big Data also identifies areas in need of further development, encouraging greater communication and collaboration between researchers in big data sub-specialties such as genomics, computational biology, and finance.},
author = {Buhlmann, Peter and Drineas, Petros and Kane, Michael and van der Laan, Mark},
isbn = {9781482249088},
publisher = {Springer},
title = {Handbook of Big Data},
year = {2016}
}
@article{Luxburg2007,
abstract = {In recent years, spectral clustering has become one of the most popular modern clustering algorithms. It is simple to implement, can be solved efficiently by standard linear algebra software, and very often outperforms traditional clustering algorithms such as the k-means algorithm. On the first glance spectral clustering appears slightly mysterious, and it is not obvious to see why it works at all and what it really does. The goal of this tutorial is to give some intuition on those questions. We describe different graph Laplacians and their basic properties, present the most common spectral clustering algorithms, and derive those algorithms from scratch by several different approaches. Advantages and disadvantages of the different spectral clustering algorithms are discussed.},
archivePrefix = {arXiv},
arxivId = {0711.0189},
author = {{Von Luxburg}, Ulrike},
doi = {10.1007/s11222-007-9033-z},
eprint = {0711.0189},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Von Luxburg - 2007 - A tutorial on spectral clustering.pdf:pdf},
isbn = {0960-3174},
issn = {09603174},
journal = {Statistics and Computing},
keywords = {Graph Laplacian,Spectral Clustering,Spectral clustering},
mendeley-tags = {Spectral Clustering},
number = {4},
pages = {395--416},
pmid = {19784854},
title = {A tutorial on spectral clustering},
url = {http://www.springerlink.com/index/10.1007/s11222-007-9033-z},
volume = {17},
year = {2007}
}
@article{Chen2011,
abstract = {Spectral clustering is one of the most popular cluster- ing approaches. Despite its good performance, it is lim- ited in its applicability to large-scale problems due to its high computational complexity. Recently, many ap- proaches have been proposed to accelerate the spectral clustering. Unfortunately, these methods usually sacri- fice quite a lot information of the original data, thus result in a degradation of performance. In this paper, we propose a novel approach, called Landmark-based Spectral Clustering (LSC), for large scale clustering problems. Specifically, we select p (? n) representa- tive data points as the landmarks and represent the orig- inal data points as the linear combinations of these land- marks. The spectral embedding of the data can then be efficiently computed with the landmark-based represen- tation. The proposed algorithm scales linearly with the problem size. Extensive experiments showthe effective- ness and efficiency of our approach comparing to the state-of-the-art methods.},
author = {Chen, Xinlei and Cai, Deng},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Cai - 2011 - Large Scale Spectral Clustering with Landmark-Based Representation.pdf:pdf},
isbn = {9781577355083},
journal = {Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence},
keywords = {Machine Learning},
pages = {313--318},
title = {Large Scale Spectral Clustering with Landmark-Based Representation},
year = {2011}
}
@article{Davenport2011,
author = {Davenport, M A and Duarte, M F and Eldar, Y C},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Davenport, Duarte, Eldar - 2011 - Introduction to compressed sensing.pdf:pdf},
journal = {Preprint},
keywords = {Compressive Senseing},
pages = {1--68},
title = {Introduction to compressed sensing},
url = {http://www.dfg-spp1324.de/download/preprints/preprint093.pdf},
year = {2011}
}
@techreport{Deloitte2012,
author = {Deloitte},
institution = {Deloitte},
number = {November},
title = {Measuring the Economic Benefits of Mathematical Science Research in the UK},
year = {2012}
}
@article{Wang2009,
author = {Wang, Eric and Silva, Jorge and Carin, Lawrence},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Silva, Carin - 2009 - COMPRESSIVE PARTICLE FILTERING FOR TARGET TRACKING.pdf:pdf},
isbn = {9781424427109},
pages = {233--236},
title = {COMPRESSIVE PARTICLE FILTERING FOR TARGET TRACKING},
year = {2009}
}
@inproceedings{Nadungodage2011,
author = {Nadungodage, Chandima Hewa and Xia, Yuni and Li, Fang and Lee, Jaehwan John and Ge, Jiaqi},
booktitle = {International Conference on Database Systems for Advanced Applications.},
doi = {10.1007/978-3-642-20152-3_39},
keywords = {data streams,linear regression,sliding windows},
pages = {458--461},
publisher = {Springer, Berlin, Heidelberg},
title = {StreamFitter : A Real Time Linear Regression Analysis System for Continuous Data Streams 2 Linear Regression Analysis on Data Streams},
url = {http://link.springer.com/10.1007/978-3-642-20152-3{\_}39},
year = {2011}
}
@book{Chen2012,
author = {Chen, Jie and Gupta, Arjun K.},
doi = {10.1007/978-0-8176-4801-5},
isbn = {978-0-8176-4800-8},
publisher = {Springer Science \& Business Media},
title = {Parametric Statistical Change Point Analysis},
url = {http://link.springer.com/10.1007/978-0-8176-4801-5},
year = {2012}
}
@book{Huff1954,
address = {New York},
author = {Huff, Darrell},
isbn = {0393052648},
keywords = {Statistics,Statistics as Topic},
pages = {1--141},
publisher = {W.W. Norton {\{}{\&}{\}} Company, Inc.},
title = {How to Lie with Statistics},
year = {1954}
}
@article{Kannan2004,
abstract = {We motivate and develop a natural bicriteria measure for assessing the quality of a clustering that avoids the drawbacks of existing measures. A simple recursive heuristic is shown to have poly-logarithmic worst-case guarantees under the new measure. The main result of the article is the analysis of a popular spectral algorithm. One variant of spectral clustering turns out to have effective worst-case guarantees; another finds a "good" clustering, if one exists.},
author = {Kannan, Ravi and Vempala, Santosh and Vetta, Adrian},
doi = {10.1145/990308.990313},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kannan, Vempala, Vetta - 2004 - On Clusterings Good, Bad and Spectral.pdf:pdf},
isbn = {0-7695-0850-2},
issn = {00045411},
journal = {Journal of the ACM},
keywords = {Algorithms,Analysis of Algorithms and Problem Complexity,Categories and Subject Descriptors,Clustering,F2 [Theory of Computation],H3 [Information Systems],Information Storage and Retrieval General Terms,Theory Additional Key Words and Phrases,graph algorithms,spectral methods},
number = {3},
pages = {497--515},
title = {On Clusterings: Good, Bad and Spectral},
url = {http://dl.acm.org/citation.cfm?id=990313$\backslash$nhttp://portal.acm.org/citation.cfm?doid=990308.990313},
volume = {51},
year = {2004}
}
@article{King1986,
abstract = {This article identifies a set of serious theoretical mistakes appearing with troublingly high frequency throughout the quantitative political science literature. These mistakes are all based on faulty statistical theory or on erroneous statistical analysis. Through algebraic and interpretive proofs, some of the most commonly made mistakes are explicated and illus- trated. The theoretical problem underlying each is highlighted, and suggested solutions are provided throughout. It is argued that closer attention to these problems and solutions will result in more reliable quantitative analyses and more useful theoretical contributions.},
author = {King, Gary (New York University)},
journal = {American Journal of Political Science},
month = {aug},
number = {3},
pages = {666--687},
title = {How Not to Lie with Statistics: Avoiding Common Mistakes in Quantitative Political Science},
url = {http://www.jstor.org/stable/2111095?origin=crossref},
volume = {30},
year = {1986}
}
@article{Chen2006,
author = {Chen, Nawei and Blostein, Dorothea},
doi = {10.1007/s10032-006-0020-2},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Blostein - 2006 - A survey of document image classification problem statement, classifier architecture and performance evaluation.pdf:pdf},
issn = {1433-2833},
journal = {International Journal of Document Analysis and Recognition (IJDAR)},
keywords = {class models,classification,document categorization,document classification,document classifiers,document features,document image classification,feature representations},
month = {aug},
number = {1},
pages = {1--16},
title = {A survey of document image classification: problem statement, classifier architecture and performance evaluation},
url = {http://www.springerlink.com/index/10.1007/s10032-006-0020-2},
volume = {10},
year = {2006}
}
@inproceedings{Ramirez2011,
abstract = {This paper addresses the problem of video anomaly recovery from a sequence of spectrally compressed video frames. Analysis of anomalies occurring in both time and spectrum is important in video surveillance applications. We present a methodology for the recovery of anomalies such as moving objects and their spectral signatures from spectrally compressed video. The spectrally compressed video frames are obtained by using a Coded Aperture Snapshot Spectral Imaging (CASSI) system. The CASSI system encodes a 3-D data cube containing both 2-D spatial information and spectral information in a single 2-D measurement. In the proposed methodology, we use the spectrally compressed video as columns of a large data matrix Q. Principal Component Pursuit (PCP) is then used to decompose Q into the stationary background and a sparse matrix capturing the anomalies in the foreground. The sparse matrix is then used jointly with Q to recover the spectral information of the objects of interest. An example for the recovery of video anomalies in a 3-channel spectral video system (RGB) is presented.},
author = {Ramirez, Ana B. and Arguello, Henry and Arce, Gonzalo},
booktitle = {2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2011.5946655},
isbn = {978-1-4577-0538-0},
issn = {1520-6149},
keywords = {2D spatial information,3D data cube,Apertures,CASSI system,Compressive sensing,Image coding,Imaging,Matrix decomposition,Sparse matrices,Video surveillance,anomaly analysis,code aperture snapshot spectral imaging,coded aperture snapshot spectral imaging system,compressed spectral imaging,data compression,data matrix,image reconstruction,image sequences,matrix algebra,principal component analysis,principal component pursuit,single 2D measurement,sparse matrix,spectral analysis,spectral compressed video frames,spectral information recovery,spectral signatures,spectral video system,stationary background,video anomaly recovery,video coding,video sequence,weighted median},
month = {may},
pages = {1321--1324},
publisher = {IEEE},
shorttitle = {Acoustics, Speech and Signal Processing (ICASSP), },
title = {Video anomaly recovery from compressed spectral imaging},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5946655},
year = {2011}
}
@inproceedings{Bifet2015,
author = {Bifet, Albert},
booktitle = {2nd Annual International Symposium on Information Management and Big Data},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bifet - 2015 - Real-Time Big Data Stream Analytics.pdf:pdf},
title = {Real-Time Big Data Stream Analytics},
year = {2015}
}
@misc{Luxburg2005,
abstract = {An important aspect of clustering algorithms is whether the partitions constructed on finite samples converge to a useful clustering of the whole data space as the sample size increases. This paper investigates this question for normalized and unnormalized versions of the popular spec- tral clustering algorithm. Surprisingly, the convergence of unnormalized spectral clustering is more difficult to handle than the normalized case. Even though recently some first results on the convergence of normal- ized spectral clustering have been obtained, for the unnormalized case we have to develop a completely new approach combining tools from numerical integration, spectral and perturbation theory, and probability. It turns out that while in the normalized case, spectral clustering usually converges to a nice partition of the data space, in the unnormalized case the same only holds under strong additional assumptions which are not always satisfied. We conclude that our analysis gives strong evidence for the superiority of normalized spectral clustering. It also provides a basis for future exploration of other Laplacian-based methods.},
author = {v. Luxburg, Ulrike and Bousquet, Olivier and Belkin, Mikhail},
isbn = {0262195348},
issn = {10495258},
keywords = {Spectral Clustering,Theory {\&} Algorithms},
mendeley-tags = {Spectral Clustering},
title = {Limits of spectral clustering},
url = {http://eprints.pascal-network.org/archive/00003908/},
urldate = {2015-04-01},
year = {2005}
}
@incollection{Studenmund2005d,
address = {London},
author = {Studenmund, A H},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {5},
edition = {Fifth},
editor = {Clinton, Denise},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {5. Hypothesis Testing},
year = {2005}
}
@inproceedings{Piccardi2004a,
abstract = {Background subtraction is a widely used approach for detecting moving objects from static cameras. Many different methods have been proposed over the recent years and both the novice and the expert can be confused about their benefits and limitations. In order to overcome this problem, this paper provides a review of the main methods and an original categorisation based on speed, memory requirements and accuracy. Such a review can effectively guide the designer to select the most suitable method for a given application in a principled way. Methods reviewed include parametric and non-parametric background density estimates and spatial correlation approaches.},
author = {Piccardi, M.},
booktitle = {Systems, Man and Cybernetics},
doi = {10.1109/ICSMC.2004.1400815},
isbn = {0-7803-8567-5},
issn = {1062-922X},
keywords = {Australia,Cameras,Computer vision,Filters,Geometry,Information technology,Layout,Object detection,Subtraction techniques,Videos,background density estimation,background subtraction technique,feature extraction,image motion analysis,spatial correlation,static cameras},
month = {oct},
pages = {3099--3104},
shorttitle = {Systems, Man and Cybernetics, 2004 IEEE Internatio},
title = {Background subtraction techniques: A review},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1400815},
year = {2004}
}
@article{Donoho2003,
abstract = {Given a dictionary D = {\{}dk{\}} of vectors dk, we seek to represent a signal S as a linear combination S = {\{}sum{\}}k {\{}gamma{\}}(k)dk, with scalar coefficients{\{}gamma{\}} (k). In particular, we aim for the sparsest representation possible. In general, this requires a combinatorial optimization process. Previous work considered the special case where D is an overcomplete system consisting of exactly two orthobases and has shown that, under a condition of mutual incoherence of the two bases, and assuming that S has a sufficiently sparse representation, this representation is unique and can be found by solving a convex optimization problem: specifically, minimizing the {\{}ell{\}}1 norm of the coefficients{\{}gamma{\}} . In this article, we obtain parallel results in a more general setting, where the dictionary D can arise from two or several bases, frames, or even less structured systems. We sketch three applications: separating linear features from planar ones in 3D data, noncooperative multiuser encoding, and identification of over-complete independent component models.},
author = {Donoho, D. L.},
doi = {10.1073/pnas.0437847100},
issn = {00278424},
journal = {Proceedings of the National Academy of Sciences},
month = {feb},
number = {5},
pages = {2197--2202},
title = {Optimally sparse representation in general (nonorthogonal) dictionaries via ell 1 minimization},
url = {http://www.pnas.org/content/100/5/2197},
volume = {100},
year = {2003}
}
@book{Aggarwal2007,
abstract = {In recent years, the progress in hardware technology has made it possible for organizations to store and record large streams of transactional data. Such data sets which continuously and rapidly grow over time are referred to as data streams. Data Streams: Models and Algorithms primarily discusses issues related to the mining aspects of data streams rather than the database management aspect of streams. This volume covers mining aspects of data streams in a comprehensive style. Each contributed chapter, from a variety of well known researchers in the data mining field, contains a survey on the topic, the key ideas in the field from that particular topic, and future research directions. Data Streams: Models and Algorithms is intended for a professional audience composed of researchers and practitioners in industry. This book is also appropriate for graduate-level students in computer science. Charu C. Aggarwal obtained his B. Tech in Computer Science from IIT Kanpur in 1993 and Ph. D. from MIT in 1996. He has been a Research Staff Member at IBM since then, and has published over 90 papers in major conferences and journals in the database and data mining field. He has applied for, or been granted, over 50 US and International patents, and has twice been designated Master Inventor at IBM for the commercial value of his patents. He has been granted 14 invention achievement awards by IBM for his patents. His work on real time bio-terrorist threat detection in data streams won the IBM Epispire award for environmental excellence in 2003. He has served on the program committee of most major database conferences, and was program chair for the Data Mining and Knowledge Discovery Workshop, 2003, and a program vice-chair for the SIAM Conference on Data Mining, 2007. He is an associate editor of the IEEE Transactions on Data Engineering and an action editor of the Data Mining and Knowledge Discovery Journal. He is a senior member of the IEEE. An Introduction to Data Streams -- On Clustering Massive Data Streams: A Summarization Paradigm -- A Survey of Classification Methods in Data Streams -- Frequent Pattern Mining in Data Streams -- A Survey of Change Diagnosis Algorithms in Evolving Data Streams -- Multi-Dimensional Analysis of Data Streams Using Stream Cubes -- Load Shedding in Data Stream Systems -- The Sliding-Window Computation Model and Results -- A Survey of Synopsis Construction in Data Streams -- A Survey of Join Processing in Data Streams -- Indexing and Querying Data Streams -- Dimensionality Reduction and Forecasting on Streams -- A Survey of Distributed Mining of Data Streams -- Algorithms for Distributed Data Stream Mining -- A Survey of Stream Processing Problems and Techniques in Sensor Networks.},
author = {Aggarwal, Charu C.},
isbn = {9780387475349},
pages = {354},
publisher = {Springer},
title = {Data streams : {Models} and algorithms},
year = {2007}
}
@inproceedings{Aslan2013a,
abstract = {This paper examines the performance of Hidden Markov Tree model based weights in reconstruction quality for an existing task-aware compressive video coding system which aims object detection specifically. The existing system utilizes weights in reconstruction which are computed by tracking of the foreground object. The proposed system acquires similar average PSNR with the existing one which reported some improvement compared to the conventional unweighted reconstruction at low sampling rates. Furthermore, it is a little bit better than the existing system at higher sampling rates. It can be inferred from this study that Bayesian approaches that take account structural dependencies between transformation coefficients has the potential of improving reconstruction quality for such a compressive video coding system with object detection task.},
author = {Aslan, Sinem and {Turhan Tunali}, E.},
booktitle = {2013 21st Signal Processing and Communications Applications Conference (SIU)},
doi = {10.1109/SIU.2013.6531223},
isbn = {978-1-4673-5563-6},
keywords = {Bayes methods,Bayesian approaches,Compressive Sensing,Hidden Markov Tree model,average PSNR,compressed video coding,conventional unweighted reconstruction,data compression,foreground object tracking,hidden Markov model,hidden Markov models,hidden Markov tree model based weights,image reconstruction,joint compressive video coding,object detection,object detection task,object tracking,reconstruction quality,sampling rates,structural dependency,surveillance video,task-aware compressive video coding system,transformation coefficients,trees (mathematics),video coding,weighted reconstruction},
language = {English},
month = {apr},
pages = {1--4},
publisher = {IEEE},
shorttitle = {Signal Processing and Communications Applications },
title = {Joint compressive video coding and analysis With Hidden Markov model based weighted reconstruction},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6531223 http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6531223},
year = {2013}
}
@inproceedings{Boone2014,
author = {Boone, K. and Ridge, A. and Crickmore, R. and Onen, D.},
booktitle = {International Petroleum Technology Conference},
doi = {10.2523/IPTC-17530-MS},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boone et al. - 2014 - Detecting Leaks in Abandoned Gas Wells with Fibre-Optic Distributed Acoustic Sensing.pdf:pdf},
isbn = {978-1-61399-322-4},
keywords = {abandonment,acoustic,fibre,integrity,leak},
month = {jan},
title = {Detecting Leaks in Abandoned Gas Wells with Fibre-Optic Distributed Acoustic Sensing},
url = {http://www.onepetro.org/doi/10.2523/IPTC-17530-MS},
year = {2014}
}
@inproceedings{Wagner1993,
author = {Wagner, D. and Wagner, F.},
booktitle = {Proceedings of the 18th International Symposium on Mathematical Foundations of Computer Science},
isbn = {3540571825},
pages = {744--750},
title = {Between Min Cut and Graph Bisection},
year = {1993}
}
@article{Melnykov2012,
abstract = {The R package MixSim is a new tool that allows simulating mixtures of Gaussian distributions with different levels of overlap between mixture components. Pairwise overlap, defined as a sum of two misclassification probabilities, measures the degree of interaction between components and can be readily employed to control the clustering complexity of datasets simulated from mixtures. These datasets can then be used for systematic performance investigation of clustering and finite mixture modeling algorithms. Among other capabilities of MixSim, there are computing the exact overlap for Gaussian mixtures, simulating Gaussian and non-Gaussian data, simulating outliers and noise variables, calculating various measures of agreement between two partitionings, and constructing parallel distribution plots for the graphical display of finite mixture models. All features of the package are illustrated in great detail. The utility of the package is highlighted through a small comparison study of several popular clustering algorithms.},
author = {Melnykov, Volodymyr and Chen, Wei-Chen and Maitra, Ranjan},
doi = {10.18637/jss.v051.i12},
issn = {1548-7660},
journal = {Journal of Statistical Software},
language = {en},
month = {nov},
number = {12},
pages = {1--25},
title = {MixSim : An R Package for Simulating Data to Study Performance of Clustering Algorithms},
url = {http://www.jstatsoft.org/index.php/jss/article/view/v051i12/v51i12.pdf},
volume = {51},
year = {2012}
}
@inproceedings{Liu2007,
author = {Liu, Tie-Yan and Yang, Huai-Yuan and Zheng, Xin and Qin, Tao and Ma, Wei-Ying},
booktitle = {European Conference on Information Retrieval},
doi = {10.1007/978-3-540-71496-5_30},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2007 - Fast large-scale spectral clustering by sequential shrinkage optimization.pdf:pdf},
isbn = {978-3-540-71494-1},
issn = {03029743},
pages = {319--330},
title = {Fast large-scale spectral clustering by sequential shrinkage optimization},
url = {http://link.springer.com/10.1007/978-3-540-71496-5{\_}30},
year = {2007}
}
@article{Srivastava2003,
author = {Srivastava, A and Lee, AB B},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Srivastava, Lee - 2003 - On advances in statistical modeling of natural images.pdf:pdf},
journal = {{\{}{\ldots}{\}} of mathematical imaging {\{}{\ldots}{\}}},
keywords = {bessel k form,generalized laplacian,image manifold,natural image statistics,non-gaussian models,scale invariance,statistical image analysis},
number = {i},
title = {{On advances in statistical modeling of natural images}},
url = {http://link.springer.com/article/10.1023/A:1021889010444},
year = {2003}
}
@misc{Alahi2012,
abstract = {Vision-based background subtraction algorithms model the intensity variation across time to classify a pixel as foreground. Unfortunately, such algorithms are sensitive to appearance changes of the background such as sudden changes of illumination or when videos are projected in the background. In this work, we propose an algorithm to extract foreground silhouettes without modeling the intensity variation across time. Using a camera pair, the stereo mismatch is processed to produce a dense disparity based on a Total Variation (TV) framework. Experimental results show that with sudden changes of background appearance, our proposed TV disparity-based extraction outperforms intensity-based algorithms and existing stereo-based approaches based on temporal depth variation and stereo mismatch.},
author = {Alahi, A. and Bagnato, L. and Matti, D. and Vandergheynst, P.},
doi = {10.1109/ICIP.2012.6467088},
issn = {1522-4880},
keywords = {Background subtraction,Cameras,Equations,Estimation,Lighting,Real-time systems,Robustness,TV,TV disparity-based extraction,background appearance change,camera pair,computer vision,dense-disparity production,disparity map,feature extraction,foreground silhouette extraction,foreground silhouettes,illumination changes,image classification,image pixel classification,intensity variation model,stereo camera,stereo image processing,stereo mismatch processing,temporal depth variation,total variation,total variation framework,video projection,vision-based background subtraction algorithms},
pages = {1229--1232},
shorttitle = {Image Processing (ICIP), 2012 19th IEEE Internatio},
title = {Foreground silhouette extraction robust to sudden changes of background appearance},
year = {2012}
}
@inproceedings{Davies2013,
abstract = {Background subtraction is a key method required to aid processing surveillance videos. Current methods require storing each pixel of every video frame, which can be wasteful as most of this information refers to the uninteresting background. Compressive sensing can offer an efficient solution by using the fact that foreground is often sparse in the spatial domain. By making this assumption and applying a specific recovery algorithm to a trained background, it is possible to reconstruct the foreground, using only a low dimensional representation of the difference between the current frame and the estimated background scene. Although new compressive sensing background subtraction algorithms are being created, no study has been made of the effect of recovery algorithms on performance of background subtraction. This is considered by applying both Basis Pursuit and Orthogonal Matching Pursuit (OMP) to a standard test video, and comparing their accuracy.},
author = {Davies, Rhian and Mihaylova, Lyudmila and Pavlidis, Nicos and Eckley, Idris A},
booktitle = {Sensor Data Fusion: Trends, Solutions, Applications},
doi = {10.1109/SDF.2013.6698258},
isbn = {9781479907786},
month = {oct},
pages = {1--6},
title = {The effect of recovery algorithms on compressive sensing background subtraction},
url = {http://ieeexplore.ieee.org/document/6698258/},
year = {2013}
}
@article{Pothen1990,
author = {Pothen, Alex and Simon, Horst D. and Liou, Kang-Pu},
doi = {10.1137/0611030},
issn = {0895-4798},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {Spectral Clustering},
mendeley-tags = {Spectral Clustering},
month = {jul},
number = {3},
pages = {430--452},
publisher = {Society for Industrial and Applied Mathematics},
title = {Partitioning Sparse Matrices with Eigenvectors of Graphs},
url = {http://dl.acm.org/citation.cfm?id=84514.84521},
volume = {11},
year = {1990}
}
@article{Dhanjal2014,
abstract = {Partitioning a graph into groups of vertices such that those within each group are more densely connected than vertices assigned to different groups, known as graph clustering, is often used to gain insight into the organisation of large scale networks and for visualisation purposes. Whereas a large number of dedicated techniques have been recently proposed for static graphs, the design of on-line graph clustering methods tailored for evolving networks is a challenging problem, and much less documented in the literature. Motivated by the broad variety of applications concerned, ranging from the study of biological networks to the analysis of networks of scientific references through the exploration of communications networks such as the World Wide Web, it is the main purpose of this paper to introduce a novel, computationally efficient, approach to graph clustering in the evolutionary context. Namely, the method promoted in this article can be viewed as an incremental eigenvalue solution for the spectral clustering method described by Ng et al. (2001) [25]. The incremental eigenvalue solution is a general technique for finding the approximate eigenvectors of a symmetric matrix given a change. As well as outlining the approach in detail, we present a theoretical bound on the quality of the approximate eigenvectors using perturbation theory. We then derive a novel spectral clustering algorithm called Incremental Approximate Spectral Clustering (IASC). The IASC algorithm is simple to implement and its efficacy is demonstrated on both synthetic and real datasets modelling the evolution of a HIV epidemic, a citation network and the purchase history graph of an e-commerce website. {\textcopyright} 2014 Elsevier B.V.},
archivePrefix = {arXiv},
arxivId = {1301.1318},
author = {Dhanjal, Charanpal and Gaudel, Romaric and Cl{\'{e}}men{\c{c}}on, St{\'{e}}phan},
doi = {10.1016/j.neucom.2013.11.015},
eprint = {1301.1318},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dhanjal, Gaudel, Cl{\'{e}}men{\c{c}}on - 2014 - Efficient eigen-updating for spectral graph clustering.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Eigen-decomposition,Normalised Laplacian,Spectral Clustering,Spectral graph clustering,Unsupervised learning},
mendeley-tags = {Spectral Clustering},
month = {may},
pages = {440--452},
title = {Efficient eigen-updating for spectral graph clustering},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214000125},
volume = {131},
year = {2014}
}
@article{Sato1999,
author = {Sato, Masa-aki},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sato - 1999 - Fast learning of on-line EM algorithm.pdf:pdf},
journal = {Rapport Technique, ATR Human Information {\{}{\ldots}{\}}},
title = {Fast learning of on-line EM algorithm},
url = {http://scholar.google.com/scholar?hl=en{\{}{\&}{\}}btnG=Search{\{}{\&}{\}}q=intitle:Fast+Learning+of+On-line+EM+Algorithm{\{}{\#}{\}}0 http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Fast+Learning+of+On-line+EM+Algorithm{\#}0},
year = {1999}
}
@article{Brambor2006,
abstract = {Multiplicative interaction models are common in the quantitative political science literature. This is so for good reason. Institutional arguments frequently imply that the relationship between political inputs and outcomes varies depending on the institutional context. Models of strategic interaction typically produce conditional hypotheses as well. Although con- ditional hypotheses are ubiquitous in political science and multiplicative interaction models have been found to capture their intuition quite well, a survey of the top three political science journals from 1998 to 2002 suggests that the execution of these models is often flawed and inferential errors are common. We believe that considerable progress in our understanding of the political world can occur if scholars follow the simple checklist of dos and don'ts for using multiplicative interaction models presented in this article. Only 10{\{}{\%}{\}} of the articles in our survey followed the checklist.},
author = {Brambor, Thomas (New York University) and Clark, William Roberts (University Of Michigan) and Golder, Matt (Florida State University)},
journal = {Political Analysis},
keywords = {Interaction effects,Multiplicative Models,STATA,Statistics},
mendeley-tags = {Interaction effects,Multiplicative Models,STATA,Statistics},
month = {may},
number = {1},
pages = {63--82},
title = {Understanding Interaction Models: Improving Empirical Analyses},
url = {http://pan.oxfordjournals.org/cgi/doi/10.1093/pan/mpi014},
volume = {14},
year = {2006}
}
@article{Bhasker2010,
author = {Bhasker, Harish and Mihaylova, Lyudmila and Achim, Alin},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhasker, Mihaylova, Achim - 2010 - Transactions Letters Video Foreground Detection Based on Symmetric Alpha-Stable Mixture Models.pdf:pdf},
number = {8},
pages = {1133--1138},
title = {Transactions Letters Video Foreground Detection Based on Symmetric Alpha-Stable Mixture Models},
volume = {20},
year = {2010}
}
@article{Same2007,
author = {Sam{\'{e}}, Allou and Ambroise, Christophe and Govaert, G{\'{e}}rard},
doi = {10.1007/s11222-007-9017-z},
issn = {0960-3174},
journal = {Statistics and Computing},
month = {jun},
number = {3},
pages = {209--218},
title = {An online classification EM algorithm based on the mixture model},
url = {http://link.springer.com/10.1007/s11222-007-9017-z},
volume = {17},
year = {2007}
}
@article{Killick2012,
abstract = {We consider the problem of detecting multiple changepoints in large data sets. Our focus is on applications where the number of changepoints will increase as we collect more data: for example in genetics as we sequence larger regions of the genome, or in finance as we observe time-series over longer periods. We consider the common approach of detecting changepoints through minimising a cost function over possible numbers and locations of changepoints. This includes most common procedures for detecting changing points, such as penalised likelihood and minimum description length. We introduce a new method for finding the minimum of such cost functions and hence the optimal number and location of changepoints, that has a computational cost which, under mild conditions, is linear in the number of observations. This compares favourably with existing methods for the same problem whose computational cost can be quadratic, or even cubic. In simulation studies we show that our new method can be orders of magnitude faster than these alternative methods. We also compare with Binary Segmentation and a genetic algorithm for finding changepoints, and show that the exactness of our approach can lead to substantial improvements in the accuracy of the inferred segmentation of the data.},
archivePrefix = {arXiv},
arxivId = {1101.1438},
author = {Killick, R. and Fearnhead, P. and Eckley, I. a.},
doi = {10.1080/01621459.2012.737745},
eprint = {1101.1438},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Killick, Fearnhead, Eckley - 2012 - Optimal detection of changepoints with a linear computational cost.pdf:pdf},
isbn = {0162-1459$\backslash$r1537-274X},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {dynamic programming,pelt,segmentation,structural change},
number = {500},
pages = {1590--1598},
title = {Optimal detection of changepoints with a linear computational cost},
url = {http://arxiv.org/abs/1101.1438},
volume = {107},
year = {2012}
}
@book{Gama2010,
abstract = {Since the beginning of the Internet age and the increased use of ubiquitous computing devices, the large volume and continuous flow of distributed data have imposed new constraints on the design of learning algorithms. Exploring how to extract knowledge structures from evolving and time-changing data, Knowledge Discovery from Data Streams presents a coherent overview of state-of-the-art research in learning from data streams. The book covers the fundamentals that are imperative to understanding data streams and describes important applications, such as TCP/IP traffic, GPS data, sensor networks, and customer click streams. It also addresses several challenges of data mining in the future, when stream mining will be at the core of many applications. These challenges involve designing useful and efficient data mining solutions applicable to real-world problems. In the appendix, the author includes examples of publicly available software and online data sets. This practical, up-to-date book focuses on the new requirements of the next generation of data mining. Although the concepts presented in the text are mainly about data streams, they also are valid for different areas of machine learning and data mining.},
author = {Gama, Jo{\~{a}}o},
isbn = {1439826129},
pages = {251--252},
publisher = {CRC Press},
title = {Knowledge discovery from data streams},
url = {https://books.google.com/books?hl=en{\&}lr={\&}id=r1XRBQAAQBAJ{\&}pgis=1},
year = {2010}
}
@inproceedings{Spielman1996,
abstract = {Spectral partitioning methods use the Fiedler vector|the eigenvector of the second-smallest eigenvalue of the Laplacian matrix|to nd a small separator of a graph. These methods are important components of many scientiic numerical algorithms and have been demonstrated by experiment to work extremely well. In this paper, we show that spectral partitioning methods work well on bounded-degree planar graphs and element meshes| the classes of graphs to which they are usually applied. While naive spectral bisection does not necessarily work, we prove that spectral partitioning techniques can be used to produce separators whose ratio of vertices removed to edges cut is O(p n) for bounded-degree planar graphs and two-dimensional meshes and O n 1=d for well-shaped d-dimensional meshes. The heart of our analysis is an upper bound on the second-smallest eigenvalues of the Laplacian matrices of these graphs.},
author = {Spielman, Daniel A and Teng, Shang-Hua},
booktitle = {Foundations of Computer Science},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Spielman, Teng - 1996 - Spectral partioning works planar graphs and finite element meshes.pdf:pdf},
pages = {96--105},
title = {Spectral partioning works: planar graphs and finite element meshes},
year = {1996}
}
@article{Chen2001,
author = {Chen, Scott Shaobing and Donoho, David L. and Saunders, Michael A},
doi = {10.1137/S003614450037906X},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Donoho, Saunders - 2001 - Atomic Decomposition by Basis Pursuit.pdf:pdf},
issn = {0036-1445},
journal = {SIAM Rev.},
keywords = {{\$}\backslashell{\^{}}1{\$} norm optimization,1 norm optimization,41a45,65d15,65k05,94a12,MATLAB code,ams subject classi cations,cosine packets,de-noising,denoising,interior-point methods for linear,interior-point methods for linear programming,matching pursuit,multi-scale edges,multiscale edges,overcomplete signal representation,programming,scale analysis,time-,time-frequency analysis,time-scale analysis,total variation de-noising,total variation denoising,wavelet packets,wavelets},
month = {jan},
number = {1},
pages = {129--159},
publisher = {Society for Industrial and Applied Mathematics},
title = {Atomic Decomposition by Basis Pursuit},
url = {http://epubs.siam.org/doi/abs/10.1137/S003614450037906X http://dl.acm.org/citation.cfm?id=588736.588850},
volume = {43},
year = {2001}
}
@inproceedings{VanderHorst2014,
author = {van der Horst, Juun and {Den Boer}, Hans and {In 't Panhuis}, Peter and Wyker, Brendan and Kusters, Roel and Mustafina, Daria and Groen, Lex and Bulushi, Nabil and Mjeni, Rifaat and Awan, Kamran Fahmeed and Rajhi, Salma Mohammed and Molenaar, Mathieu M and Reynolds, Alan and Paleja, Rakesh and Randell, David and Bartlett, Richard and Green, Kevyn},
booktitle = {International Petroleum Technology Conference},
doi = {10.2523/IPTC-17528-MS},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van der Horst et al. - 2014 - Fibre Optic Sensing For Improved Wellbore Production Surveillance.pdf:pdf},
isbn = {978-1-61399-322-4},
keywords = {fibre optic sensing,production monitoring,well and reservoir surveillance},
month = {jan},
title = {Fibre Optic Sensing For Improved Wellbore Production Surveillance},
url = {http://www.onepetro.org/doi/10.2523/IPTC-17528-MS},
year = {2014}
}
@article{Chen2013,
author = {{Jing Chen}, Yongtian Wang, and Hanxiao Wu and Chen, Jing and Wang, Yongtian and Wu, Hanxiao},
doi = {10.1109/JSEE.2013.00119},
issn = {1004-4132},
journal = {Journal of Systems Engineering and Electronics},
keywords = {coded aperture,compressive imaging,compressive sensing,motion detection},
language = {English},
month = {dec},
number = {6},
pages = {1019--1028},
publisher = {BIAI},
title = {Coded aperture compressive imaging array applied for surveillance systems},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6756024 http://www.jseepub.com/CN/abstract/abstract12217.shtml},
volume = {24},
year = {2013}
}
@article{Meila2001,
abstract = {We present a new view of clustering and segmentation by pairwise similarities. We interpret the similarities as edge flows in a Markov random walk and study the eigenvalues and eigenvectors of the walk's transition matrix. This view shows that spectral methods for clustering and segmentation have a probabilistic foundation. We prove that the Normalized Cut method arises naturally from our framework and we provide a complete characterization of the cases when the Normalized Cut algorithm is exact. Then we discuss other spectral segmentation and clustering methods showing that several of them are essentially the same as NCut.},
author = {Meila, M. and Meila, M. and Shi, J. and Shi, J.},
doi = {10.1.1.33.1501},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meila et al. - 2001 - A random walks view of spectral segmentation.pdf:pdf},
journal = {AI and Statistics (AISTATS)},
keywords = {Spectral Clustering},
mendeley-tags = {Spectral Clustering},
pages = {5287},
title = {A random walks view of spectral segmentation},
url = {http://scholar.google.com/scholar?hl=en{\{}{\&}{\}}btnG=Search{\{}{\&}{\}}q=intitle:A+Random+Walks+View+of+Spectral+Segmentation{\{}{\#}{\}}0 http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:A+Random+Walks+View+of+Spectral+Segmentation{\#}0},
volume = {57},
year = {2001}
}
@incollection{Studenmund2005k,
address = {London},
author = {Studenmund, A H},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {16},
edition = {Fifth},
editor = {Clinton, Denise},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {16. Statistical Principles},
year = {2005}
}
@article{Franti2006,
abstract = {Agglomerative clustering generates the partition hierarchically by a sequence of merge operations. We propose an alternative to the merge-based approach by removing the clusters iteratively one by one until the desired number of clusters is reached. We apply local optimization strategy by always removing the cluster that increases the distortion the least. Data structures and their update strategies are considered. The proposed algorithm is applied as a crossover method in a genetic algorithm, and compared against the best existing clustering algorithms. The proposed method provides best performance in terms of minimizing intra-cluster variance. {\textcopyright} 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
author = {Fr{\"{a}}nti, Pasi and Virmajoki, Olli},
doi = {10.1016/j.patcog.2005.09.012},
isbn = {0-7803-7622-6},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Agglomeration,Clustering algorithms,Codebook generation,PNN,Vector quantization},
number = {5},
pages = {761--775},
title = {Iterative shrinking method for clustering problems},
volume = {39},
year = {2006}
}
@article{Kutyniok2012,
archivePrefix = {arXiv},
arxivId = {1203.3815},
author = {Kutyniok, Gitta},
eprint = {1203.3815},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kutyniok - 2012 - Theory and Applications of Compressed Sensing.pdf:pdf},
journal = {arXiv preprint arXiv:1203.3815},
keywords = {15b52,2000,2006,65f22,68u10,90c25,94a12,94a20,and since then,compressed sensing is a,dimension reduction,frames,greedy algorithms,ill-posed inverse problems,minimization,msc,novel research area,random matrices,sparse approximation,sparse recovery,which was introduced in,ℓ 1},
month = {mar},
number = {July},
title = {Theory and Applications of Compressed Sensing},
url = {http://arxiv.org/abs/1203.3815},
year = {2012}
}
@article{Mihaylova,
author = {Mihaylova, Lyudmila},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mihaylova - Unknown - SMART INTELLIGENT VIDEO SURVEILLANCE.pdf:pdf},
pages = {1--10},
title = {SMART INTELLIGENT VIDEO SURVEILLANCE}
}
@inproceedings{La2006,
abstract = {Recent studies in linear inverse problems have recognized the sparse representation of unknown signal in a certain basis as an useful and effective prior information to solve those problems. In many multiscale bases (e.g. wavelets), signals of interest (e.g. piecewise-smooth signals) not only have few significant coefficients, but also those significant coefficients are well-organized in trees. We propose to exploit this sparse tree representation as additional prior information for linear inverse problems with limited numbers of measurements. In particular, our proposed algorithm named tree-based orthogonal matching pursuit (TOMP) is shown to provide significant better reconstruction compared to methods that only use sparse representation assumption},
author = {La, Chinh and Do, Minh},
booktitle = {International Conference on Image Processing},
doi = {10.1109/ICIP.2006.312578},
isbn = {1-4244-0480-0},
issn = {1522-4880},
keywords = {Indexing,Inverse problems,Length measurement,Matching pursuit algorithms,Pursuit algorithms,Reconstruction algorithms,Signal reconstruction,Tree data structures,Tree-based Orthogonal Matching Pursuit,Wavelet coefficients,greedy algorithms,linear inverse problem,signal representation,sparse representation,sparse representations,tree structures,tree-based orthogonal matching pursuit algorithm,trees (mathematics),unknown signal recognition},
pages = {1277--1280},
shorttitle = {Image Processing, 2006 IEEE International Conferen},
title = {Tree-Based Orthogonal Matching Pursuit Algorithm for Signal Reconstruction},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4106770},
year = {2006}
}
@article{Candes2005,
author = {Cand{\`{e}}s, Emmanuel and Tao, Terence},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cand{\`{e}}s, Tao - 2005 - Decoding by linear programming.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
keywords = {basis pursuit,decoding of,determined systems,duality in optimization,gaussian random matrices,gramming,l1 minimization,linear codes,linear pro-,principal angles,random,restricted orthonormality,singular,sparse solutions to under-,values of random matrices},
pages = {1--22},
title = {Decoding by linear programming},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1542412 http://ieeexplore.ieee.org/xpls/abs{\{}{\_}{\}}all.jsp?arnumber=1542412},
year = {2005}
}
@article{McIvor2000,
author = {McIvor, AM M},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McIvor - 2000 - Background subtraction techniques.pdf:pdf},
journal = {Proc. of Image and Vision Computing},
keywords = {background subtraction,segmentation,surveillance},
number = {1},
title = {Background subtraction techniques},
url = {http://algebra.sci.csueastbay.edu/{~}tebo/Classes/6825/ivcnz00.pdf http://algebra.sci.csueastbay.edu/{\{}{~}{\}}tebo/Classes/6825/ivcnz00.pdf},
year = {2000}
}
@article{Zhang2013,
abstract = {Recently, sparse coding has been successfully applied in visual tracking. The goal of this paper is to review the state-of-the-art tracking methods based on sparse coding. We first analyze the benefits of using sparse coding in visual tracking and then categorize these methods into appearance modeling based on sparse coding (AMSC) and target searching based on sparse representation (TSSR) as well as their combination. For each categorization, we introduce the basic framework and subsequent improvements with emphasis on their advantages and disadvantages. Finally, we conduct extensive experiments to compare the representative methods on a total of 20 test sequences. The experimental results indicate that: (1) AMSC methods significantly outperform TSSR methods. (2) For AMSC methods, both discriminative dictionary and spatial order reserved pooling operators are important for achieving high tracking accuracy. (3) For TSSR methods, the widely used identity pixel basis will degrade the performance when the target or candidate images are not aligned well or severe occlusion occurs. (4) For TSSR methods, ℓ1ℓ1 norm minimization is not necessary. In contrast, ℓ2ℓ2 norm minimization can obtain comparable performance but with lower computational cost. The open questions and future research topics are also discussed.},
author = {Zhang, Shengping and Yao, Hongxun and Sun, Xin and Lu, Xiusheng},
doi = {10.1016/j.patcog.2012.10.006},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2013 - Sparse coding based visual tracking Review and experimental comparison.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {appearance modeling,dictionary learning,sparse coding,sparse representation,visual tracking},
month = {jul},
number = {7},
pages = {1772--1788},
title = {Sparse coding based visual tracking: Review and experimental comparison},
url = {http://dx.doi.org/10.1016/j.patcog.2012.10.006},
volume = {46},
year = {2013}
}
@article{Wang2012b,
abstract = {To improve the speed of image storage, processing and transmission in visual systems, to reduce the computation of target-tracking algorithm and to improve the performance of the visual tracking methods with object appearance variation, according to the signal description and processing theory of compressive sensing, the tracking based on eigenbasis and compressive sampling is proposed, and the objects in the visual system are described in low-dimensional subspace representation learned online. Meanwhile, combining the representation with Bayesian inference, an adaptive object tracking method is presented. First, the authors represent the appearance of the object in the low-dimensional subspace, then they obtain the optimal estimation of the state parameters by Bayesian inference. Finally, the authors update the eigenbasis space using the optimal observation. Experimental results show that the proposed method is able to track objects effectively and robustly under pose variation, temporary occlusion and large illumination changes.},
author = {Wang, J. and Li, J.},
doi = {10.1049/iet-ipr.2012.0154},
issn = {1751-9659},
journal = {IET Image Processing},
keywords = {Bayes methods,Bayesian inference,adaptive object tracking algorithm,adaptive object tracking method,adaptive signal processing,compressed sensing,compressive sampling,compressive sensing,eigenbasis space,image processing,image representation,image sampling,image storage,image transmission,object appearance variation,object tracking,parameter estimation,performance improvement,pose variation,signal description,signal processing theory,state parameter estimation,subspace representation,target tracking,target-tracking algorithm,temporary occlusion,visual tracking method},
language = {English},
month = {nov},
number = {8},
pages = {1170--1180},
publisher = {IET},
shorttitle = {Image Processing, IET},
title = {Adaptive object tracking algorithm based on eigenbasis space and compressive sampling},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6403963 http://digital-library.theiet.org/content/journals/10.1049/iet-ipr.2012.0154},
volume = {6},
year = {2012}
}
@inproceedings{Schniter2008,
abstract = {A low-complexity recursive procedure is presented for minimum mean squared error (MMSE) estimation in linear regression models. A Gaussian mixture is chosen as the prior on the unknown parameter vector. The algorithm returns both an approximate MMSE estimate of the parameter vector and a set of high posterior probability mixing parameters. Emphasis is given to the case of a sparse parameter vector. Numerical simulations demonstrate estimation performance and illustrate the distinctions between MMSE estimation and MAP model selection. The set of high probability mixing parameters not only provides MAP basis selection, but also yields relative probabilities that reveal potential ambiguity in the sparse model.},
author = {Schniter, Philip and Potter, Lee C. and Ziniel, Justin},
booktitle = {2008 Information Theory and Applications Workshop},
doi = {10.1109/ITA.2008.4601068},
isbn = {978-1-4244-2670-6},
keywords = {Bayes methods,Bayesian methods,Estimation error,Gaussian mixture,Gaussian processes,Linear regression,MAP model selection,MMSE,Matching pursuit algorithms,Recursive estimation,Signal processing,Signal processing algorithms,State estimation,Sufficient conditions,Vectors,fast Bayesian matching pursuit,high posterior probability mixing parameter,iterative methods,least mean squares methods,linear regression model,low-complexity recursive procedure,maximum likelihood estimation,minimum mean squared error estimation,probability,regression analysis,sparse parameter vector},
month = {jan},
pages = {326--333},
publisher = {IEEE},
shorttitle = {Information Theory and Applications Workshop, 2008},
title = {Fast bayesian matching pursuit},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4601068},
year = {2008}
}
@incollection{Studenmund2005h,
address = {London},
author = {Studenmund, A H},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {9},
edition = {Fifth},
editor = {Clinton, Denise},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {9. Serial Correlation},
year = {2005}
}
@article{Bartels2014,
annote = {An algorithm is proposed to calculate confidence intervals and p-values for hypothesis testing that converge to exact values in the limit of investing a large amount of computation time. The frequentist hypothesis test procedure is generic, exact, efficient, conceptually simple, and fairly easy to implement. The procedure is generic in that no assumptions were made on the probability model or the test procedure. The procedure is exact in that independent of the model and the test, the procedure determines exact p-values in the limit of sufficiently large computational resources. The procedure is conceptually simple in that it uses only basic definitions of statistical concepts. With respect to computational efficiency, the proposed algorithm with the likelihood-ratio test is comparable to bootstrap with maximum likelihood estimation of parameters.},
author = {Bartels, Christian},
keywords = {confidence region,mcmc,p-value,statistics},
mendeley-tags = {confidence region,mcmc,p-value,statistics},
month = {jun},
title = {Efficient generic integration algorithm to determine confidence intervals and p-values for hypothesis testing},
url = {http://figshare.com/articles/Efficient{\_}generic{\_}integration{\_}algorithm{\_}to{\_}determine{\_}confidence{\_}intervals{\_}and{\_}p{\_}values{\_}for{\_}hypothesis{\_}testing/1054694},
year = {2014}
}
@article{Ye2009,
author = {Ye, Qiang},
doi = {10.1137/060676349},
issn = {0895-4798},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {diagonal dominant matrix,eigenvalues,relative perturbation},
month = {jan},
number = {1},
pages = {11--17},
publisher = {Society for Industrial and Applied Mathematics},
title = {Relative Perturbation Bounds for Eigenvalues of Symmetric Positive Definite Diagonally Dominant Matrices},
url = {http://dl.acm.org/citation.cfm?id=1654229.1654231},
volume = {31},
year = {2009}
}
@inproceedings{Li2012,
abstract = {This paper proposes a novel approach to deal with the problem of visual tracking in some challenging situations. In our approach, Gabor features of image are used for expressing the templates and candidate targets in order to enhance the robustness of the variations due to illumination and appearance changes. Then we cast tracking as a sparse approximation problem in a particle filter framework. Gabor features derived from the Gabor wavelets representation of image are robust to changes in illumination and expression of the target object. At the same time, the sparse representation is able to deal with the problem of noise, varying viewpoints, background clutter, and illumination changes. The sparse representation is achieved by solving the ℓ1-regularized least square problem. The candidate target with the smallest residual error is considered as the target we want. Most of existing algorithms are unable to track objects for a long time because of the even-changing target and background. In order to overcome the drawback, the template set is renewed by using the incremental learning algorithm which is based on principal components analysis(PCA). We use our approach and other popular methods to track 4 challenging video sequences in which the target objects and the backgrounds change intensively and the targets are partially occluded sometimes. The results show that our method has more excellent performances compared with other methods.},
author = {Li, Weiguang and Hou, Yueen and Lou, Huidong and Ye, Guoqiang},
booktitle = {2012 IEEE International Conference on Robotics and Biomimetics (ROBIO)},
doi = {10.1109/ROBIO.2012.6491234},
isbn = {978-1-4673-2127-3},
keywords = {{\&}{\#}x2113,1-regularized least square problem,Gabor feature,Gabor filters,Gabor wavelets representation,PCA,approximation theory,background clutter,illumination,image representation,incremental learning algorithm,learning (artificial intelligence),least mean squares methods,object tracking,particle filter framework,particle filtering (numerical methods),principal component analysis,residual error,robust visual tracking,sparse approximation problem,sparse representation,video sequences,wavelet transforms},
language = {English},
month = {dec},
pages = {1829--1835},
publisher = {IEEE},
shorttitle = {Robotics and Biomimetics (ROBIO), 2012 IEEE Intern},
title = {Robust visual tracking based on Gabor feature and sparse representation},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6491234 http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6491234},
year = {2012}
}
@article{Needell2009,
abstract = {Compressive sampling offers a new paradigm for acquiring signals that are compressible with respect to an orthonormal basis. The major algorithmic challenge in compressive sampling is to approximate a compressible signal from noisy samples. This paper describes a new iterative recovery algorithm called CoSaMP that delivers the same guarantees as the best optimization-based approaches. Moreover, this algorithm offers rigorous bounds on computational cost and storage. It is likely to be extremely efficient for practical problems because it requires only matrix–vector multiplies with the sampling matrix. For compressible signals, the running time is just O(Nlog2N)O(Nlog2N), where N is the length of the signal.},
author = {Needell, D. and Tropp, J.A.},
doi = {10.1016/j.acha.2008.07.002},
issn = {10635203},
journal = {Applied and Computational Harmonic Analysis},
keywords = {algorithms,approximation,basis pursuit,compressed sensing,orthogonal matching pursuit,restricted isometry property,signal recovery,sparse approximation,uncertainty principle},
month = {may},
number = {3},
pages = {301--321},
title = {CoSaMP: Iterative signal recovery from incomplete and inaccurate samples},
url = {http://dx.doi.org/10.1016/j.acha.2008.07.002},
volume = {26},
year = {2009}
}
@article{Chen2014,
abstract = {An inexpensive, noninvasive system that could accurately classify flying insects would have important implications for entomological research, and allow for the development of many useful applications in vector and pest control for both medical and agricultural entomology. Given this, the last sixty years have seen many research efforts devoted to this task. To date, however, none of this research has had a lasting impact. In this work, we show that pseudo-acoustic optical sensors can produce superior data; that additional features, both intrinsic and extrinsic to the insect's flight behavior, can be exploited to improve insect classification; that a Bayesian classification approach allows to efficiently learn classification models that are very robust to over-fitting, and a general classification framework allows to easily incorporate arbitrary number of features. We demonstrate the findings with large-scale experiments that dwarf all previous works combined, as measured by the number of insects and the number of species considered.},
author = {Chen, Yanping and Why, Adena and Batista, Gustavo and Mafra-Neto, Agenor and Keogh, Eamonn},
doi = {10.1007/s10905-014-9454-4},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2014 - Flying Insect Classification with Inexpensive Sensors.pdf:pdf},
isbn = {1090501494544},
issn = {08927553},
journal = {Journal of Insect Behavior},
keywords = {Automate insect classification,Bayesian classifier,flight activity circadian rhythm,insect flight sound,insect wingbeat},
month = {sep},
number = {5},
pages = {657--677},
pmid = {25350921},
publisher = {Springer US},
title = {Flying Insect Classification with Inexpensive Sensors},
url = {http://link.springer.com/10.1007/s10905-014-9454-4},
volume = {27},
year = {2014}
}
@article{Steinbach2004,
abstract = {Cluster analysis divides data into groups (clusters) for the purposes of summarization or improved understanding. For example, cluster analysis has been used to group related documents for browsing, to find genes and proteins that have similar functionality, or as a means of data compression. While clustering has a long history and a large number of clustering techniques have been developed in statistics, pattern recognition, data mining, and other fields, significant challenges still remain. In this chapter we provide a short introduction to cluster analysis, and then focus on the challenge of clustering high dimensional data. We present a brief overview of several recent techniques, including a more detailed description of recent work of our own which uses a concept-based clustering approach. 1},
author = {Steinbach, Michael and Ert{\"{o}}z, Levent and Kumar, Vipin},
doi = {10.1007/978-3-662-08968-2_16},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steinbach, Ert{\"{o}}z, Kumar - 2004 - The Challenges of Clustering High Dimensional Data.pdf:pdf},
isbn = {3540431829},
issn = {3540431829},
journal = {New Directions in Statistical Physics},
pages = {273--309},
title = {The Challenges of Clustering High Dimensional Data},
url = {http://www.springerlink.com/index/10.1007/978-3-662-08968-2{\_}16$\backslash$nhttp://books.google.com/books?hl=en{\&}lr={\&}id=LincuuxkyB0C{\&}oi=fnd{\&}pg=PA273{\&}dq=The+Challenges+of+Clustering+High+Dimensional+Data+*{\&}ots=zC7v8O6Ta4{\&}sig=q9OXlMxqYAERW5bY},
year = {2004}
}
@inproceedings{Liu2013b,
abstract = {Graph clustering has received growing attention in recent years as an important analytical technique, both due to the prevalence of graph data, and the usefulness of graph structures for exploiting intrinsic data characteristics. However, as graph data grows in scale, it becomes increasingly more challenging to identify clusters. In this paper we propose an efficient clustering algorithm for largescale graph data using spectral methods. The key idea is to repeatedly generate a small number of "supernodes" connected to the regular nodes, in order to compress the original graph into a sparse bipartite graph. By clustering the bipartite graph using spectral methods, we are able to greatly improve efficiency without losing considerable clustering power. Extensive experiments show the effectiveness and efficiency of our approach.},
author = {Liu, Jialu and Wang, Chi and Danilevsky, Marina and Han, Jiawei},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2013 - Large-scale spectral clustering on graphs.pdf:pdf},
isbn = {9781577356332},
issn = {10450823},
pages = {1486--1492},
title = {Large-scale spectral clustering on graphs},
year = {2013}
}
@article{Morales2015,
abstract = {samoa (Scalable Advanced Massive Online Analysis) is a platform for mining big data streams. It provides a collection of distributed streaming algorithms for the most common data mining and machine learning tasks such as classification, clustering, and regression, as well as programming abstractions to develop new algorithms. It features a pluggable architecture that allows it to run on several distributed stream processing engines such as Storm, S4, and Samza. samoa is written in Java, is open source, and is available at http://samoa-project.net under the Apache Software License version 2.0.},
author = {Morales, Gianmarco De Francisci and Bifet, Albert},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Morales, Bifet - 2015 - SAMOA Scalable Advanced Massive Online Analysis.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {classification,clustering,data streams,distributed ssytems,machine learning,regresion,tool-box},
pages = {149--153},
title = {SAMOA: Scalable Advanced Massive Online Analysis},
url = {http://jmlr.org/papers/v16/morales15a.html},
volume = {16},
year = {2015}
}
@article{Tropp2004,
author = {Tropp, JA A},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tropp - 2004 - Greed is good Algorithmic results for sparse approximation.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
number = {10},
pages = {2231--2242},
title = {Greed is good: {Algorithmic} results for sparse approximation},
url = {http://ieeexplore.ieee.org/xpls/abs{\{}{\_}{\}}all.jsp?arnumber=1337101 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1337101},
volume = {50},
year = {2004}
}
@article{Liu2013a,
abstract = {Online learned tracking is widely used for its adaptive ability to handle appearance changes. However, it introduces potential drifting problems due to the accumulation of errors during the self-updating, especially for occluded scenarios. The recent literature demonstrates that appropriate combinations of trackers can help balance the stability and flexibility requirements. We have developed a robust tracking algorithm using a local sparse appearance model (SPT) and K-Selection. A static sparse dictionary and a dynamically updated online dictionary basis distribution are used to model the target appearance. A novel sparse representation-based voting map and a sparse constraint regularized mean shift are proposed to track the object robustly. Besides these contributions, we also introduce a new selection-based dictionary learning algorithm with a locally constrained sparse representation, called K-Selection. Based on a set of comprehensive experiments, our algorithm has demonstrated better performance than alternatives reported in the recent literature.},
author = {Liu, Baiyang and Huang, Junzhou and Kulikowski, Casimir and Yang, Lin},
doi = {10.1109/TPAMI.2012.215},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Adaptation models,Encoding,Heuristic algorithms,Histograms,K-selection,SPT,Sparse representation,Target tracking,Visualization,appearance model,dictionary learning,drifting problems,dynamically updated online dictionary basis distri,flexibility requirements,image representation,learning (artificial intelligence),local sparse appearance model,object tracking,occluded scenarios,online learned tracking,robust tracking algorithm,robust visual tracking,selection-based dictionary learning algorithm,sparse constraint regularized mean shift,sparse representation-based voting map,stability requirements,static sparse dictionary,tracking},
month = {dec},
number = {12},
pages = {2968--81},
pmid = {24136434},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {Robust visual tracking using local sparse appearance model and K-selection.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24136434},
volume = {35},
year = {2013}
}
@article{Luxburg2008,
author = {von Luxburg, Ulrike and Belkin, Mikhail and Bousquet, Olivier},
issn = {2168-8966},
journal = {The Annals of Statistics},
keywords = {Spectral Clustering,Spectral clustering,consistency,convergence of eigenvectors,graph Laplacian},
mendeley-tags = {Spectral Clustering},
month = {apr},
number = {2},
pages = {555--586},
publisher = {Institute of Mathematical Statistics},
title = {Consistency of spectral clustering},
url = {http://projecteuclid.org/euclid.aos/1205420511},
volume = {36},
year = {2008}
}
@article{Saligrama2010,
abstract = {This article describes a family of unsupervised approaches to video anomaly detection based on statistical activity analysis. Approaches based on activity analysis provide intriguing possibilities for region-of-interest (ROI) processing since relevant activities and their locations are detected prior to higher-level processing such as object tracking, tagging, and classification. This strategy is essential for scalability of video analysis to cluttered environments with a multitude of objects and activities. Activity analysis approaches typically do not involve object tracking, and yet they inherently account for spatiotemporal dependencies. They are robust to clutter arising from multiple activities and contamination arising from poor background subtraction or occlusions. They can sometimes also be employed for fusing activities from multiple cameras. We illustrate successful application of activity analysis to anomaly detection in various scenarios, including the detection of abandoned objects, crowds of people, and illegal U-turns.},
author = {Saligrama, Venkatesh and Konrad, Janusz and Jodoin, Pierre Marc},
doi = {10.1109/MSP.2010.937393},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saligrama, Konrad, Jodoin - 2010 - Video anomaly identification.pdf:pdf},
isbn = {1053-5888},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
number = {5},
pages = {18--33},
title = {Video anomaly identification},
url = {http://ieeexplore.ieee.org/xpls/abs{\{}{\_}{\}}all.jsp?arnumber=5562666 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5562666},
volume = {27},
year = {2010}
}
@article{Cappe2009,
abstract = {In this contribution, we propose a generic online (also sometimes called adaptive or recursive) version of the Expectation-Maximisation (EM) algorithm applicable to latent variable models of independent observations. Compared to the algorithm of Titterington (1984), this approach is more directly connected to the usual EM algorithm and does not rely on integration with respect to the complete data distribution. The resulting algorithm is usually simpler and is shown to achieve convergence to the stationary points of the Kullback-Leibler divergence between the marginal distribution of the observation and the model distribution at the optimal rate, i.e., that of the maximum likelihood estimator. In addition, the proposed approach is also suitable for conditional (or regression) models, as illustrated in the case of the mixture of linear regressions model.},
archivePrefix = {arXiv},
arxivId = {0712.4273},
author = {Capp{\'{e}}, Olivier and Moulines, Eric},
doi = {10.1111/j.1467-9868.2009.00698.x},
eprint = {0712.4273},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Capp{\'{e}}, Moulines - 2009 - On-line expectation-maximization algorithm for latent data models.pdf:pdf},
isbn = {1467-9868},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Adaptive algorithms,Expectation-maximization,Latent data models,Mixture of regressions,On-line estimation,Polyak-Ruppert averaging,Stochastic approximation},
month = {jun},
number = {3},
pages = {593--613},
title = {On-line expectation-maximization algorithm for latent data models},
url = {http://arxiv.org/abs/0712.4273},
volume = {71},
year = {2009}
}
@incollection{Studenmund2005f,
address = {London},
author = {Studenmund, A H},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {7},
edition = {Fifth},
editor = {Clinton, Denise},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {7. Specification: Choosing a Functional Form},
year = {2005}
}
@article{Candes2007,
author = {Cand{\`{e}}s, Emmanuel and Romberg, Justin},
doi = {10.1088/0266-5611/23/3/008},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cand{\`{e}}s, Romberg - 2007 - Sparsity and incoherence in compressive sampling.pdf:pdf},
issn = {0266-5611},
journal = {Inverse Problems},
month = {jun},
number = {3},
pages = {969--985},
title = {Sparsity and incoherence in compressive sampling},
url = {http://stacks.iop.org/0266-5611/23/i=3/a=008?key=crossref.bdb1d0e3390f5616a4395b50273198a9},
volume = {23},
year = {2007}
}
@article{Pudlewski2012,
author = {Pudlewski, Scott and Prasanna, Arvind and Melodia, Tommaso},
doi = {10.1109/TMC.2011.175},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pudlewski, Prasanna, Melodia - 2012 - Compressed-Sensing-Enabled Video Streaming for Wireless Multimedia Sensor Networks.pdf:pdf},
issn = {1536-1233},
journal = {IEEE Transactions on Mobile Computing},
month = {jun},
number = {6},
pages = {1060--1072},
title = {Compressed-Sensing-Enabled Video Streaming for Wireless Multimedia Sensor Networks},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6188348},
volume = {11},
year = {2012}
}
@article{Ning2007,
abstract = {In recent years, spectral clustering method has gained attentions because of its superior performance compared to other traditional clustering algorithms such as K-means algorithm. The existing spectral clustering algorithms are all off-line algorithms, i.e., they can not incrementally update the clustering result given a small change of the data set. However, the capability of incrementally updating is essential to some applications such as real time monitoring of the evolving communities of websphere or blogsphere. Unlike traditional stream data, these applications require incremental algorithms to handle not only insertion/deletion of data points but also similarity changes between existing items. This paper extends the standard spectral clustering to such evolving data by introducing the incidence vector/matrix to represent two kinds of dynamics in the same framework and by incrementally updating the eigenvalue system. Our incremental algorithm, initialized by a standard spectral clustering, continuously and efficiently updates the eigenvalue system and generates instant cluster labels, as the data set is evolving. The algorithm is applied to a blog data set. Compared with recomputation of the solution by standard spectral clustering, it achieves similar accuracy but with much lower computational cost. Close inspection into the blog content shows that the incremental approach can discover not only the stable blog communities but also the evolution of the individual multi-topic blogs.},
author = {Ning, Huazhong and Xu, W and Chi, Y and Gong, Y and Huang, T S},
isbn = {9780898716306},
journal = {SIAM International Conference on Data Mining},
keywords = {Spectral Clustering,incidence vector,incremental clustering,matrix,spectral clus-,tering,web-blogs},
language = {en},
mendeley-tags = {Spectral Clustering},
pages = {261--272},
title = {Incremental Spectral Clustering With Application to Monitoring of Evolving Blog Communities.},
url = {http://www.appliedmathematician.org/proceedings/datamining/2007/dm07{\_}024Ning.pdf},
year = {2007}
}
@article{Mei2011,
abstract = {In this paper, we propose a robust visual tracking method by casting tracking as a sparse approximation problem in a particle filter framework. In this framework, occlusion, noise, and other challenging issues are addressed seamlessly through a set of trivial templates. Specifically, to find the tracking target in a new frame, each target candidate is sparsely represented in the space spanned by target templates and trivial templates. The sparsity is achieved by solving an l1-regularized least-squares problem. Then, the candidate with the smallest projection error is taken as the tracking target. After that, tracking is continued using a Bayesian state inference framework. Two strategies are used to further improve the tracking performance. First, target templates are dynamically updated to capture appearance changes. Second, nonnegativity constraints are enforced to filter out clutter which negatively resembles tracking targets. We test the proposed approach on numerous sequences involving different types of challenges, including occlusion and variations in illumination, scale, and pose. The proposed approach demonstrates excellent performance in comparison with previously proposed trackers. We also extend the method for simultaneous tracking and recognition by introducing a static template set which stores target images from different classes. The recognition result at each frame is propagated to produce the final result for the whole video. The approach is validated on a vehicle tracking and classification task using outdoor infrared video sequences.},
author = {Mei, Xue and Ling, Haibin},
doi = {10.1109/TPAMI.2011.66},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mei, Ling - 2011 - Robust visual tracking and vehicle classification via sparse representation.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = {nov},
number = {11},
pages = {2259--2272},
pmid = {21422491},
title = {Robust visual tracking and vehicle classification via sparse representation.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21422491},
volume = {33},
year = {2011}
}
@inproceedings{Williams2001,
abstract = {A major problem for kernel-based predictors (such as Support Vector Machines and Gaussian processes) is that the amount of computation required to find the solution scales as O(n ), where n is the number of training examples. We show that an approximation to the eigendecomposition of the Gram matrix can be computed by the Nystr{\"{o}}m method (which is used for the numerical solution of eigenproblems). This is achieved by carrying out an eigendecomposition on a smaller system of size m {\textless} n, and then expanding the results back up to n dimensions. The computational complexity of a predictor using this approximation is O(m n). We report experiments on the USPS and abalone data sets and show that we can set m n without any significant decrease in the accuracy of the solution.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Williams, Christopher and Seeger, Matthias},
booktitle = {Advances in Neural Information Processing Systems},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Williams, Seeger - 2001 - Using the Nystrom Method to Speed up Kernel Machines.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
pages = {682--688},
pmid = {25246403},
title = {Using the {Nystr{\"{o}}m} Method to Speed Up Kernel Machines},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.7519},
year = {2001}
}
@article{Ng2001,
abstract = {Despite many empirical successes of spectral clustering methods -- algorithms that cluster points using eigenvectors of matrices derived from the distances between the points -- there are several unresolved issues. First, there is a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.},
author = {Ng, Andrew Y and Jordan, Michael I and Weiss, Yair},
doi = {10.1.1.19.8100},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ng, Jordan, Weiss - 2001 - On Spectral Clustering Analysis and an algorithm.pdf:pdf},
isbn = {0818619155},
journal = {Advances in Neural Information Processing Systems},
keywords = {Spectral Clustering},
mendeley-tags = {Spectral Clustering},
pages = {849--856},
title = {On Spectral Clustering: Analysis and an algorithm},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100{\&}rank=1},
year = {2001}
}
@article{Wang2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1105.4408v1},
author = {Wang, Jian and Shim, Byonghyo},
eprint = {arXiv:1105.4408v1},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Shim - 2011 - A Simple Proof of the Mutual Incoherence Condition for Orthogonal Matching Pursuit.pdf:pdf},
journal = {arXiv preprint arXiv:1105.4408},
number = {2010},
title = {A Simple Proof of the Mutual Incoherence Condition for Orthogonal Matching Pursuit},
url = {http://arxiv.org/abs/1105.4408},
year = {2011}
}
@article{Maddalena2008,
abstract = {Detection of moving objects in video streams is the first relevant step of information extraction in many computer vision applications. Aside from the intrinsic usefulness of being able to segment video streams into moving and background components, detecting moving objects provides a focus of attention for recognition, classification, and activity analysis, making these later steps more efficient. We propose an approach based on self organization through artificial neural networks, widely applied in human image processing systems and more generally in cognitive science. The proposed approach can handle scenes containing moving backgrounds, gradual illumination variations and camouflage, has no bootstrapping limitations, can include into the background model shadows cast by moving objects, and achieves robust detection for different types of videos taken with stationary cameras. We compare our method with other modeling techniques and report experimental results, both in terms of detection accuracy and in terms of processing speed, for color video sequences that represent typical situations critical for video surveillance systems.},
author = {Maddalena, Lucia and Petrosino, Alfredo},
doi = {10.1109/TIP.2008.924285},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maddalena, Petrosino - 2008 - A self-organizing approach to background subtraction for visual surveillance applications.pdf:pdf},
issn = {1057-7149},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Algorithms,Automated,Automated: methods,Computer-Assisted,Computer-Assisted: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation,Pattern Recognition,Reproducibility of Results,Security Measures,Sensitivity and Specificity,Subtraction Technique},
month = {jul},
number = {7},
pages = {1168--77},
pmid = {18586624},
title = {A self-organizing approach to background subtraction for visual surveillance applications.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18586624},
volume = {17},
year = {2008}
}
@article{Friedman,
author = {Friedman, Nir and Russell, Stuart},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friedman, Russell - Unknown - Image segmentation in video sequences A probabilistic approach.pdf:pdf},
keywords = {em,image processing,segmentation,shadows,video processing},
pages = {1--13},
title = {Image segmentation in video sequences : A probabilistic approach}
}
@techreport{Laney2001,
abstract = {3D Data Management: Controlling Data Volume, Velocity, and Variety. Current business conditions and mediums are pushing traditional data management principles to their limits, giving rise to novel, more formalized approaches. META Trend: During 2001/02, leading enterprises will increasingly use a centralized data warehouse to define a common business vocabulary that improves internal and external collaboration. Through 2003/04, data quality and integration woes will be tempered by data profiling technologies (for generating metadata, consolidated schemas, and integration logic) and information logistics agents. By 2005/06, data, document, and knowledge management will coalesce, driven by schema-agnostic indexing strategies and portal maturity.},
author = {Laney, Doug},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laney - 2001 - 3-D Data Management Controlling Data Volume, Velocity and Variety.pdf:pdf},
institution = {META Group Research Note},
title = {3-D Data Management: Controlling Data Volume, Velocity and Variety},
year = {2001}
}
@article{Ester1996,
author = {Ester, Martin and Kriegel, Hans-Peter and Sander, J{\"{o}}rg and Xu, Xiaowei},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ester et al. - 1996 - A density-based algorithm for discovering clusters in large spatial databases with noise.pdf:pdf},
journal = {Proceedings of the Second International Conference on Knowledge Discovery and Data Mining},
title = {A density-based algorithm for discovering clusters in large spatial databases with noise},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.121.9220},
year = {1996}
}
@article{Zelnik-Manor2004,
abstract = {We study a number of open issues in spectral clustering: (i) Selecting the appropriate scale of analysis, (ii) Handling multi-scale data, (iii) Clustering with irregular background clutter, and, (iv) Finding automatically the number of groups. We first propose that a ‘local ' scale should be used to compute the affinity between each pair of points. This local scaling leads to better clustering especially when the data includes multiple scales and when the clusters are placed within a cluttered background. We further suggest exploiting the structure of the eigenvectors to infer automatically the number of groups. This leads to a new algorithm in which the final randomly initialized k-means stage is eliminated. 1},
author = {Zelnik-manor, Lihi and Perona, Pietro},
doi = {10.1.1.84.7940},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zelnik-manor et al. - 2004 - Self-tuning spectral clustering.pdf:pdf},
isbn = {9780769535081},
journal = {Advances in Neural Information Processing Systems},
keywords = {Spectral Clustering},
mendeley-tags = {Spectral Clustering},
pages = {1601--1608},
title = {Self-tuning spectral clustering},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.84.7940},
year = {2004}
}
@article{Fiedler1973,
abstract = {(not listed)},
author = {Fieldler, Miroslav},
doi = {10.1080/03081080500054810},
issn = {0011-4642},
journal = {Czechoslovak Mathematical Jornal},
keywords = {Spectral Clustering},
language = {eng},
mendeley-tags = {Spectral Clustering},
number = {2},
pages = {298--305},
publisher = {Institute of Mathematics, Academy of Sciences of the Czech Republic},
title = {Algebraic Connectivity of Graphs},
url = {https://eudml.org/doc/12723},
volume = {23},
year = {1973}
}
@article{Cevher2008b,
author = {Cevher, Volkan and Sankaranarayanan, Aswin},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cevher, Sankaranarayanan - 2008 - Compressive sensing for background subtraction.pdf:pdf},
journal = {European Conference on Computer Vision},
pages = {155--168},
title = {Compressive sensing for background subtraction},
url = {http://link.springer.com/chapter/10.1007/978-3-540-88688-4{\{}{\_}{\}}12 http://link.springer.com/chapter/10.1007/978-3-540-88688-4{\_}12},
year = {2008}
}
@article{Dasgupta2003,
author = {Dasgupta, Sanjoy and Gupta, Anupam},
doi = {10.1002/rsa.10073},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dasgupta, Gupta - 2003 - An elementary proof of a theorem of Johnson and Lindenstrauss.pdf:pdf},
issn = {1042-9832},
journal = {Random Structures and Algorithms},
month = {jan},
number = {1},
pages = {60--65},
title = {An elementary proof of a theorem of Johnson and Lindenstrauss},
url = {http://doi.wiley.com/10.1002/rsa.10073},
volume = {22},
year = {2003}
}
@article{Donath1973,
abstract = {Let a k-partition of a graph be a division of the vertices into k disjoint subsets containing m1 ≥ m2, {\ldots}, ≥ mk vertices. Let Ec be the number of edges whose two vertices belong to different subsets. Let $\lambda$1 ≥ $\lambda$2, {\ldots}, ≥ $\lambda$k be the k largest eigenvalues of a matrix, which is the sum of the adjacency matrix of the graph plus any diagonal matrix U such that the sum of all the elements of the sum matrix is zero. Then given equation. A theorem is given that shows the effect of the maximum degree of any node being limited, and it is also shown that the right-hand side is a concave function of U. Computational studies are made of the ratio of upper bound to lower bound for the two-partition of a number of random graphs having up to 100 nodes.},
author = {Donath, W. E. and Hoffman, A. J.},
doi = {10.1147/rd.175.0420},
issn = {0018-8646},
journal = {IBM Journal of Research and Development},
month = {sep},
number = {5},
pages = {420--425},
publisher = {IBM Corp.},
title = {Lower Bounds for the Partitioning of Graphs},
url = {http://dl.acm.org/citation.cfm?id=1664638.1664644},
volume = {17},
year = {1973}
}
@inproceedings{Alpert1995,
abstract = {A spectral partitioning method uses the eigenvectors of a graph's adjacency or Laplacian matrix to construct a geometric representation (e.g., a linear ordering) which is then heuristically partitioned. We map each graph vertex to a vector in d-dimensional space, where d is the number of eigenvectors, such that these vectors constitute an instance of the vector partitioning problem. When all the eigenvectors are used, graph partitioning exactly reduces to vector partitioning. This result motivates a simple ordering heuristic that can be used to yield high-quality 2-way and multi-way partitionings. Our experiments suggest the vector partitioning perspective opens the door to new and effective heuristics.},
author = {Alpert, So-Zen Yao Charles J.},
booktitle = {32nd Design Automation Conference},
doi = {10.1109/DAC.1995.250089},
isbn = {0-89791-725-1},
issn = {0738-100X},
keywords = {Computer science,Costs,Dynamic programming,Laplace equations,Partitioning algorithms,Upper bound,Vectors},
language = {English},
month = {dec},
pages = {195--200},
publisher = {ACM},
title = {Spectral Partitioning: The More Eigenvectors, The Better},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1586701},
year = {1995}
}
@incollection{Studenmund2005i,
address = {London},
author = {Studenmund, A H},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {10-12},
edition = {Fifth},
editor = {Clinton, Denise},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {345--433},
publisher = {Pearson Education, Inc.},
title = {10-12. Heteroskedasticity.},
year = {2005}
}
@article{Talavera2013,
author = {Talavera, Juan O},
journal = {Revista Medica del Instituto Mexicano del Seguro Social},
number = {Supl},
pages = {S10----S15},
title = {{I . Dise{\{}{\~{n}}{\}}os de investigaci{\{}{\'{o}}{\}}n}},
volume = {51},
year = {2013}
}
@inproceedings{Lu2013,
author = {Lu, Cewu and Shi, Jiaping and Jia, Jiaya},
booktitle = {2013 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2013.60},
isbn = {978-0-7695-4989-7},
issn = {1063-6919},
keywords = {Computer vision,Dictionaries,Dictionary Learning,History,Linear systems,Online Learning,Robust Statistics,Robustness,Signal to noise ratio,Training data,data handling,dynamic data processing,large-scale data processing,learning (artificial intelligence),online robust dictionary learning,sparse data fitting term,square data fitting term},
language = {English},
month = {jun},
pages = {415--422},
publisher = {IEEE},
title = {Online Robust Dictionary Learning},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6618904},
year = {2013}
}
@article{Hanley1983,
author = {Hanley, JA and McNeil, BJ},
journal = {Radiology},
month = {sep},
number = {3},
pages = {839--843},
title = {A method of comparing the areas under receiver operating characteristic curves derived from the same cases},
url = {http://radiology.rsna.org/content/148/3/839.abstract},
volume = {148},
year = {1983}
}
@incollection{Eckley2011b,
address = {Cambridge},
author = {Eckley, Idris A. and Fearnhead, Paul and Killick, Rebecca},
booktitle = {Bayesian Time Series Models},
chapter = {10},
doi = {10.1017/CBO9780511984679.011},
editor = {Barber, David and Cemgil, A. Taylan and Chiappa, Silvia},
pages = {205--224},
publisher = {Cambridge University Press},
title = {Analysis of changepoint models},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511984679A085},
year = {2011}
}
@article{Zhang1996a,
author = {Zhang, Tian and Ramakrishnan, Raghu and Livny, Miron},
doi = {10.1145/235968.233324},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Ramakrishnan, Livny - 1996 - BIRCH An Efficient Data Clustering Method for Very Large Databases.pdf:pdf},
isbn = {0-89791-794-4},
issn = {01635808},
journal = {ACM SIGMOD Record},
month = {jun},
number = {2},
pages = {103--114},
publisher = {ACM},
title = {BIRCH: An Efficient Data Clustering Method for Very Large Databases},
url = {http://dl.acm.org/citation.cfm?id=235968.233324},
volume = {25},
year = {1996}
}
@article{Duarte2008,
author = {Duarte, Marco F. and Wakin, Michael B. and Baraniuk, Richard G.},
doi = {10.1109/ICASSP.2008.4518815},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duarte, Wakin, Baraniuk - 2008 - Wavelet-domain compressive signal reconstruction using a Hidden Markov Tree model.pdf:pdf},
isbn = {978-1-4244-1483-3},
issn = {1520-6149},
journal = {Acoustics, Speech and Signal Processing},
month = {mar},
pages = {5137--5140},
title = {Wavelet-domain compressive signal reconstruction using a Hidden Markov Tree model},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4518815},
year = {2008}
}
@article{Bhaskar2013,
author = {Bhaskar, Harish and Mihaylova, Lyudmila and Maskell, Simon},
doi = {10.1016/j.neucom.2011.12.039},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhaskar, Mihaylova, Maskell - 2013 - Articulated human body parts detection based on cluster background subtraction and foreground match.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Genetic algorithm,Optimisation,Pictorial structures,background subtraction,human target tracking},
month = {jan},
pages = {58--73},
publisher = {Elsevier},
title = {Articulated human body parts detection based on cluster background subtraction and foreground matching},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0925231212003165},
volume = {100},
year = {2013}
}
@incollection{Studenmund2005g,
address = {London},
author = {Studenmund, A H},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {8},
edition = {Fifth},
editor = {Clinton, Denise},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {8. Multicollinearity},
year = {2005}
}
@article{Hofmeyr2015,
abstract = {We study the problem of determining the optimal low dimensional projection for maximising the separability of a binary partition of an unlabelled dataset, as measured by spectral graph theory. This is achieved by finding projections which minimise the second eigenvalue of the Laplacian matrices of the projected data, which corresponds to a non-convex, non-smooth optimisation problem. We show that the optimal univariate projection based on spectral connectivity converges to the vector normal to the maximum margin hyperplane through the data, as the scaling parameter is reduced to zero. This establishes a connection between connectivity as measured by spectral graph theory and maximal Euclidean separation. It also allows us to apply our methodology to the problem of finding large margin linear separators. The computational cost associated with each eigen-problem is quadratic in the number of data. To mitigate this problem, we propose an approximation method using microclusters with provable approximation error bounds. We evaluate the performance of the proposed method on a large collection of benchmark datasets and find that it compares favourably with existing methods for projection pursuit and dimension reduction for unsupervised data partitioning.},
archivePrefix = {arXiv},
arxivId = {1509.01546},
author = {Hofmeyr, David P. and Pavlidis, Nicos G. and Eckley, Idris A.},
eprint = {1509.01546},
month = {sep},
title = {Minimum Spectral Connectivity Projection Pursuit for Unsupervised Classification},
url = {http://arxiv.org/abs/1509.01546},
year = {2015}
}
@article{Tibshirani1996,
author = {Tibshirani, R},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tibshirani - 1996 - Regression shrinkage and selection via the lasso.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B},
pages = {267--288},
title = {Regression shrinkage and selection via the lasso},
url = {http://www.jstor.org/stable/10.2307/2346178},
year = {1996}
}
@article{Huang2008,
abstract = {Spectral clustering is useful for a wide-ranging set of applications in areas such as biological data analysis, image processing and data mining. However, the com-putational and/or communication resources required by the method in processing large-scale data are often prohibitively high, and practitioners are often required to perturb the original data in various ways (quantization, downsampling, etc) before invoking a spectral algorithm. In this paper, we use stochastic perturbation theory to study the effects of data perturbation on the performance of spectral clustering. We show that the error under perturbation of spectral clustering is closely related to the perturbation of the eigenvectors of the Laplacian matrix. From this result we derive approximate upper bounds on the clustering error. We show that this bound is tight empirically across a wide range of problems, suggesting that it can be used in practical settings to determine the amount of data reduction allowed in order to meet a specification of permitted loss in clustering performance.},
author = {Huang, Ling and Yan, Donghui and Taft, Nina and Jordan, Michael I.},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2008 - Spectral clustering with perturbed data(2).pdf:pdf},
isbn = {9781605609492},
journal = {Advances in Neural Information Processing Systems},
pages = {705--712},
title = {Spectral clustering with perturbed data},
year = {2008}
}
@inproceedings{Yan2009,
abstract = {Human cognition is characterized by three important features: productivity, dynamics and grounding. These features can be integrated in a neural architecture. The representations in this architecture are not symbol tokens, that can be copied and transported. Instead, the representations always remain "in situ", because they are grounded in perception, action, emotion, associations and (semantic) relations. The neural architecture shows how these representations can be combined in a productive manner, and how dynamics influences this process. The constraints that each of these features impose on each other could result in an architecture in which the local and the global aspects of cognition interact in processing and learning.},
author = {Yan, Donghui and Huang, Ling and Jordan, Michael I},
booktitle = {Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/1557019.1557118},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yan, Huang, Jordan - 2009 - Fast approximate spectral clustering.pdf:pdf},
isbn = {9781605584959},
issn = {10987576},
keywords = {Spectral Clustering,data quantization,spectral clustering,unsupervised learning},
mendeley-tags = {Spectral Clustering},
month = {jun},
pages = {907--916},
title = {Fast approximate spectral clustering},
url = {http://portal.acm.org/citation.cfm?doid=1557019.1557118},
year = {2009}
}



@article{Silva2013,
abstract = {Data stream mining is an active research area that has recently emerged to discover knowledge from large amounts of continuously generated data. In this context, several data stream clustering algorithms have been proposed to perform unsupervised learning. Nevertheless, data stream clustering imposes several challenges to be addressed, such as dealing with nonstationary, unbounded data that arrive in an online fashion. The intrinsic nature of stream data requires the development of algorithms capable of performing fast and incremental processing of data objects, suitably addressing time and memory limitations. In this article, we present a survey of data stream clustering algorithms, providing a thorough discussion of the main design components of state-of-the-art algorithms. In addition, this work addresses the temporal aspects involved in data stream clustering, and presents an overview of the usually employed experimental methodologies. A number of references are provided that describe applications of data stream clustering in different domains, such as network intrusion detection, sensor networks, and stock market analysis. Information regarding software packages and data repositories are also available for helping researchers and practitioners. Finally, some important issues and open questions that can be subject of future research are discussed.},
author = {Silva, Jonathan A and Faria, Elaine R and Barros, Rodrigo C and Hruschka, Eduardo R and de Carvalho, Andr{\'{e}} C P L F  and Gama, Jo{\~{a}}o},
doi = {10.1145/2522968.2522981},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silva et al. - 2013 - Data stream clustering.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
keywords = {Data stream clustering,online clustering},
number = {1},
pages = {1--31},
title = {Data stream clustering},
url = {http://doi.acm.org/10.1145/2522968.2522981$\backslash$nhttp://dl.acm.org/citation.cfm?doid=2522968.2522981},
volume = {46},
year = {2013}
}
@article{Malik2000,
abstract = {We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We applied this approach to segmenting static images, as well as motion sequences, and found the results to be very encouraging http://repository.upenn.edu/cis{\_}papers/107},
archivePrefix = {arXiv},
arxivId = {cs/0703101v1},
author = {Shi, Jianbo and Malik, Jitendra},
doi = {10.1109/34.868688},
eprint = {0703101v1},
isbn = {0-8186-7822-4},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Bayesian methods,Brightness,Clustering algorithms,Coherence,Data mining,Eigenvalues and eigenfunctions,Filling,Image segmentation,Partitioning algorithms,Spectral Clustering,Tree data structures,computer vision,dissimilarity,eigenvalues,eigenvalues and eigenfunctions,graph partitioning,graph theory,image segmentation,image sequences,normalized cut,perceptual grouping,similarity},
mendeley-tags = {Spectral Clustering},
number = {8},
pages = {888--905},
pmid = {15742889},
primaryClass = {cs},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {Normalized cuts and image segmentation},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=868688},
volume = {22},
year = {2000}
}
@inproceedings{Valgren2007,
abstract = {This paper presents a novel use of spectral clustering algorithms to support cases where the entries in the affinity matrix are costly to compute. The method is incremental - the spectral clustering algorithm is applied to the affinity matrix after each row/column is added - which makes it possible to inspect the clusters as new data points are added. The method is well suited to the problem of appearance-based, on-line topological mapping for mobile robots. In this problem domain, we show that we can reduce environment-dependent parameters of the clustering algorithm to just a single, intuitive parameter. Experimental results in large outdoor and indoor environments show that we can close loops correctly by computing only a fraction of the entries in the affinity matrix. The accompanying video clip shows how an example map is produced by the algorithm.},
author = {Valgren, Christoffer and Duckett, Tom and Lilienthal, Achim},
booktitle = {Proceedings 2007 IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2007.364138},
isbn = {1-4244-0602-1},
issn = {1050-4729},
keywords = {Clustering algorithms,Clustering methods,Computer vision,Fingerprint recognition,Indoor environments,Informatics,Mobile robots,Robotics and automation,Sensor systems,Spectral Clustering,Speech recognition,affinity matrix,appearance-based online topological mapping,incremental spectral clustering,mobile robots,pattern clustering,topology},
mendeley-tags = {Spectral Clustering},
month = {apr},
pages = {4283--4288},
publisher = {IEEE},
shorttitle = {Robotics and Automation, 2007 IEEE International C},
title = {Incremental Spectral Clustering and Its Application To Topological Mapping},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4209756},
year = {2007}
}
@article{Kristan2011,
abstract = {We propose a novel approach to online estimation of probability density functions, which is based on kernel density estimation (KDE). The method maintains and updates a non-parametric model of the observed data, from which the KDE can be calculated. We propose an online bandwidth estimation approach and a compression/revitalization scheme which maintains the KDE's complexity low. We compare the proposed online KDE to the state-of-the-art approaches on examples of estimating stationary and non-stationary distributions, and on examples of classification. The results show that the online KDE outperforms or achieves a comparable performance to the state-of-the-art and produces models with a significantly lower complexity while allowing online adaptation. {\{}{\textcopyright}{\}} 2011 Elsevier Ltd. All rights reserved.},
author = {Kristan, Matej and Leonardis, Ale{\v{s}} and Sko{\v{c}}aj, Danijel},
doi = {10.1016/j.patcog.2011.03.019},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kristan, Leonardis, Sko{\v{c}}aj - 2011 - Multivariate online kernel density estimation with Gaussian kernels.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Gaussian mixture models,Kernel density estimation,Online models,Probability density estimation},
month = {oct},
number = {10-11},
pages = {2630--2642},
title = {Multivariate online kernel density estimation with Gaussian kernels},
url = {http://www.sciencedirect.com/science/article/pii/S0031320311001233},
volume = {44},
year = {2011}
}
@inproceedings{Molenaar2011,
author = {Molenaar, Mathieu M. and Hill, David and Webster, Paul and Fidan, Erkan and Birch, Bill},
booktitle = {SPE Hydraulic Fracturing Technology Conference},
doi = {10.2118/140561-MS},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Molenaar et al. - 2011 - First Downhole Application of Distributed Acoustic Sensing (DAS) for Hydraulic Fracturing Monitoring and Diagno.pdf:pdf},
isbn = {978-1-55563-321-9},
month = {apr},
publisher = {Society of Petroleum Engineers},
title = {First Downhole Application of Distributed Acoustic Sensing (DAS) for Hydraulic Fracturing Monitoring and Diagnostics},
url = {http://www.onepetro.org/doi/10.2118/140561-MS},
year = {2011}
}
@article{Aguilar-Barojas2005,
abstract = {En la investigaci{\{}{\'{o}}{\}}n en salud, es muy dif{\{}{\'{i}}{\}}cil estudiar a toda la poblaci{\{}{\'{o}}{\}}n que presenta la variable de inter{\{}{\'{e}}{\}}s, por lo que es necesario realizar un muestreo que resulte representativo de la poblaci{\{}{\'{o}}{\}}n objetivo. El c{\{}{\'{a}}{\}}lculo de la muestra permite responder a la pregunta del investigador de ¿cu{\{}{\'{a}}{\}}ntos individuos se deben considerar para estudiar un par{\{}{\'{a}}{\}}metro con un grado de confianza determinado? o ¿cu{\{}{\'{a}}{\}}ntos individuos se deben estudiar para detectar en los resultados de los dos grupos, una diferencia que sea estad{\{}{\'{i}}{\}}sticamente significativa? El art{\{}{\'{i}}{\}}culo realiza las consideraciones previas sobre la profundidad del estudio y las variables. Presenta las f{\{}{\'{o}}{\}}rmulas para calcular muestras con variables cualitativas y cuantitativas para estudios descriptivos y explicativos. En estos {\{}{\'{u}}{\}}ltimos, cuando se utilizan las pruebas de contrastaci{\{}{\'{o}}{\}}n de hip{\{}{\'{o}}{\}}tesis m{\{}{\'{a}}{\}}s comunes, como son la Chi cuadrada, la t de student y el coeficiente de correlaci{\{}{\'{o}}{\}}n de Pearson.},
archivePrefix = {arXiv},
arxivId = {1405-2091},
author = {Aguilar-Barojas, S},
eprint = {1405-2091},
journal = {Salud en Tabasco},
keywords = {SRA,c{\{}{\'{a}}{\}}lculo de muestra,f{\{}{\'{o}}{\}}rmulas,investigaci{\{}{\'{o}}{\}}n en salud,muestra,representativa,s},
mendeley-tags = {SRA},
number = {1-2},
pages = {333--338},
title = {{F{\{}{\'{o}}{\}}rmulas para el c{\{}{\'{a}}{\}}lculo de la muestra en investigaciones de salud}},
url = {http://www.redalyc.org/articulo.oa?id=48711206},
volume = {11},
year = {2005}
}
@article{Szalkai2013,
abstract = {The original k-means clustering method works only if the exact vectors representing the data points are known. Therefore calculating the distances from the centroids needs vector operations, since the average of abstract data points is undefined. Existing algorithms can be extended for those cases when the sole input is the distance matrix, and the exact representing vectors are unknown. This extension may be named relational k-means after a notation for a similar algorithm invented for fuzzy clustering. A method is then proposed for generalizing k-means for scenarios when the data points have absolutely no connection with a Euclidean space.},
author = {Szalkai, Bal{\'{a}}zs},
keywords = {kmeans},
mendeley-tags = {kmeans},
month = {mar},
pages = {3},
title = {Generalizing k-means for an arbitrary distance matrix},
url = {http://arxiv.org/abs/1303.6001},
year = {2013}
}
@article{Page1954,
abstract = {In this study, the effect of powder cellulose (PC) and 2 types of microcrystalline cellulose (MCC 101 and MCC 301) on pellet properties produced by an extrusion/spheronization process was investigated. The different investigated types of cellulose displayed different behavior during the extrusion/spheronization process. Pure PC was unsuitable for extrusion, because too much water was required and the added water was partly squeezed during the extrusion process. In contrast, MCC 101 and MCC 301 were extrudable at a wide range of water content, but the quality of the resulting products varied. In the extrusion/spheronization process, MCC 101 was the best substance, with easy handling and acceptable product properties. The properties of the extrudates and pellets were determined by Fourier transform (FT) Raman spectroscopy and environmental scanning electron microscopy (ESEM). FT-Raman spectroscopy was able to distinguish between the original substances and also between the wet and dried extrudates. The particle sizes of the raw material and of the extrudates were determined by ESEM without additional preparation. For MCC, the size of the resulting particles within the extrudate or pellet was smaller. However, in the extrudates of PC, changes in particle size could not be observed. http://www.jstor.org/stable/2333009?origin=crossref},
author = {Page, Es},
doi = {10.2307/2333009},
isbn = {00063444},
issn = {00063444},
journal = {Biometrika},
month = {jun},
number = {1},
pages = {100--115},
title = {Continuous inspection schemes},
url = {http://www.jstor.org/stable/2333009?origin=crossref},
volume = {41},
year = {1954}
}
@article{Liu2005,
abstract = {This article reviews methodologies used for analyzing ordered categorical (ordinal) response variables. We begin by surveying models for data with a single ordinal response variable. We also survey recently proposed strategies for modeling ordinal response variables when the data have some type of clustering or when repeated measurement occurs at various occasions for each subject, such as in longitudinal studies. Primary models in that case include marginal models and cluster-specific (conditional) models for which effects apply conditionally at the cluster level. Re- lated discussion refers to multi-level and transitional models. The main empha- sis is on maximum likelihood inference, although we indicate certain models (e.g., marginal models,multi-level models) for which this can be computationally difficult. The Bayesian approach has also received considerable attention for categorical data in the past decade, and we survey recent Bayesian approaches to modeling ordinal response variables. Alternative, non-model-based, approaches are also available for certain types of inference.},
author = {Liu, Ivy and Agresti, A},
journal = {Test},
keywords = {contingency tables,ordinal,statistics},
mendeley-tags = {contingency tables,ordinal,statistics},
number = {1},
pages = {1--73},
publisher = {Springer},
title = {The Analysis of Ordered Categorical Data: An Overview and a Survey of Recent Developments},
url = {http://www.springerlink.com/index/vj250ju52484xj03.pdf},
volume = {14},
year = {2005}
}
@misc{Qaisar2013,
abstract = {Compressive sensing (CS) is a novel sampling paradigm that samples signals in a much more efficient way than the established Nyquist sampling theorem. CS has recently gained a lot of attention due to its exploitation of signal sparsity. Sparsity, an inherent characteristic of many natural signals, enables the signal to be stored in few samples and subsequently be recovered accurately, courtesy of CS. This article gives a brief background on the origins of this idea, reviews the basic mathematical foundation of the theory and then goes on to highlight different areas of its application with a major emphasis on communications and network domain. Finally, the survey concludes by identifying new areas of research where CS could be beneficial.},
author = {Qaisar, S. and Bilal, R.M. and Iqbal, W. and Naureen, M. and {Sungyoung Lee}},
doi = {10.1109/JCN.2013.000083},
issn = {1229-2370},
keywords = {CS,Compressive imaging,Nyquist sampling theorem,compressed sensing,compressive sensing,compressive sensing (CS),incoherence,mathematical analysis,mathematical foundation,signal sampling,signal sparsity exploitation,signals sampling paradigm,sparsity,wireless sensor networks (WSNs)},
number = {5},
pages = {443--456},
shorttitle = {Communications and Networks, Journal of},
title = {Compressive sensing: From theory to applications, a survey},
volume = {15},
year = {2013}
}
@article{Howland2013,
abstract = {We demonstrate a compressed sensing, photon counting lidar system based on the single-pixel camera. Our technique recovers both depth and intensity maps from a single under-sampled set of incoherent, linear projections of a scene of interest at ultra-low light levels around 0.5 picowatts. Only two-dimensional reconstructions are required to image a three-dimensional scene. We demonstrate intensity imaging and depth mapping at 256 x 256 pixel transverse resolution with acquisition times as short as 3 seconds. We also show novelty filtering, reconstructing only the difference between two instances of a scene. Finally, we acquire 32 x 32 pixel real-time video for three-dimensional object tracking at 14 frames-per-second.},
archivePrefix = {arXiv},
arxivId = {1309.4385},
author = {Howland, Gregory A. and Lum, Daniel J. and Ware, Matthew R. and Howell, John C.},
eprint = {1309.4385},
month = {sep},
pages = {16},
title = {Photon counting compressive depth mapping},
url = {http://arxiv.org/abs/1309.4385},
year = {2013}
}
@article{Pati1993,
author = {Pati, Y.C. C and Rezaiifar, R. and Krishnaprasad, P.S. S},
doi = {10.1109/ACSSC.1993.342465},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pati, Rezaiifar, Krishnaprasad - 1993 - Orthogonal matching pursuit recursive function approximation with applications to wavelet decomp.pdf:pdf},
isbn = {0-8186-4120-7},
journal = {Signals, Systems and Computers},
pages = {40--44},
publisher = {IEEE Comput. Soc. Press},
title = {Orthogonal matching pursuit: {Recursive} function approximation with applications to wavelet decomposition},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=342465},
year = {1993}
}
@article{Tuzel2005,
author = {Tuzel, O. and Porikli, F. and Meer, P.},
doi = {10.1109/CVPR.2005.384},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tuzel, Porikli, Meer - 2005 - A Bayesian Approach to Background Modeling.pdf:pdf},
isbn = {0-7695-2372-2},
journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops},
pages = {58},
publisher = {Ieee},
title = {A Bayesian Approach to Background Modeling},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1565362},
volume = {3},
year = {2005}
}
@article{Bartels2013,
author = {Bartels, Christian},
month = {dec},
title = {Positioning Bayesian inference as a particular application of frequentist inference and vice versa},
url = {http://figshare.com/articles/Positioning{\{}{\_}{\}}Bayesian{\{}{\_}{\}}inference{\{}{\_}{\}}as{\{}{\_}{\}}a{\{}{\_}{\}}particular{\{}{\_}{\}}application{\{}{\_}{\}}of{\{}{\_}{\}}frequentist{\{}{\_}{\}}inference{\{}{\_}{\}}and{\{}{\_}{\}}vice{\{}{\_}{\}}versa/867707},
year = {2013}
}
@book{McLachlan2000,
abstract = {An up-to-date, comprehensive account of major issues in finite mixture modeling This volume provides an up-to-date account of the theory and applications of modeling via finite mixture distributions. With an emphasis on the applications of mixture models in both mainstream analysis and other areas such as unsupervised pattern recognition, speech recognition, and medical imaging, the book describes the formulations of the finite mixture approach, details its methodology, discusses aspects of its implementation, and illustrates its application in many common statistical contexts. Major issues discussed in this book include identifiability problems, actual fitting of finite mixtures through use of the EM algorithm, properties of the maximum likelihood estimators so obtained, assessment of the number of components to be used in the mixture, and the applicability of asymptotic theory in providing a basis for the solutions to some of these problems. The author also considers how the EM algorithm can be scaled to handle the fitting of mixture models to very large databases, as in data mining applications. This comprehensive, practical guide: Provides more than 800 references-40{\%} published since 1995 Includes an appendix listing available mixture software Links statistical literature with machine learning and pattern recognition literature Contains more than 100 helpful graphs, charts, and tables Finite Mixture Models is an important resource for both applied and theoretical statisticians as well as for researchers in the many areas in which finite mixture models can be used to analyze data.},
author = {{McLachlan, G.J, Peel}, D.},
booktitle = {Technometrics},
doi = {10.1198/tech.2002.s651},
isbn = {0471006262},
issn = {0040-1706},
pages = {419},
pmid = {19219904},
publisher = {John Wiley {\&} Sons.},
title = {Finite Mixture Models},
url = {http://doi.wiley.com/10.1002/0471721182},
year = {2000}
}
@article{Barnich2011,
abstract = {This paper presents a technique for motion detection that incorporates several innovative mechanisms. For example, our proposed technique stores, for each pixel, a set of values taken in the past at the same location or in the neighborhood. It then compares this set to the current pixel value in order to determine whether that pixel belongs to the background, and adapts the model by choosing randomly which values to substitute from the background model. This approach differs from those based upon the classical belief that the oldest values should be replaced first. Finally, when the pixel is found to be part of the background, its value is propagated into the background model of a neighboring pixel. We describe our method in full details (including pseudo-code and the parameter values used) and compare it to other background subtraction techniques. Efficiency figures show that our method outperforms recent and proven state-of-the-art methods in terms of both computation speed and detection rate. We also analyze the performance of a downscaled version of our algorithm to the absolute minimum of one comparison and one byte of memory per pixel. It appears that even such a simplified version of our algorithm performs better than mainstream techniques.},
author = {Barnich, Olivier and {Van Droogenbroeck}, Marc},
doi = {10.1109/TIP.2010.2101613},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barnich, Van Droogenbroeck - 2011 - ViBe a universal background subtraction algorithm for video sequences.pdf:pdf},
issn = {1941-0042},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Computer-Assisted,Computer-Assisted: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation,Pattern Recognition,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,Subtraction Technique,Video Recording,Video Recording: methods},
month = {jun},
number = {6},
pages = {1709--24},
pmid = {21189241},
title = {ViBe: a universal background subtraction algorithm for video sequences.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21189241},
volume = {20},
year = {2011}
}
@article{Zhang2014,
abstract = {Crowdsourcing is a popular paradigm for effectively collecting labels at low cost. The Dawid-Skene estimator has been widely used for inferring the true labels from the noisy labels provided by non-expert crowdsourcing workers. However, since the estimator maximizes a non-convex log-likelihood function, it is hard to theoretically justify its performance. In this paper, we propose a two-stage efficient algorithm for multi-class crowd labeling problems. The first stage uses the spectral method to obtain an initial estimate of parameters. Then the second stage refines the estimation by optimizing the objective function of the Dawid-Skene estimator via the EM algorithm. We show that our algorithm achieves the optimal convergence rate up to a logarithmic factor. We conduct extensive experiments on synthetic and real datasets. Experimental results demonstrate that the proposed algorithm is comparable to the most accurate empirical approach, while outperforming several other recently proposed methods.},
archivePrefix = {arXiv},
arxivId = {1406.3824},
author = {Zhang, Yuchen and Chen, Xi and Zhou, Dengyong and Jordan, Michael I.},
eprint = {1406.3824},
keywords = {Spectral Clustering},
mendeley-tags = {Spectral Clustering},
month = {jun},
title = {Spectral Methods meet EM: A Provably Optimal Algorithm for Crowdsourcing},
url = {http://arxiv.org/abs/1406.3824},
year = {2014}
}
@inproceedings{Sivalingam2011,
abstract = {Background subtraction is a fundamental task in many computer vision applications, such as robotics and automated surveillance systems. The performance of high-level visions tasks such as object detection and tracking is dependent on effective foreground detection techniques. In this paper, we propose a novel background modeling algorithm that represents the background as a linear combination of dictionary atoms and the foreground as a sparse error, when one uses the respective set of dictionary atoms as basis elements to linearly approximate/reconstruct a new image. The dictionary atoms represent variations of the background model, and are learned from the training frames. The sparse foreground estimation during the training and performance phases is formulated as a Lasso [1] problem, while the dictionary update step in the training phase is motivated from the K-SVD algorithm [2]. Our proposed method works well in the presence of foreground in the training frames, and also gives the foreground masks for the training frames as a by-product of the batch training phase. Experimental validation is provided on standard datasets with ground truth information, and the receiver operating characteristic (ROC) curves are shown.},
author = {Sivalingam, Ravishankar and D'Souza, Alden and Bazakos, Michael and Miezianko, Roland},
booktitle = {2011 IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2011.5979981},
isbn = {978-1-61284-386-5},
issn = {1050-4729},
keywords = {Airports,Atmospheric modeling,Computational modeling,Dictionaries,K-SVD algorithm,Lasso problem,Lighting,Robustness,Training,background modeling algorithm,background subtraction,batch training phase,computer vision,dictionary atoms,dictionary learning,dictionary update step,ground truth information,high-level visions tasks,image reconstruction,learning (artificial intelligence),linear combination,receiver operating characteristic curves,sensitivity analysis,singular value decomposition,sparse error,sparse foreground estimation,standard datasets,training frames},
month = {may},
pages = {4234--4239},
publisher = {IEEE},
shorttitle = {Robotics and Automation (ICRA), 2011 IEEE Internat},
title = {Dictionary learning for robust background modeling},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5979981},
year = {2011}
}
@inproceedings{Sato2000b,
author = {Sato, M},
booktitle = {International Conference on Neural Information Processing},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sato - 2000 - Convergence of On-line EM Algorithm.ps:ps},
pages = {476--481},
title = {Convergence of On-line EM Algorithm},
url = {http://www.cns.atr.jp/{\{}{~}{\}}masaaki/paper/oem-conv.ps.gz http://www.cns.atr.jp/{~}masaaki/paper/oem-conv.ps.gz},
year = {2000}
}
@article{Elgammal2000,
author = {Elgammal, Ahmed and Harwood, David and Davis, Larry},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elgammal, Harwood, Davis - 2000 - Non-parametric model for background subtraction.pdf:pdf},
journal = {European Conference on Computer Vision},
keywords = {active and real time,motion detection,non-parametric estimation,shadow detection,vision,visual motion,visual surveillance},
pages = {751-767},
title = {Non-parametric model for background subtraction},
url = {http://link.springer.com/chapter/10.1007/3-540-45053-X{\{}{\_}{\}}48 http://link.springer.com/chapter/10.1007/3-540-45053-X{\_}48},
year = {2000}
}
@inproceedings{Liu2010,
abstract = {Compressed sensing is a novel technology to acquire and reconstruct signals below the Nyquist rate, and has great potential in image and video acquisition to explore the data redundancy and to significantly reduce the number of sampled data. In this paper, we explore the temporal redundancy in videos, and propose a block-based adaptive framework for compressed video sampling. It addresses the independent movement of different regions in a video, classifies blocks into different types depending on their inter-frame correlation, and adjusts the sampling and reconstruction strategies accordingly. Our framework also considers the diverse texture complexity of different regions, and adaptively adjusts the number of measurements collected for each region based on their sparsity. Our simulation results show that the proposed framework reduces the number of sampled measurements by 52{\%} to 80{\%} while still satisfying the quality constraint on the reconstructed frames. Compared to prior works, our proposed scheme improves the quality of the reconstructed frames and achieves a 0.8dB to 5.4dB gain in the average PSNR.},
author = {Liu, Zhaorui and Zhao, H. Vicky and Elezzabi, A. Y.},
booktitle = {2010 IEEE International Conference on Image Processing},
doi = {10.1109/ICIP.2010.5654000},
isbn = {978-1-4244-7992-4},
issn = {1522-4880},
keywords = {Complexity theory,Compressed sensing,Correlation,Current measurement,Image coding,Image reconstruction,PSNR,block-based adaptive framework,data redundancy,image acquisition,image sampling,signal detection,signal reconstruction,video acquisition,video coding,video sampling},
month = {sep},
pages = {1649--1652},
publisher = {IEEE},
shorttitle = {Image Processing (ICIP), 2010 17th IEEE Internatio},
title = {Block-based adaptive compressed sensing for video},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5654000},
year = {2010}
}
@article{Sato2000a,
abstract = {A normalized gaussian network (NGnet) (Moody {\&} Darken, 1989) is a network of local linear regression units. The model softly partitions the input space by normalized gaussian functions, and each local unit linearly approximates the output within the partition. In this article, we propose a new on-line EMalgorithm for the NGnet, which is derived from the batch EMalgorithm (Xu, Jordan, {\&}Hinton 1995), by introducing a discount factor. We show that the on-line EM algorithm is equivalent to the batch EM algorithm if a specific scheduling of the discount factor is employed. In addition, we show that the on-line EM algorithm can be considered as a stochastic approximation method to find the maximum likelihood estimator. A new regularization method is proposed in order to deal with a singular input distribution. In order to manage dynamic environments, where the input-output distribution of data changes over time, unit manipulation mechanisms such as unit production, unit deletion, and unit division are also introduced based on probabilistic interpretation. Experimental results show that our approach is suitable for function approximation problems in dynamic environments. We also apply our on-line EM algorithm to robot dynamics problems and compare our algorithm with the mixtures-of-experts family.},
author = {Sato, M and Ishii, S},
doi = {10.1162/089976600300015853},
issn = {0899-7667},
journal = {Neural computation},
month = {feb},
number = {2},
pages = {407--432},
pmid = {10636949},
publisher = {MIT Press},
title = {On-line EM algorithm for the normalized gaussian network.},
url = {http://dl.acm.org/citation.cfm?id=1121858.1121869},
volume = {12},
year = {2000}
}
@inproceedings{Velasquez2013,
author = {Velasquez, Guillermo and Kain, Jeff and Villamizar, Miguel and Yong, Zhou and Dhar, Joydeep and {Carvajal M}, Gustavo Adolfo and Goel, Harish K and Nasr, Hatem and Moricca, Giuseppe and Cullick, Alvin Stan and Bermudez, Fernando and Querales, Maiquel and Rodriguez, Jose Antonio and Al-Jasmi, Ahmad Khalid},
booktitle = {SPE Digital Energy Conference},
doi = {10.2118/163809-MS},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Velasquez et al. - 2013 - ESP {\&}quotSmart Flow{\&}quot Integrates Quality and Control Data for Diagnostics and Optimization in Real Time.pdf:pdf},
isbn = {978-1-61399-251-7},
month = {mar},
publisher = {Society of Petroleum Engineers},
title = {ESP "Smart Flow" Integrates Quality and Control Data for Diagnostics and Optimization in Real Time},
url = {http://www.onepetro.org/doi/10.2118/163809-MS},
year = {2013}
}
@article{Braumoeller2004,
abstract = {When a statistical equation incorporates a multiplicative term in an attempt to model interaction effects, the statistical significance of the lower-order coefficients is largely useless for the typical purposes of hypothesis testing. This fact remains largely unappreciated in political science, however. This brief article explains this point, provides examples, and offers some suggestions for more meaningful interpretation},
author = {Braumoeller, Bear F},
journal = {International Organization},
keywords = {Interaction effects,Multiplicative Models,Statistics},
mendeley-tags = {Interaction effects,Multiplicative Models,Statistics},
month = {oct},
number = {04},
pages = {807--820},
publisher = {Cambridge Univ Press},
title = {Hypothesis Testing and Multiplicative Interaction Terms},
url = {http://www.journals.cambridge.org/abstract{\{}{\_}{\}}S0020818304040251},
volume = {58},
year = {2004}
}
@article{Cook2008,
author = {Cook, Alex},
number = {August},
title = {Kaplan – Meier estimate of S ( t ) in R},
year = {2008}
}
@article{Anagnostopoulos2012,
author = {Anagnostopoulos, Christoforos and Tasoulis, Dimitris K. and Adams, Niall M. and Pavlidis, Nicos G. and Hand, David J.},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anagnostopoulos et al. - 2012 - Online linear and quadratic discriminant analysis with adaptive forgetting for streaming classification.pdf:pdf},
journal = {Statistical Analysis {\ldots}},
keywords = {arrive continually,computationally tractable analysis of,data that,for timely,forgetting factor,furthermore,in the context of,linear discriminant analysis,online,streaming data,super-,time-varying classification},
title = {Online linear and quadratic discriminant analysis with adaptive forgetting for streaming classification},
url = {http://onlinelibrary.wiley.com/doi/10.1002/sam.10151/full},
year = {2012}
}
@incollection{Studenmund2005e,
address = {London},
author = {Studenmund, A H},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {6},
edition = {Fifth},
editor = {Clinton, Denise},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {6. Specification: Choosing the Independent Variables.},
year = {2005}
}
@phdthesis{Pickering2015,
abstract = {This thesis considers the application of changepoint detection methodology for the analysis of acoustic sensing signals. In the first part, we propose a detection procedure for changes in the second-order structure of a univariate time series. This utilises a penalised likelihood based on Whittle's approximation and allows for a non-linear penalty function. This procedure is subsequently used to detect changes in acoustic sensing data which correspond to external disturbances of the measuring cable. The second part shifts focus to multivariate time series, and considers the detection of changes which occur in only a subset of the variables. We introduce the concept of changepoint vectors which we use to model such changes. A dynamic programming scheme is proposed which obtains the optimal configuration of changepoint vectors for a given multivariate series. Consideration of pruning techniques suggests that these are not practically viable for this setting. We therefore introduce approxima-tions which vastly improve computational speed with negligible detrimental impact on accuracy. This approximated procedure is applied to multivariate acoustic sensing data.},
author = {Pickering, Benjamin James},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pickering - 2015 - Changepoint Detection for Acoustic Sensing Signals.pdf:pdf},
school = {Lancaster University},
title = {Changepoint Detection for Acoustic Sensing Signals},
year = {2015}
}
@article{Toyama1999,
author = {Toyama, K. and Krumm, J. and Brumitt, B. and Meyers, B.},
doi = {10.1109/ICCV.1999.791228},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Toyama et al. - 1999 - Wallflower principles and practice of background maintenance.pdf:pdf},
isbn = {0-7695-0164-8},
journal = {Computer Vision},
pages = {255--261},
title = {Wallflower: {Principles} and practice of background maintenance},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=791228},
year = {1999}
}
@article{Tibshirani2001,
author = {Tibshirani, Robert and Walther, Guenther and Hastie, Trevor},
doi = {10.1111/1467-9868.00293},
issn = {1369-7412},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {Spectral Clustering},
mendeley-tags = {Spectral Clustering},
month = {may},
number = {2},
pages = {411--423},
title = {Estimating the number of clusters in a data set via the gap statistic},
url = {http://doi.wiley.com/10.1111/1467-9868.00293},
volume = {63},
year = {2001}
}
@misc{Preacher2004,
abstract = {This web page calculates simple intercepts and simple slopes, the region of significance, and computes specific values to facilitate the plotting of significant three-way interactions in ordinary least squares (OLS) regression. The interaction can be between any combination of dichotomous and continuous variables. We assume that the user is sufficiently knowledgeable in the testing, probing, and interpretation of interactions in multiple regression (e.g., Aiken {\{}{\&}{\}} West, 1991; Bauer {\{}{\&}{\}} Curran, 2004; Cohen, Cohen, West {\{}{\&}{\}} Aiken, 2003). A more extensive treatment of interaction effects can be found here. We further assume that the user has read the descriptions provided in support of the web page for probing a two-way interaction.},
author = {Preacher, Kristopher J (University Of North Carolina At Chapel Hill) and Curran, Patrick J (University Of North Carolina At Chapel Hill) and Bauer, Daniel J (University Of North Carolina At Chapel Hill)},
keywords = {3-Way Interactions,Interactions,Statistics},
mendeley-tags = {3-Way Interactions,Interactions,Statistics},
pages = {1--5},
title = {Simple Intercepts, Simple Slopes, and Regions of Significance in MLR 3-Way Interactions},
year = {2004}
}
@article{Li2004,
abstract = {This paper addresses the problem of background modeling for foreground object detection in complex environments. A Bayesian framework that incorporates spectral, spatial, and temporal features to characterize the background appearance is proposed. Under this framework, the background is represented by the most significant and frequent features, i.e., the principal features, at each pixel. A Bayes decision rule is derived for background and foreground classification based on the statistics of principal features. Principal feature representation for both the static and dynamic background pixels is investigated. A novel learning method is proposed to adapt to both gradual and sudden "once-off" background changes. The convergence of the learning process is analyzed and a formula to select a proper learning rate is derived. Under the proposed framework, a novel algorithm for detecting foreground objects from complex environments is then established. It consists of change detection, change classification, foreground segmentation, and background maintenance. Experiments were conducted on image sequences containing targets of interest in a variety of environments, e.g., offices, public buildings, subway stations, campuses, parking lots, airports, and sidewalks. Good results of foreground detection were obtained. Quantitative evaluation and comparison with the existing method show that the proposed method provides much improved results.},
author = {Li, Liyuan and Huang, Weimin and Gu, Irene Yu-Hua and Tian, Qi},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2004 - Statistical modeling of complex backgrounds for foreground object detection.pdf:pdf},
issn = {1057-7149},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Biological,Cluster Analysis,Computer Graphics,Computer Simulation,Computer-Assisted,Computer-Assisted: methods,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models,Numerical Analysis,Pattern Recognition,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,Statistical,Subtraction Technique},
month = {nov},
number = {11},
pages = {1459--1472},
pmid = {15540455},
title = {Statistical modeling of complex backgrounds for foreground object detection.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15540455},
volume = {13},
year = {2004}
}
@misc{Lu2010,
author = {Lu, Yifan and Wang, Lei and Hartley, Richard and Li, Hongdong and Xu, Dan},
booktitle = {Faculty of Engineering and Information Sciences - Papers},
pages = {1 -- 12},
title = {Compressive evaluation in human motion tracking},
url = {http://ro.uow.edu.au/eispapers/858},
year = {2010}
}
@book{Cleary2012,
author = {Cleary, Paul D and Crofton, Christine and Hays, Ron D and Horner, Ronnie},
booktitle = {Medical care},
doi = {10.1097/MLR.0b013e31826ec0cb},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cleary et al. - 2012 - Introduction.pdf:pdf},
isbn = {0001499106},
issn = {1537-1948},
month = {nov},
pages = {S1},
pmid = {23064270},
title = {Introduction.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23097130},
volume = {50 Suppl},
year = {2012}
}
@article{Cai2011,
author = {Cai, TT T and Wang, Lie},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai, Wang - 2011 - Orthogonal matching pursuit for sparse signal recovery with noise.pdf:pdf},
journal = {Information Theory, IEEE Transactions on},
number = {7},
pages = {4680--4688},
title = {Orthogonal matching pursuit for sparse signal recovery with noise},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5895106 http://ieeexplore.ieee.org/xpls/abs{\{}{\_}{\}}all.jsp?arnumber=5895106},
volume = {57},
year = {2011}
}
@article{Park2009,
author = {Park, JY Y and Wakin, Michael},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Park, Wakin - 2009 - A multiscale framework for compressive sensing of video.pdf:pdf},
journal = {Picture Coding Symposium, 2009. PCS {\ldots}},
pages = {1--4},
title = {A multiscale framework for compressive sensing of video},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5167440 http://ieeexplore.ieee.org/xpls/abs{\{}{\_}{\}}all.jsp?arnumber=5167440},
year = {2009}
}
@article{Baraniuk2007,
abstract = {The Shannon/Nyquist sampling theorem specifies that to avoid losing information when capturing a signal, one must sample at least two times faster than the signal bandwidth. In many applications, including digital image and video cameras, the Nyquist rate is so high that too many samples result, making compression a necessity prior to storage or transmission. In other applications, including imaging systems (medical scanners and radars) and high-speed analog- to-digital converters, increasing the sampling rate is very expensive. This lecture note presents a new method to capture and represent compressible signals at a rate significantly below the Nyquist rate. This method, called compressive sensing, employs nonadaptive linear projections that preserve the structure of the signal; the signal is then reconstructed from these projections using an optimization process.},
author = {Baraniuk, Richard G.},
doi = {10.1109/MSP.2007.4286571},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baraniuk - 2007 - Compressive sensing.pdf:pdf},
isbn = {1053-5888},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
number = {4},
pages = {118--121},
pmid = {19158952},
title = {Compressive sensing},
url = {http://ieeexplore.ieee.org/xpls/abs{\{}{\_}{\}}all.jsp?arnumber=4286571 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4286571},
volume = {24},
year = {2007}
}
@article{Dempster1977,
abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
archivePrefix = {arXiv},
arxivId = {0710.5696v2},
author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
doi = {10.1.1.133.4884},
eprint = {0710.5696v2},
isbn = {0000000779},
issn = {0035-9246},
journal = {JOURNAL OF THE ROYAL STATISTICAL SOCIETY, SERIES B},
number = {1},
pages = {1--38},
pmid = {9501024},
title = {Maximum likelihood from incomplete data via the EM algorithm},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.133.4884},
volume = {39},
year = {1977}
}
@article{Davis1997,
author = {Davis, G. and Mallat, S. and Avellaneda, M.},
doi = {10.1007/BF02678430},
issn = {0176-4276},
journal = {Constructive Approximation},
month = {mar},
number = {1},
pages = {57--98},
title = {Adaptive greedy approximations},
url = {http://link.springer.com/10.1007/BF02678430},
volume = {13},
year = {1997}
}
@article{Wu1993,
author = {Wu, Z. and Leahy, R.},
doi = {10.1109/34.244673},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Biomedical engineering,Biomedical image processing,Clustering algorithms,Clustering methods,Data analysis,Graph theory,Image segmentation,Partitioning algorithms,Technological innovation,Tree graphs,arc capacities,closed edge contours,data clustering,flow and cut equivalent tree partitioning,graph theory,image segmentation,largest inter-subgraph maximum flow minimization,minimax techniques,mutually exclusive subgraphs,optimal graph theoretic approach,partially equivalent tree,pattern recognition,region boundary location,subgraph condensation,undirected adjacency graph},
language = {English},
number = {11},
pages = {1101--1113},
publisher = {IEEE},
title = {An optimal graph theoretic approach to data clustering: {Theory} and its application to image segmentation},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=244673},
volume = {15},
year = {1993}
}
@article{Cao2012,
abstract = {An efficient vehicle detection method is a necessity for the intelligent transportation system under the complicated traffic environment at present. To solve the problems of large computation and the poor real-time in traditional vehicle detecting methods, this article proposes a real-time vehicle detecting algorithm integrated compressive sensing (CS) theories and background subtraction method. In addition, this paper undertakes the reconstruction of foreground image of vehicle based on the orthogonal matching pursuit (OMP) algorithm. Proved by the experimental result, the proposed vehicle detection algorithm could produce higher precision detection, smaller calculation and higher-quality reconstructed image compared to the traditional ones.},
author = {Cao, Yiqin and Lei, Zhangming and Huang, Xiaosheng and Zhang, Zhen and Zhong, Tao},
doi = {10.1016/j.aasri.2012.06.075},
issn = {22126716},
journal = {AASRI Procedia},
keywords = {background subtraction,cs (compressive sensing),image reconstruction,omp (orthogonal matching pursuit)},
month = {jan},
number = {null},
pages = {480--485},
title = {A Vehicle Detection Algorithm Based on Compressive Sensing and Background Subtraction},
url = {http://dx.doi.org/10.1016/j.aasri.2012.06.075},
volume = {1},
year = {2012}
}
@phdthesis{Silkina2014,
author = {Silkina, Tatiana},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silkina - 2014 - Application of Distributed Acoustic Sensing to Flow Regime Classification.pdf:pdf},
number = {June},
school = {Norwegian University of Science and Technology},
title = {Application of Distributed Acoustic Sensing to Flow Regime Classification},
type = {Master's thesis},
year = {2014}
}
@article{Jiang2014,
author = {Jiang, Hong and Zhao, Songqing and Shen, Zuowei and Deng, Wei and Wilford, Paul A. and Haimi-Cohen, Raziel},
doi = {10.1002/bltj.21646},
issn = {10897089},
journal = {Bell Labs Technical Journal},
month = {mar},
number = {4},
pages = {63--74},
title = {Surveillance Video Analysis Using Compressive Sensing With Low Latency},
url = {http://doi.wiley.com/10.1002/bltj.21646},
volume = {18},
year = {2014}
}
@article{Ma2012,
author = {Ma, J. and Plonka, G. and Hussaini, M. Y.},
doi = {10.1109/TCSVT.2012.2201673},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma, Plonka, Hussaini - 2012 - Compressive video sampling with approximate message passing decoding.pdf:pdf},
issn = {1051-8215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {approximate message passing al-,compressed sensing,video online compression},
pages = {1},
title = {Compressive video sampling with approximate message passing decoding},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6208848},
year = {2012}
}
@article{Radke2005,
abstract = {Detecting regions of change in multiple images of the same scene taken at different times is of widespread interest due to a large number of applications in diverse disciplines, including remote sensing, surveillance, medical diagnosis and treatment, civil infrastructure, and underwater sensing. This paper presents a systematic survey of the common processing steps and core decision rules in modern change detection algorithms, including significance and hypothesis testing, predictive models, the shading model, and background modeling. We also discuss important preprocessing methods, approaches to enforcing the consistency of the change mask, and principles for evaluating and comparing the performance of change detection algorithms. It is hoped that our classification of algorithms into a relatively small number of categories will provide useful guidance to the algorithm designer.},
author = {Radke, Richard J and Andra, Srinivas and Al-Kofahi, Omar and Roysam, Badrinath},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Radke et al. - 2005 - Image change detection algorithms a systematic survey.pdf:pdf},
issn = {1057-7149},
journal = {IEEE transactions on image processing : a publication of the IEEE Signal Processing Society},
keywords = {Algorithms,Animals,Artificial Intelligence,Automated,Automated: methods,Biological,Computer-Assisted,Computer-Assisted: methods,Data Collection,Humans,Image Enhancement,Image Enhancement: methods,Image Interpretation,Imaging,Information Storage and Retrieval,Information Storage and Retrieval: methods,Models,Numerical Analysis,Pattern Recognition,Signal Processing,Subtraction Technique,Three-Dimensional,Three-Dimensional: methods},
month = {mar},
number = {3},
pages = {294--307},
pmid = {15762326},
title = {Image change detection algorithms: a systematic survey.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15762326},
volume = {14},
year = {2005}
}
@article{Kim2007,
author = {Kim, Seung-jean and Koh, K and Lustig, M and Boyd, Stephen and Gorinevsky, Dimitry},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim et al. - 2007 - An Interior-Point Method for Large-Scale l1-Regularized Least Squares.pdf:pdf},
isbn = {9550061051},
number = {4},
pages = {606--617},
title = {An Interior-Point Method for Large-Scale l1-Regularized Least Squares},
volume = {1},
year = {2007}
}
@article{Kleijnen2016,
abstract = {The intersection of mobile marketing and shopper marketing, known as mobile shopper marketing, is a rapidly evolving area. We formally define mobile shopper marketing as the planning and execution of all mobile-based marketing activities that influence a shopper along and beyond the path-to-purchase: from the initial shopping trigger, to the purchase, consumption, repurchase, and recommendation stages. However, not much is known about mobile shopper marketing. We plug this gap by first discussing mobile shopper marketing and its scope in depth and then presenting a process model that connects the mobile shopping journey with four key entities, i.e., shopper, employee, organization, and mobile technology. For each of these themes, we identify the challenges that offer future research opportunities.},
author = {Shankar, Venkatesh and Kleijnen, Mirella and Ramanathan, Suresh and Rizley, Ross and Holland, Steve and Morrissey, Shawn},
doi = {10.1016/j.intmar.2016.03.002},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shankar et al. - 2016 - Mobile Shopper Marketing Key Issues, Current Insights, and Future Research Avenues.pdf:pdf},
isbn = {10949968},
issn = {15206653},
journal = {Journal of Interactive Marketing},
keywords = {Consumer behavior,Digital marketing,Mobile marketing,Shopper marketing,Technology},
pages = {37--48},
pmid = {114990393},
title = {Mobile Shopper Marketing: Key Issues, Current Insights, and Future Research Avenues},
volume = {34},
year = {2016}
}
@article{Hawkins2010,
abstract = {The assumption of fully known in-control distributions has long been recognized as an idealization, at best approximately true. Recent development of normal-based change-point methods has allowed the assumption of exactly known in-control mean and variance to be relaxed, but retained the assumption of normality. In this paper, we develop a nonparametric tool based on the change-point model for statistical process control. This method is shown to perform well, even beating the parametric approach for small to moderate shifts in normal data, and to involve relatively light computation.},
author = {Hawkins, D. and Deng, Qiqi},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hawkins, Deng - Unknown - A Nonparametric Change-Point Control Chart.pdf:pdf},
isbn = {0022-4065},
issn = {0022-4065},
journal = {Journal of Quality Technology},
keywords = {chart performance,cumulative methods,one major,process control,rank sum test,spc},
number = {2},
pages = {165--173},
title = {A Nonparametric Change-Point Control Chart},
volume = {42},
year = {2010}
}
@incollection{Studenmund2005a,
address = {London},
author = {Studenmund, A H},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {2},
edition = {Fifth},
editor = {Clinton, Denise},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {34--62},
publisher = {Pearson Education, Inc.},
title = {2. Ordinary Least Squares.},
year = {2005}
}
@article{Hagen1992,
author = {Hagen, L. and Kahng, A.B.},
doi = {10.1109/43.159993},
issn = {02780070},
journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
keywords = {Benchmark testing,CAD,Circuit testing,Clustering methods,Cost function,Eigenvalues and eigenfunctions,Lanczos-type methods,Robustness,Runtime,Sparse matrices,Spectral Clustering,Symmetric matrices,VLSI,VLSI design,Very large scale integration,algorithmic speedups,circuit layout CAD,circuit netlists,clustering,eigenvalue,graph representation,graph theory,heuristic ratio cuts,industry benchmark suites,netlist intersection graph,network routing,ratio cut partitioning,solution quality,sparse symmetric problem,spectral methods},
language = {English},
mendeley-tags = {Spectral Clustering},
number = {9},
pages = {1074--1085},
publisher = {IEEE},
title = {New spectral methods for ratio cut partitioning and clustering},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=159993},
volume = {11},
year = {1992}
}
@article{Pan2012,
abstract = {In this study, one adaptive spatiotemporal background modelling algorithm is proposed for robust and reliable moving object detection in dynamic scene. First, a modified adaptive Gaussian mixture model (GMM) is presented to describe the temporal distribution of each pixel, based on which the spatial distribution of background is constructed by using non-parametric density estimation. By fusing the temporal and spatial distribution model, a heuristic strategy is presented for background subtraction. To reduce the computational cost, a novel criterion for adaptively determining the components number of GMM and the integral image method for calculating the spatial distribution model are proposed. Several experiments show that the proposed method can effectively reduce false positives caused by sudden or gradual changes of the background, and maintains lower false negatives, compared with some representative algorithms.},
author = {Pan, Q. and Liang, Y. and Zhang, L. and Wang, Y.},
doi = {10.1049/iet-cvi.2010.0229},
issn = {1751-9632},
journal = {IET Computer Vision},
keywords = {GMM,adaptive Gaussian mixture model,adaptive spatiotemporal background modelling,background subtraction,dynamic scene,integral image method,moving object detection,nonparametric density estimation,spatial distribution model,temporal distribution model},
month = {sep},
number = {5},
pages = {451--458},
publisher = {IET Digital Library},
title = {Adaptive spatiotemporal background modelling},
url = {http://digital-library.theiet.org/content/journals/10.1049/iet-cvi.2010.0229},
volume = {6},
year = {2012}
}
@book{Webb,
abstract = {Summary: " Statistical Pattern Recognition provides an introduction to statistical pattern theory and techniques, with material drawn from a wide range of fields, including the areas of engineering, statistics, computer science and the social sciences. The book describes techniques for analysing data comprising measurements made on individuals or objects.. The techniques are used to make a prediction such as disease of a patient, the type of object illuminated by a radar, economic forecast. Emphasis is placed on techniques for classification, a term used for predicting the class or group an object belongs to (based on a set of exemplars) and for methods that seek to discover natural groupings in a data set. Each section concludes with a description of the wide range of practical applications that have been addressed and the further developments of theoretical techniques and includes a variety of exercises, from 'open-book' questions to more lengthy projects. New material is presented, including the analysis of complex networks and basic techniques for analysing the properties of datasets and also introduces readers to the use of variational methods for Bayesian density estimation and looks at new applications in biometrics and security. "},
author = {Webb, Andrew R.},
doi = {10.1002/0470854774},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Webb - 2002 - Statistical Pattern Recognition.pdf:pdf},
isbn = {0470845139},
keywords = {MATHEMATICS / Probability {\&} Statistics / General,MATHEMATICS / Probability {\{}{\&}{\}} Statistics / General,Pattern perception -- Statistical methods},
pages = {515},
title = {Statistical Pattern Recognition},
year = {2002}
}

@incollection{Warnell2011,
author = {Warnell, Garrett and Chellappa, Rama},
booktitle = {Recent Developments in Video Surveillance},
chapter = {1},
editor = {El-Alfy, Hazem},
pages = {205--224},
publisher = {InTech},
title = {Compressive Sensing in Visual Tracking},
year = {2011}
}

@article{Cai2010,
author = {Cai, T T and Zhang, C H and Zhou, H H},
doi = {10.1214/09-AOS752},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {Covariance matrix,Frobenius norm,minimax lower bound,operator norm,optimal rate of convergence,tapering},
month = {aug},
number = {4},
pages = {2118--2144},
title = {Optimal rates of convergence for covariance matrix estimation},
url = {http://projecteuclid.org/euclid.aos/1278861244},
volume = {38},
year = {2010}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {The Mendeley Support Team},
booktitle = {Mendeley Desktop},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {Getting Started with Mendeley},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Elwell2011,
abstract = {We introduce an ensemble of classifiers-based approach for incremental learning of concept drift, characterized by nonstationary environments (NSEs), where the underlying data distributions change over time. The proposed algorithm, named Learn(++). NSE, learns from consecutive batches of data without making any assumptions on the nature or rate of drift; it can learn from such environments that experience constant or variable rate of drift, addition or deletion of concept classes, as well as cyclical drift. The algorithm learns incrementally, as other members of the Learn(++) family of algorithms, that is, without requiring access to previously seen data. Learn(++). NSE trains one new classifier for each batch of data it receives, and combines these classifiers using a dynamically weighted majority voting. The novelty of the approach is in determining the voting weights, based on each classifier's time-adjusted accuracy on current and past environments. This approach allows the algorithm to recognize, and act accordingly, to the changes in underlying data distributions, as well as to a possible reoccurrence of an earlier distribution. We evaluate the algorithm on several synthetic datasets designed to simulate a variety of nonstationary environments, as well as a real-world weather prediction dataset. Comparisons with several other approaches are also included. Results indicate that Learn(++). NSE can track the changing environments very closely, regardless of the type of concept drift. To allow future use, comparison and benchmarking by interested researchers, we also release our data used in this paper.},
author = {Elwell, Ryan and Polikar, Robi},
doi = {10.1109/TNN.2011.2160459},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elwell, Polikar - 2011 - Incremental learning of concept drift in nonstationary environments.pdf:pdf},
issn = {1941-0093},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
keywords = {Algorithms,Artificial Intelligence,Automatic Data Processing,Automatic Data Processing: methods,Environment,Humans,Learning,Learning: physiology,Models,Neural Networks (Computer),Neurological,Nonlinear Dynamics},
month = {oct},
number = {10},
pages = {1517--31},
pmid = {21824845},
shorttitle = {Neural Networks, IEEE Transactions on},
title = {Incremental learning of concept drift in nonstationary environments.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21824845},
volume = {22},
year = {2011}
}
@article{Duarte2008Single,
author = {Duarte, M F. and Davenport, M. A. and Takhar, D. and Laska, J. N. and Kelly, K. F. and Baraniuk, R. G.},
doi = {10.1109/MSP.2007.914730},
issn = {1053-5888},
journal = {IEEE Signal Processing Magazine},
keywords = {CMOS image sensors,Charge coupled devices,Computer architecture,Digital cameras,Hyperspectral imaging,Image reconstruction,Layout,Lenses,Optical computing,Sampling methods,broad spectral range,cameras,compressive sampling,data compression,digital camera,digital micromirror device,digital photography,image sampling,micromirrors, single pixel imaging},
pages = {83--91},
publisher = {IEEE},
title = {Single-Pixel Imaging via Compressive Sampling},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=4472247},
volume = {25},
year = {2008}
}
@incollection{Bouchachia2012,
address = {New York, NY},
author = {Bouchachia, Abdelhamid and Prossegger, Markus},
booktitle = {Learning in Non-Stationary Environments: Methods and Applications},
doi = {10.1007/978-1-4419-8020-5_4},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouchachia, Prossegger - 2012 - Incremental spectral clustering.pdf:pdf},
isbn = {9781441980205},
issn = {1975-9320},
pages = {77--99},
publisher = {Springer New York},
title = {Incremental spectral clustering},
url = {http://link.springer.com/10.1007/978-1-4419-8020-5{\_}4},
volume = {9781441980},
year = {2012}
}
@article{Stauffer,
author = {Stauffer, C. and Grimson, W.E.L. E L},
doi = {10.1109/CVPR.1999.784637},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stauffer, Grimson - Unknown - Adaptive background mixture models for real-time tracking.pdf:pdf},
isbn = {0-7695-0149-4},
journal = {Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)},
pages = {246--252},
publisher = {IEEE Comput. Soc},
title = {Adaptive background mixture models for real-time tracking},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=784637}
}
@article{Cevher2008a,
author = {Cevher, Volkan and Duarte, M F},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cevher, Duarte - 2008 - Sparse signal recovery using markov random fields.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {1--8},
title = {Sparse signal recovery using markov random fields},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\{}{\_}{\}}files/NIPS2008{\{}{\_}{\}}0981.pdf http://machinelearning.wustl.edu/mlpapers/paper{\_}files/NIPS2008{\_}0981.pdf},
year = {2008}
}
@article{Taylor1979,
abstract = {Given a wavelet w and a noisy trace t + s * w + n, an approximation ŝ of the spike train s can be obtained using the ℓ1 norm. This extraction has the advantage of preserving isolated spikes in s. On some types of data the spike train ŝ can represent s as a sparse series of spikes, which may be sampled at a rate higher than the sample rate of the data trace t. The extracted spike train ŝ may be qualitatively much different than those commonly extracted using the ℓ2 norm. The ℓ1 norm can also be used to extract a wavelet ŵ from a trace t when a spike train s is known. This wavelet extraction can be constrained to give a smooth wavelet which integrates to zero and goes to zero at the ends. Given a trace t and an initial approximation for either s or w, it is possible to alternately extract spike trains and wavelets to improve the representation of trace t. Although special algorithms have been developed to solve ℓ1 problems, all of the calculations can be performed using a general linear programming system. ...},
author = {Taylor, Howard L. and Banks, Stephen C. and McCoy, John F.},
doi = {10.1190/1.1440921},
issn = {0016-8033},
journal = {Geophysics},
language = {en},
month = {jan},
number = {1},
pages = {39--52},
publisher = {Society of Exploration Geophysicists},
title = {Deconvolution with the norm},
url = {http://library.seg.org/doi/abs/10.1190/1.1440921},
volume = {44},
year = {1979}
}
@article{Marcia2008,
author = {Marcia, R and Willett, RM M},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marcia, Willett - 2008 - Compressive coded aperture video reconstruction.pdf:pdf},
journal = {Proc. European Signal Processing Conf.( {\{}{\ldots}{\}}},
number = {1},
title = {Compressive coded aperture video reconstruction},
url = {http://people.ee.duke.edu/roummel/pub/papers/MarciaEUSIPCO2008.pdf},
year = {2008}
}
@inproceedings{Cossalter2009,
abstract = {In a typical video analysis framework, video sequences are decoded and reconstructed in the pixel domain before being processed for high level tasks such as classification or detection.Nevertheless, in some application scenarios, it might be of interest to complete these analysis tasks without disclosing sensitive data, e.g. the identity of people captured by surveillance cameras. In this paper we propose a new coding scheme suitable for video surveillance applications that allows tracking of video objects without the need to reconstruct the sequence,thus enabling privacy protection. By taking advantage of recent findings in the compressive sensing literature, we encode a video sequence with a limited number of pseudo-random projections of each frame. At the decoder, we exploit the sparsity that characterizes background subtracted images in order to recover the location of the foreground object. We also leverage the prior knowledge about the estimated location of the object, which is predicted by means of a particle filter, to improve the recovery of the foreground object location. The proposed framework enables privacy, in the sense it is impossible to reconstruct the original video content from the encoded random projections alone, as well as secrecy, since decoding is prevented if the seed used to generate the random projections is not available.},
author = {Cossalter, M. and Tagliasacchi, M. and Valenzise, G.},
booktitle = {Advanced Video and Signal-Based Video Surveillance},
doi = {10.1109/AVSS.2009.13},
isbn = {978-1-4244-4755-8},
keywords = {Cameras,Decoding,Image coding,Image reconstruction,Particle filters,Privacy,Protection,Video compression,Video sequences,Video surveillance,compressive sensing,data privacy,foreground object location,image sequences,particle filter,particle filtering (numerical methods),privacy protection,privacy-enabled object tracking,pseudo-random projection,surveillance camera,video analysis framework,video coding,video decoding,video object tracking,video reconstruction,video surveillance application},
month = {sep},
pages = {436--441},
shorttitle = {Advanced Video and Signal Based Surveillance, 2009},
title = {Privacy-Enabled Object Tracking in Video Sequences Using Compressive Sensing},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5279666},
year = {2009}
}
@article{Zhao2011,
abstract = {We propose a learning-based background subtraction approach based on the theory of sparse representation and dictionary learning. Our method makes the following two important assumptions: (1) the background of a scene has a sparse linear representation over a learned dictionary; (2) the foreground is},
author = {Zhao, Cong and Wang, Xiaogang and Cham, Wai-Kuen},
doi = {10.1155/2011/972961},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Wang, Cham - 2011 - Background Subtraction via Robust Dictionary Learning.pdf:pdf},
issn = {1687-5176},
journal = {EURASIP Journal on Image and Video Processing},
language = {en},
month = {feb},
number = {1},
pages = {1--12},
publisher = {Springer},
title = {Background Subtraction via Robust Dictionary Learning},
url = {http://jivp.eurasipjournals.com/content/2011/1/972961},
volume = {2011},
year = {2011}
}
@article{Liang2009,
abstract = {The (batch) EM algorithm plays an important role in unsupervised induction, but it sometimes suffers from slow convergence. In this paper, we show that online variants (1) provide significant speedups and (2) can even find better solutions than those found by batch EM. We support these findings on four unsupervised tasks: part-of-speech tagging, document classification, word segmentation, and word alignment.},
author = {Liang, Percy and Klein, Dan},
doi = {10.3115/1620754.1620843},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang, Klein - 2009 - Online EM for unsupervised models.pdf:pdf},
isbn = {9781932432411},
issn = {978-1-932432-41-1},
journal = {Proceedings of Human Language Technologies The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics on NAACL 09},
month = {may},
pages = {611},
publisher = {Association for Computational Linguistics},
title = {Online EM for unsupervised models},
url = {http://portal.acm.org/citation.cfm?doid=1620754.1620843},
year = {2009}
}
@article{Fryzlewicz2014,
abstract = {We propose a new technique, called Wild Binary Segmentation (WBS), for consistent estimation of the number and locations of multiple change-points in data. We assume that the number of change-points can increase to infinity with the sample size. Due to a certain random localisation mechanism, WBS works even for very short spacings between the change-points, unlike standard Binary Segmentation. On the other hand, despite its use of localisation, WBS does not require the choice of a window or span parameter, and does not lead to a significant increase in computational complexity. WBS is also easy to code. We propose two stopping criteria for WBS: one based on thresholding and the other based on what we term the “strengthened Schwarz Information Criterion”. We provide default recommended values of the parameters of the procedure and show that it offers very good practical performance in comparison with the state of the art. In addition, we provide a new proof of consistency of Binary Segmentation with improved rates of convergence, as well as a corresponding result for WBS.},
archivePrefix = {arXiv},
arxivId = {arXiv:1411.0858v1},
author = {Fryzlewicz, Piotr},
doi = {10.1214/14-AOS1245},
eprint = {arXiv:1411.0858v1},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fryzlewicz - 2014 - Wild binary segmentation for multiple change-point detection.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Bayesian information criterion,Binary segmentation,Change-point detection,Multiple change-points,Randomised algorithms,Thresholding},
month = {nov},
number = {6},
pages = {2243--2281},
title = {Wild binary segmentation for multiple change-point detection},
url = {http://arxiv.org/abs/1411.0858 http://dx.doi.org/10.1214/14-AOS1245},
volume = {42},
year = {2014}
}
@book{Everitt2001,
abstract = {5th ed. "This edition provides a thorough revision of the fourth edition which focuses on the practical aspects of cluster analysis and covers new methodology in terms of longitudinal data and provides examples from bioinformatics. Real life examples are used throughout to demonstrate the application of the theory, and figures are used extensively to illustrate graphical techniques. This book includes an appendix of getting started on cluster analysis using R, as well as a comprehensive and up-to-date bibliography."-- "This edition provides a thorough revision of the fourth edition which focuses on the practical aspects of cluster analysis and covers new methodology in terms of longitudinal data and provides examples from bioinformatics"-- Front Matter -- An Introduction to Classification and Clustering -- Detecting Clusters Graphically -- Measurement of Proximity -- Hierarchical Clustering -- Optimization Clustering Techniques -- Finite Mixture Densities as Models for Cluster Analysis -- Model-Based Cluster Analysis for Structured Data -- Miscellaneous Clustering Methods -- Some Final Comments and Guidelines -- Bibliography -- Index.},
author = {Everit, B.S. and Landau, Sabine and Leese, Morven},
doi = {http://dx.doi.org/10.4135/9781412983648},
isbn = {0-435-82297-7},
issn = {00335177},
pages = {330},
pmid = {3820},
publisher = {Wiley},
title = {Cluster analysis},
year = {2001}
}
@article{Lin2009,
author = {Lin, HH H and Liu, TL L},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Liu - 2009 - Learning a scene background model via classification.pdf:pdf},
journal = {Signal Processing, IEEE},
keywords = {SVM,background modeling,boosting,classification,tracking},
number = {5},
pages = {1641--1654},
title = {Learning a scene background model via classification},
url = {http://ieeexplore.ieee.org/xpls/abs{\{}{\_}{\}}all.jsp?arnumber=4776465 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4776465},
volume = {57},
year = {2009}
}
@article{Stoer1997,
author = {Stoer, Mechthild and Wagner, Frank},
doi = {10.1145/263867.263872},
issn = {00045411},
journal = {Journal of the ACM},
keywords = {Spectral Clustering,min-cut},
mendeley-tags = {Spectral Clustering},
month = {jul},
number = {4},
pages = {585--591},
publisher = {ACM},
title = {A simple min-cut algorithm},
url = {http://dl.acm.org/citation.cfm?id=263867.263872},
volume = {44},
year = {1997}
}
@article{Ning2010,
abstract = {In recent years, the spectral clustering method has gained attentions because of its superior performance. To the best of our knowledge, the existing spectral clustering algorithms cannot incrementally update the clustering results given a small change of the data set. However, the capability of incrementally updating is essential to some applications such as websphere or blogsphere. Unlike the traditional stream data, these applications require incremental algorithms to handle not only insertion/deletion of data points but also similarity changes between existing points. In this paper, we extend the standard spectral clustering to such evolving data, by introducing the incidence vector/matrix to represent two kinds of dynamics in the same framework and by incrementally updating the eigen-system. Our incremental algorithm, initialized by a standard spectral clustering, continuously and efficiently updates the eigenvalue system and generates instant cluster labels, as the data set is evolving. The algorithm is applied to a blog data set. Compared with recomputation of the solution by the standard spectral clustering, it achieves similar accuracy but with much lower computational cost. It can discover not only the stable blog communities but also the evolution of the individual multi-topic blogs. The core technique of incrementally updating the eigenvalue system is a general algorithm and has a wide range of applications-as well as incremental spectral clustering-where dynamic graphs are involved. This demonstrates the wide applicability of our incremental algorithm. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Ning, Huazhong and Xu, Wei and Chi, Yun and Gong, Yihong and Huang, Thomas S.},
doi = {10.1016/j.patcog.2009.06.001},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Graph,Incidence vector/matrix,Incremental clustering,Spectral Clustering,Spectral clustering,Web-blogs},
mendeley-tags = {Spectral Clustering},
month = {jan},
number = {1},
pages = {113--127},
publisher = {Elsevier Science Inc.},
title = {Incremental spectral clustering by efficiently updating the eigen-system},
url = {http://dl.acm.org/citation.cfm?id=1595888.1595943},
volume = {43},
year = {2010}
}
@article{Priebe1993,
abstract = {A recursive, nonparametric method is developed for performing density estimation derived from mixture models, kernel estimation and stochastic approximation. The asymptotic performance of the method, dubbed "adaptive mixtures" (Priebe and Marchette, Pattern Recognition 24, 1197-1209 (1991)) for its data-driven development of a mixture model approximation to the true density, is investigated using the method of sieves. Simulations are included indicating convergence properties for some simple examples. ?? 1993.},
author = {Priebe, Carey E. and Marchette, David J.},
doi = {10.1016/0031-3203(93)90130-O},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Priebe, Marchette - 1993 - Adaptive mixture density estimation.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Density estimation,EM algorithm,Kernel estimator,Maximum likelihood,Method of sieves,Mixture model,Nonparametric estimation,Recursive estimation,Stochastic approximation},
month = {may},
number = {5},
pages = {771--785},
title = {Adaptive mixture density estimation},
url = {http://www.sciencedirect.com/science/article/pii/003132039390130O},
volume = {26},
year = {1993}
}
@article{Bhattacharya2014,
abstract = {We propose a sparse-coding framework for activity recognition in ubiquitous and mobile computing that alleviates two fundamental problems of current supervised learning approaches. (i) It automatically derives a compact, sparse and meaningful feature representation of sensor data that does not rely on prior expert knowledge and generalizes well across domain boundaries. (ii) It exploits unlabeled sample data for bootstrapping effective activity recognizers, i.e., substantially reduces the amount of ground truth annotation required for model estimation. Such unlabeled data is easy to obtain, e.g., through contemporary smartphones carried by users as they go about their everyday activities. Based on the self-taught learning paradigm we automatically derive an over-complete set of basis vectors from unlabeled data that captures inherent patterns present within activity data. Through projecting raw sensor data onto the feature space defined by such over-complete sets of basis vectors effective feature extraction is pursued. Given these learned feature representations, classification backends are then trained using small amounts of labeled training data. We study the new approach in detail using two datasets which differ in terms of the recognition tasks and sensor modalities. Primarily we focus on a transportation mode analysis task, a popular task in mobile-phone based sensing. The sparse-coding framework demonstrates better performance than the state-of-the-art in supervised learning approaches. More importantly, we show the practical potential of the new approach by successfully evaluating its generalization capabilities across both domain and sensor modalities by considering the popular Opportunity dataset. Our feature learning approach outperforms state-of-the-art approaches to analyzing activities of daily living.},
author = {Bhattacharya, Sourav and Nurmi, Petteri and Hammerla, Nils and Pl{\"{o}}tz, Thomas},
doi = {10.1016/j.pmcj.2014.05.006},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhattacharya et al. - 2014 - Using unlabeled data in a sparse-coding framework for human activity recognition.pdf:pdf},
issn = {15741192},
journal = {Pervasive and Mobile Computing},
keywords = {Activity recognition,Machine learning,Sparse-coding,Unsupervised learning},
month = {dec},
pages = {242--262},
title = {Using unlabeled data in a sparse-coding framework for human activity recognition},
url = {http://www.sciencedirect.com/science/article/pii/S1574119214000820},
volume = {15},
year = {2014}
}
@book{Harkness2016,
abstract = {Includes index. "Timandra Harkness cuts through the hype to put data science into its real-life context using a wide range of stories, people, and places to reveal what is essentially a human science--demystifying big data, telling us where it comes from and what it can do. 'Big Data' then asks the awkward questions: What are the unspoken assumptions underlying its methods? Are we being bamboozled by mega data's size, its speed, and its shiny technology? Nobody needs a degree in computer science to follow Harkness's exploration of what mega data can do for us--and what it can't or shouldn't. 'Big Data' asks you to decide: Are you a data point, or a human being?"--Provided by publisher. Big data knows where you've been and who your friends are. It knows what you like and what makes you angry. It can predict what you'll buy, where you'll be the victim of crime and when you'll have a heart attack. Big data knows you better than you know yourself, or so it claims. But how well do you know big data? You've probably seen the phrase in newspaper headlines, at work in a marketing meeting, or on a fitness-tracking gadget. But can you understand it without being a Silicon Valley nerd who writes computer programs for fun? Yes, you can. Timandra Harkness writes comedy, not computer code. The only programs she makes are on the radio. If you can read a newspaper, you can read this book. Starting with the basics--what IS data? And what makes it big?--Timandra takes you on a whirlwind tour of how people are using big data today: from science to smart cities, business to politics, self-quantification to the Internet of Things. Finally, she asks the big questions about where it's taking us; is it too big for its boots, or does it think too small? Are you a data point or a human being? Will this book be full of rhetorical questions? No. It also contains puns, asides, unlikely stories and engaging people, inspiring feats and thought-provoking dilemmas. Leaving you armed and ready to decide what you think about one of the decade's big ideas: big data.--From dust jacket. Part 1: What is it? Where did it come from?. What is data? And what makes it big? ; Death and taxes. And babies ; Thinking machines -- Part 2: What has big data ever done for us?. Big business ; Big science ; Big society ; Data-driven democracy -- Part 3: Big ideas?. Big Brother ; Who do we think you are? ; Are you a data point or a human being? -- Appendix. Keeping your data private.},
author = {Harkness, Timandra},
isbn = {9781472920065},
pages = {304},
publisher = {Bloomsbury},
title = {Big data : does size matter?},
year = {2016}
}
@article{Aggarwal2003,
abstract = {The clustering problem is a difficult problem for the data stream domain. This is because the large volumes of data arriving in a stream renders most traditional algorithms too inefficient. In recent years, a...},
author = {Aggarwal, Charu C. and Watson, T. J. and Han, Jiawei and Wang, Jianyong and Yu, Philip S.},
doi = {10.1.1.13.8650},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aggarwal et al. - 2003 - A Framework for Clustering Evolving Data Streams.pdf:pdf},
isbn = {0-12-722442-4},
journal = {Proceedings of the 29th International Conference on Very Large Data Bases},
month = {sep},
pages = {81--92},
publisher = {VLDB Endowment},
title = {A Framework for Clustering Evolving Data Streams},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.8650},
year = {2003}
}
@inproceedings{Ailon2009,
author = {Ailon, Nir and Jaiswal, Ragesh and Monteleoni, Claire},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ailon, Jaiswal, Monteleoni - 2009 - Streaming k-means approximation.pdf:pdf},
pages = {10--18},
title = {Streaming k-means approximation},
url = {http://papers.nips.cc/paper/3812-streaming-k-means-approximation},
year = {2009}
}
@book{Gama2007,
abstract = {Sensor networks consist of distributed autonomous devices that cooperatively monitor an environment. Sensors are equipped with capacities to store information in memory, process this information and communicate with their neighbors. Processing data streams generated from wireless sensor networks has raised new research challenges over the last few years due to the huge numbers of data streams to be managed continuously and at a very high rate. The book provides the reader with a comprehensive overview of stream data processing, including famous prototype implementations like the Nile system and the TinyOS operating system. The set of chapters covers the state-of-art in data stream mining approaches using clustering, predictive learning, and tensor analysis techniques, and applying them to applications in security, the natural sciences, and education. This research monograph delivers to researchers and graduate students the state of the art in data stream processing in sensor networks. The huge bibliography offers an excellent starting point for further reading and future research. Overview -- Sensor Networks: An Overview -- Data Stream Processing -- Data Stream Processing in Sensor Networks -- Data Stream Management Techniques in Sensor Networks -- Data Stream Management Systems and Architectures -- Querying of Sensor Data -- Aggregation and Summarization in Sensor Networks -- Sensory Data Monitoring -- Mining Sensor Network Data Streams -- Clustering Techniques in Sensor Networks -- Predictive Learning in Sensor Networks -- Tensor Analysis on Multi-aspect Streams -- Applications -- Knowledge Discovery from Sensor Data for Security Applications -- Knowledge Discovery from Sensor Data For Scientific Applications -- TinyOS Education with LEGO MINDSTORMS NXT.},
author = {Gama, João. and Gaber, Mohamed Medhat.},
isbn = {9783540736790},
pages = {244},
publisher = {Springer},
title = {Learning from data streams : {Processing} techniques in sensor networks},
year = {2007}
}
@inproceedings{Sen-Ching2004,
author = {Cheung, Sen-Ching S. and Kamath, Chandrika},
booktitle = {Electronic Imaging},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheung, Kamath - 2004 - Robust techniques for background subtraction in urban traffic video.pdf:pdf},
keywords = {background subtraction,urban traffic video},
pages = {881--892},
title = {Robust techniques for background subtraction in urban traffic video},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=838095},
year = {2004}
}
@misc{Langone2014,
abstract = {In this work a new model for online clustering named Incremental kernel spectral clustering (IKSC) is presented. It is based on kernel spectral clustering (KSC), a model designed in the Least Squares Support Vector Machines (LS-SVMs) framework, with primal-dual setting. The IKSC model is developed to quickly adapt itself to a changing environment, in order to learn evolving clusters with high accuracy. In contrast with other existing incremental spectral clustering approaches, the eigen-updating is performed in a model-based manner, by exploiting one of the Karush–Kuhn–Tucker (KKT) optimality conditions of the KSC problem. We test the capacities of IKSC with some experiments conducted on computer-generated data and a real-world data-set of PM10 concentrations registered during a pollution episode occurred in Northern Europe in January 2010. We observe that our model is able to precisely recognize the dynamics of shifting patterns in a non-stationary context.},
author = {Langone, Rocco and {Mauricio Agudelo}, Oscar and {De Moor}, Bart and Suykens, Johan A.K.},
booktitle = {Neurocomputing},
doi = {10.1016/j.neucom.2014.02.036},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Langone et al. - 2014 - Incremental kernel spectral clustering for online learning of non-stationary data.pdf:pdf},
issn = {09252312},
keywords = {Incremental kernel spectral clustering,LS-SVMs,Non-stationary data,Online clustering,Out-of-sample eigenvectors,PM10 concentrations},
month = {sep},
pages = {246--260},
title = {Incremental kernel spectral clustering for online learning of non-stationary data},
url = {ftp://ftp.esat.kuleuven.be/pub/SISTA/rlangone/reports/13-141.pdf http://www.sciencedirect.com/science/article/pii/S0925231214004433},
urldate = {2016-05-03},
volume = {139},
year = {2014}
}
@incollection{Studenmund2005,
address = {London},
author = {Studenmund, A H},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {1},
edition = {Fifth},
editor = {Clinton, Denise},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {1. The Basic Regression Model.},
year = {2005}
}
@article{Alimoglu1996,
abstract = {Pen-based handwriting recognition has enormous practical utility.$\backslash$nIt is different from optical recognition in that the input is a temporal$\backslash$nsignal of pen movements as opposed to a static spatial pattern. We examine various ways of combining multiple learners which are trained with different representations of the same input signal: dynamic (pen movements) and static (final 2D image). We notice that the classifiers based on different representations fail for different patterns and investigate ways to combine the two representations. We benchmark voting, stacking, mixture of experts and cascading. In voting and stacking, the two are always used together. In the mixture of experts, the gating network chooses one of the two. In cascading, the static is used only when the dynamic is not certain. On a handwritten digit database significant increase in accuracy has been obtained.},
author = {Alimoglu, Fevzi and Alpaydin, Ethem},
journal = {Proceedings of the Fifth Turkish Artificial Intelligence and Artificial Neural Networks Symposium},
title = {Methods of Combining Multiple Classifiers Based on Different Representations for Pen-based Handwritten Digit Recognition},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.6383},
year = {1996}
}



@inproceedings{Patri2012,
author = {Patri, Om Prasad and Sorathia, Vikrambhai S. and Prasanna, Viktor K},
booktitle = {SPE Annual Technical Conference and Exhibition},
pages = {3530--3543},
title = {Event-driven information integration for the digital oilfield},
year = {2012}
}



@book{Gujarati2004,
abstract = {This book covers some essential topics of econometrics. It covers from single regression to multiple regression. The second part of the book talks about how to detect a violation of assumptions (multicollinearity, heteroscedasticity, autocorrelation, model specification) made for running multiple regression and what the remedies are. The third part deals with three topics, including (a) regression on dummy variables, (b) regression on dummy dependent variables, (c) autoregressive and distributed lag models. The last part deals with simultaneous-equation model.},
author = {Gujarati, Damodar N (West Point Military Academy)},
edition = {Forth},
isbn = {9780071276252},
keywords = {Econometrics,Statistics},
mendeley-tags = {Econometrics,Statistics},
pages = {1--1003},
publisher = {The McGraw−Hill Companies},
title = {Basic Econometrics},
year = {2004}
}
@article{Candes2006,
abstract = {Suppose we are given a vector f in a class FsubeRopfN , e.g., a class of digital signals or digital images. How many linear measurements do we need to make about f to be able to recover f to within precision epsi in the Euclidean (lscr2) metric? This paper shows that if the objects of interest are sparse in a fixed basis or compressible, then it is possible to reconstruct f to within very high accuracy from a small number of random measurements by solving a simple linear program. More precisely, suppose that the nth largest entry of the vector |f| (or of its coefficients in a fixed basis) obeys |f|(n)lesRmiddotn-1p/, where R{\textgreater}0 and p{\textgreater}0. Suppose that we take measurements yk=langf{\#} ,Xkrang,k=1,...,K, where the Xk are N-dimensional Gaussian vectors with independent standard normal entries. Then for each f obeying the decay estimate above for some 0{\textless}p{\textless}1 and with overwhelming probability, our reconstruction ft, defined as the solution to the constraints yk=langf{\#} ,Xkrang with minimal lscr1 norm, obeys parf-f{\#}parlscr2lesCp middotRmiddot(K/logN)-r, r=1/p-1/2. There is a sense in which this result is optimal; it is generally impossible to obtain a higher accuracy from any set of K measurements whatsoever. The methodology extends to various other random measurement ensembles; for example, we show that similar results hold if one observes a few randomly sampled Fourier coefficients of f. In fact, the results are quite general and require only two hypotheses on the measurement ensemble which are detailed},
author = {Cand{\`{e}}s, Emmanuel and Tao, Terence},
doi = {10.1109/TIT.2006.885507},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
keywords = {Concentration of measure,Concrete,Digital images,Encoding,Geometry,Image coding,Imdge reconstruction,Linear programming,Mathematics,Measurement standards,N-dimensional Gaussian vector,Vectors,convex optimization,duality in optimization,linear measurement,linear program,random matrices,random projection,random projections,signal reconstruction,signal recovery,singular values of random matrices,sparsity,trigonometric expansions,uncertainty principle,universal encoding strategy},
month = {dec},
pages = {5406--5425},
shorttitle = {Information Theory, IEEE Transactions on},
title = {Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4016283},
volume = {52},
year = {2006}
}
@unpublished{Keele2008,
abstract = {Experiments have become an increasingly common tool for political science researchers over the last decade, particularly laboratory experiments performed on small convenience samples. The standard statistical paradigm used in political science is designed to connect samples to populations, while the inferential goal in an experiment is often about understand- ing whether an observed treatment effect occurred due to chance. In this paper, we outline an alternative derivation for statistical inference based on randomization of the treatment. While some standard tests approximate this form of inference, many do not and can produce incorrect inferences. These tests also have robust forms that are insensitive to the distribu- tion of the data. We outline common randomization tests, such as Wilcoxon rank tests and the Kruskal-Wallis test, and also develop a randomization test for two-way factorial designs as an alternative to the commonly used two-way ANOVA model. Finally, we reanalyze data from two political science experiments using randomization tests to illustrate the inferential errors that can be made when classical tests are used with data from the lab.},
author = {Keele, Luke (Ohio State University) and Mcconnaughy, Corrine (Ohio State University) and White, Ismail (Ohio State University)},
pages = {1--41},
title = {Statistical Inference For Experiments},
year = {2008}
}
@article{Fan2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1206.2197v1},
author = {Fan, Rong and Wan, Qun and Liu, Yipeng and Chen, Hui and Zhang, Xiao},
eprint = {arXiv:1206.2197v1},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fan et al. - 2012 - Complex Orthogonal Matching Pursuit and Its Exact Recovery Conditions.pdf:pdf},
journal = {arXiv preprint arXiv:1206.2197},
number = {1},
pages = {1--18},
title = {Complex Orthogonal Matching Pursuit and Its Exact Recovery Conditions},
url = {http://arxiv.org/abs/1206.2197},
volume = {2012},
year = {2012}
}
@article{Cao2014,
abstract = {Spectral clustering has become one of the most popular clustering approaches in recent years. However, its high computational complexity prevents its application to large-scale datasets. To address this complexity, approximate spectral clustering methods have been proposed. In these methods, computational costs are reduced by using approximation techniques, such as the Nystr{\"{o}}m method, or by constructing a smaller representative dataset on which spectral clustering is performed. However, the computational efficiency of these approximation methods is achieved at the cost of performance degradation. In this paper, we propose an efficient approximate spectral clustering method in which clustering performance is improved by utilizing local information among the data, while the scalability to the large-scale datasets is retained. Specifically, we improve the approximate spectral clustering method in two aspects. First, a sparse affinity graph is adopted to improve the performance of spectral clustering on the small representative dataset. Second, local interpolation is utilized to improve the extension of the clustering result. Experiments are conducted on several real-world datasets, showing that the proposed method is efficient and outperforms the state-of-the-art approximate spectral clustering algorithms. {\textcopyright} 2013 Elsevier B.V.},
author = {Cao, Jiangzhong and Chen, Pei and Dai, Qingyun and Ling, Wing Kuen},
doi = {10.1016/j.patrec.2013.11.005},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao et al. - 2014 - Local information-based fast approximate spectral clustering.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Local information,Local interpolation,Sparse affinity graph,Spectral Clustering,Spectral clustering},
mendeley-tags = {Spectral Clustering},
month = {mar},
number = {1},
pages = {63--69},
title = {Local information-based fast approximate spectral clustering},
url = {http://www.sciencedirect.com/science/article/pii/S0167865513004285},
volume = {38},
year = {2014}
}
@article{Claerbout1973,
abstract = {An attractive alternative to least‐squares data modeling techniques is the use of absolute value error criteria. Unlike the least‐squares techniques the inclusion of some infinite blunders along with the data will hardly affect the solution to an otherwise well‐posed problem. An example of this great stability is seen when an average is, determined by using the median rather than the arithmetic mean. Algorithms for absolute error minimization are often approximately as costly as least‐squares algorithms; however, unlike least‐squares, they naturally lend themselves to inequality or bounding constraints on models.},
author = {Claerbout, Jon F. and Muir, Francis},
doi = {10.1190/1.1440378},
issn = {0016-8033},
journal = {Geophysics},
language = {en},
month = {oct},
number = {5},
pages = {826--844},
publisher = {Society of Exploration Geophysicists},
title = {Robust modelling with erratic data},
url = {http://library.seg.org/doi/abs/10.1190/1.1440378},
volume = {38},
year = {1973}
}
@unpublished{Imai2009,
abstract = {In a highly influential paper, Baron and Kenny (1986) proposed a statistical procedure to con- duct a causal mediation analysis and identify possible causal mechanisms. This procedure has been widely used across many branches of the social and medical sciences and especially in psychology and epidemiology. However, one major limitation of this approach is that it is based on a set of linear regressions and cannot be easily extended to more complex situations that are frequently encoun- tered in applied research. In this paper, we propose an approach that generalizes the Baron-Kenny procedure. Our method can accommodate linear and nonlinear relationships, parametric and non- parametric models, continuous and discrete mediators, and various types of outcome variables. We also provide a formal statistical justification for the proposed generalization of the Baron-Kenny pro- cedure by placing causal mediation analysis within the widely-accepted counterfactual framework of causal inference. Finally, we develop a set of sensitivity analyses that allow applied researchers to quantify the robustness of their empirical conclusions. Such sensitivity analysis is important because as we showthe Baron-Kenny procedure and our generalization of it rest on a strong and untestable as- sumption even in randomized experiments. We illustrate the proposed methods by applying them to a randomized field experiment, the Job Search Intervention Study (JOBS II).We also offer easy-to-use software that implements all of our proposed methods.},
address = {Princeton},
author = {Imai, Kosuke (Princenton University) and Keele, Luke (Princenton University) and Tingley, Dustin (Princenton University)},
institution = {Princeton University},
keywords = {Mediation,Statistics,Structural Equation Modeling,causal inference,causal mechanisms,sensitivity analysis,sequential ignorability,struc- tural equation modeling,unobserved confounder},
mendeley-tags = {Mediation,Statistics,Structural Equation Modeling},
title = {A General Approach to Causal Mediation Analysis},
year = {2009}
}
@article{Donoho2006,
author = {Donoho, David L.},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Donoho - 2006 - Compressed sensing.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
keywords = {adaptive sampling,almost-spherical sections of banach,and phrases,based complexity,basis pursuit,equations,fand n-widths,gel,information-,integrated sensing and processing,minimum 1 norm decomposition,optimal recovery,spaces,sparse solution of linear},
pages = {1289--1306},
title = {Compressed sensing},
url = {http://ieeexplore.ieee.org/xpls/abs{\{}{\_}{\}}all.jsp?arnumber=1614066 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1614066},
volume = {52},
year = {2006}
}
@article{Murray2012,
abstract = {Background: During the past decade, renewed global and national efforts to combat malaria have led to ambitious goals. We aimed to provide an accurate assessment of the levels and time trends in malaria mortality to aid assessment of progress towards these goals and the focusing of future efforts. Methods: We systematically collected all available data for malaria mortality for the period 1980-2010, correcting for misclassification bias. We developed a range of predictive models, including ensemble models, to estimate malaria mortality with uncertainty by age, sex, country, and year. We used key predictors of malaria mortality such as Plasmodium falciparum parasite prevalence, first-line antimalarial drug resistance, and vector control. We used out-of-sample predictive validity to select the final model. Findings: Global malaria deaths increased from 995 000 (95 uncertainty interval 711 000-1 412 000) in 1980 to a peak of 1 817 000 (1 430 000-2 366 000) in 2004, decreasing to 1 238 000 (929 000-1 685 000) in 2010. In Africa, malaria deaths increased from 493 000 (290 000-747 000) in 1980 to 1 613 000 (1 243 000-2 145 000) in 2004, decreasing by about 30 to 1 133 000 (848 000-1 591 000) in 2010. Outside of Africa, malaria deaths have steadily decreased from 502 000 (322 000-833 000) in 1980 to 104 000 (45 000-191 000) in 2010. We estimated more deaths in individuals aged 5 years or older than has been estimated in previous studies: 435 000 (307 000-658 000) deaths in Africa and 89 000 (33 000-177 000) deaths outside of Africa in 2010. Interpretation: Our findings show that the malaria mortality burden is larger than previously estimated, especially in adults. There has been a rapid decrease in malaria mortality in Africa because of the scaling up of control activities supported by international donors. Donor support, however, needs to be increased if malaria elimination and eradication and broader health and development goals are to be met. Funding: The Bill {\&} Melinda Gates Foundation. {\textcopyright} 2012 Elsevier Ltd.},
author = {Murray, Christopher J L and Rosenfeld, Lisa C and Lim, Stephen S. and Andrews, Kathryn G and Foreman, Kyle J. and Haring, Diana and Fullman, Nancy and Naghavi, Mohsen and Lozano, Rafael and Lopez, Alan D.},
doi = {10.1016/S0140-6736(12)60034-8},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Murray et al. - 2012 - Global malaria mortality between 1980 and 2010 A systematic analysis.pdf:pdf},
isbn = {1474-547X (Electronic)$\backslash$n0140-6736 (Linking)},
issn = {01406736},
journal = {The Lancet},
month = {feb},
number = {9814},
pages = {413--431},
pmid = {22305225},
publisher = {Elsevier},
title = {Global malaria mortality between 1980 and 2010: A systematic analysis},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22305225},
volume = {379},
year = {2012}
}
@article{Yilmaz2006,
author = {Yilmaz, Alper and Javed, Omar and Shah, Mubarak},
doi = {10.1145/1177352.1177355},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yilmaz, Javed, Shah - 2006 - Object tracking.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
month = {dec},
number = {4},
pages = {13----es},
title = {Object tracking},
url = {http://portal.acm.org/citation.cfm?doid=1177352.1177355},
volume = {38},
year = {2006}
}
@inproceedings{Sakai2009,
abstract = {This paper proposes a fast spectral clustering method for large-scale data. In the present method, random projection and random sampling techniques are adopted for reducing the data dimensionality and cardinality. The computation time of the present method is quasi-linear with respect to the data cardinality. The clustering result can be updated with a small computational cost when data samples or random samples are appended or removed.},
author = {Sakai, Tomoya and Imiya, Atsushi},
booktitle = {International Workshop on Machine Learning and Data Mining in Pattern Recognition},
doi = {10.1007/978-3-642-03070-3_28},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sakai, Imiya - 2009 - Fast spectral clustering with random projection and sampling.pdf:pdf},
isbn = {3642030696},
issn = {03029743},
pages = {372--384},
title = {Fast spectral clustering with random projection and sampling},
url = {http://link.springer.com/10.1007/978-3-642-03070-3{\_}28},
year = {2009}
}
@article{Elfenbein2007,
author = {Elfenbein, Hillary Anger and Foo, Maw Der and White, Judith and Tan, Hwee Hoon and Aik, Voon Chuan},
doi = {10.1007/s10919-007-0033-7},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
keywords = {IM,emotion recognition {\{}{\'{a}}{\}} accuracy,emotional intelligence,workplace {\{}{\'{a}}{\}} performance {\{}{\'{a}}{\}},{\{}{\'{a}}{\}},{\{}{\'{a}}{\}} decoding {\{}{\'{a}}{\}} negotiation},
mendeley-tags = {IM},
month = {aug},
number = {4},
pages = {205--223},
title = {Reading your Counterpart: The Benefit of Emotion Recognition Accuracy for Effectiveness in Negotiation},
url = {http://www.springerlink.com/index/10.1007/s10919-007-0033-7},
volume = {31},
year = {2007}
}
@article{Reilly2012,
author = {Reilly, Barry and Rickman, Neil and Witt, Robert},
issn = {17409705},
journal = {Significance},
month = {jun},
number = {3},
pages = {17--21},
title = {Robbing banks: Crime does pay - but not very much},
url = {http://doi.wiley.com/10.1111/j.1740-9713.2012.00570.x},
volume = {9},
year = {2012}
}
@article{Wakin2006,
author = {Wakin, Michael and Laska, J and Duarte, M F},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wakin, Laska, Duarte - 2006 - Compressive imaging for video representation and coding.pdf:pdf},
journal = {Picture Coding {\ldots}},
title = {Compressive imaging for video representation and coding},
url = {http://inside.mines.edu/{~}mwakin/papers/pcs-camera.pdf},
year = {2006}
}
@book{Platte,
author = {Platte, RB B},
booktitle = {stat.asu.edu},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Platte - Unknown - An Introduction to Compressive Sensing.pdf:pdf},
title = {An Introduction to Compressive Sensing},
url = {http://stat.asu.edu/{\{}{~}{\}}platte/apm598/apm598{\{}{\_}{\}}cs{\{}{\_}{\}}intro.pdf http://stat.asu.edu/{~}platte/apm598/apm598{\_}cs{\_}intro.pdf}
}
@article{Ferryman2014,
abstract = {This paper presents the PETS2009 outdoor crowd image analysis surveillance dataset and the performance evaluation of people counting, detection and tracking results using the dataset submitted to five IEEE Performance Evaluation of Tracking and Surveillance (PETS) workshops. The evaluation was carried out using well established metrics developed in the Video Analysis and Content Extraction (VACE) programme and the CLassification of Events, Activities, and Relationships (CLEAR) consortium. The comparative evaluation highlights the detection and tracking performance of the authors' systems in areas such as precision, accuracy and robustness and provides a brief analysis of the metrics themselves to provide further insights into the performance of the authors' systems.},
author = {Ferryman, James and Ellis, Anna-Louise},
doi = {10.1016/j.patrec.2014.01.005},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferryman, Ellis - 2014 - Performance Evaluation of Crowd Image Analysis using the PETS2009 Dataset.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
month = {jan},
title = {Performance Evaluation of Crowd Image Analysis using the PETS2009 Dataset},
url = {http://www.sciencedirect.com/science/article/pii/S0167865514000191},
year = {2014}
}
@inproceedings{Johannessen2012,
author = {Johannessen, Kjetil and Drakeley, Brian Keith and Farhadiroushan, Mahmoud},
booktitle = {SPE Intelligent Energy International},
doi = {10.2118/149602-MS},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Johannessen, Drakeley, Farhadiroushan - 2012 - Distributed Acoustic Sensing - A New Way of Listening to Your WellReservoir.pdf:pdf},
isbn = {978-1-61399-191-6},
month = {apr},
publisher = {Society of Petroleum Engineers},
title = {Distributed Acoustic Sensing - A New Way of Listening to Your Well/Reservoir},
url = {http://www.onepetro.org/doi/10.2118/149602-MS},
year = {2012}
}
@article{Jacques2005,
author = {Jacques, JCS C S},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jacques - 2005 - Background subtraction and shadow detection in grayscale video sequences.pdf:pdf},
journal = {Computer Graphics and {\{}{\ldots}{\}}},
title = {Background subtraction and shadow detection in grayscale video sequences},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1599103 http://ieeexplore.ieee.org/xpls/abs{\{}{\_}{\}}all.jsp?arnumber=1599103},
year = {2005}
}
@inproceedings{Raina2007,
address = {New York, New York, USA},
author = {Raina, Rajat and Battle, Alexis and Lee, Honglak and Packer, Benjamin and Ng, Andrew Y.},
booktitle = {Proceedings of the 24th international conference on Machine learning - ICML '07},
doi = {10.1145/1273496.1273592},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raina et al. - 2007 - Self-taught learning.pdf:pdf},
isbn = {9781595937933},
month = {jun},
pages = {759--766},
publisher = {ACM Press},
title = {Self-taught learning},
url = {http://dl.acm.org/citation.cfm?id=1273496.1273592},
year = {2007}
}
@article{Tropp2007,
author = {Tropp, JA A and Gilbert, AC C},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tropp, Gilbert - 2007 - Signal recovery from random measurements via orthogonal matching pursuit.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
number = {12},
pages = {4655--4666},
title = {Signal recovery from random measurements via orthogonal matching pursuit},
url = {http://ieeexplore.ieee.org/xpls/abs{\{}{\_}{\}}all.jsp?arnumber=4385788 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4385788},
volume = {53},
year = {2007}
}
@article{Mohler2015,
abstract = {The concentration of police resources in stable crime hotspots has proven effective in reducing crime, but the extent to which police can disrupt dynamically changing crime hotspots is unknown. Police must be able to anticipate the future location of dynamic hotspots to disrupt them. Here we report results of two randomized controlled trials of near real-time Epidemic Type Aftershock Sequence (ETAS) crime forecasting, one trial within three divisions of the Los Angeles Police Department and the other trial within two divisions of the Kent Police Department (UK). We investigate the extent to which i) ETAS models of short term crime risk outperform existing best practice of hotspot maps produced by dedicated crime analysts, ii) police officers in the field can dynamically patrol predicted hotspots given limited resources, and iii) crime can be reduced by predictive policing algorithms under realistic law enforcement resource constraints. While previous hotspot policing experiments fix treatment and control hotspots throughout the experimental period, we use a novel experimental design to allow treatment and control hotspots to change dynamically over the course of the experiment. Our results show that ETAS models predict 1.4-2.2 times as much crime compared to a dedicated crime analyst using existing criminal intelligence and hotspot mapping practice. Police patrols using ETAS forecasts led to a average 7.4{\%} reduction in crime volume as a function of patrol time, whereas patrols based upon analyst predictions showed no significant effect. Dynamic police patrol in response to ETAS crime forecasts can disrupt opportunities for crime and lead to real crime reductions.$\backslash$nThe concentration of police resources in stable crime hotspots has proven effective in reducing crime, but the extent to which police can disrupt dynamically changing crime hotspots is unknown. Police must be able to anticipate the future location of dynamic hotspots to disrupt them. Here we report results of two randomized controlled trials of near real-time Epidemic Type Aftershock Sequence (ETAS) crime forecasting, one trial within three divisions of the Los Angeles Police Department and the other trial within two divisions of the Kent Police Department (UK). We investigate the extent to which i) ETAS models of short term crime risk outperform existing best practice of hotspot maps produced by dedicated crime analysts, ii) police officers in the field can dynamically patrol predicted hotspots given limited resources, and iii) crime can be reduced by predictive policing algorithms under realistic law enforcement resource constraints. While previous hotspot policing experiments fix treatment and control hotspots throughout the experimental period, we use a novel experimental design to allow treatment and control hotspots to change dynamically over the course of the experiment. Our results show that ETAS models predict 1.4-2.2 times as much crime compared to a dedicated crime analyst using existing criminal intelligence and hotspot mapping practice. Police patrols using ETAS forecasts led to a average 7.4{\%} reduction in crime volume as a function of patrol time, whereas patrols based upon analyst predictions showed no significant effect. Dynamic police patrol in response to ETAS crime forecasts can disrupt opportunities for crime and lead to real crime reductions.},
author = {Mohler, G. O. and Short, M. B. and Malinowski, Sean and Johnson, Mark and Tita, G. E. and Bertozzi, Andrea L. and Brantingham, P. J.},
doi = {10.1080/01621459.2015.1077710},
isbn = {0001412108},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {crime,experimental methods,machine learning,point processes,policing dosage},
month = {oct},
number = {February},
pages = {00--00},
publisher = {Taylor {\&} Francis},
title = {Randomized controlled field trials of predictive policing},
url = {http://www.tandfonline.com/doi/full/10.1080/01621459.2015.1077710 http://dx.doi.org/10.1080/01621459.2015.1077710},
volume = {1459},
year = {2015}
}
@article{Fowlkes2004,
abstract = {Spectral graph  theoretic methods have recently shown great promise for the problem of image segmentation. However, due to the computational demands of these approaches, applications to large problems such as spatiotemporal data and high resolution imagery have been slow to appear. The contribution of this paper is a method that substantially reduces the computational requirements of grouping algorithms based on spectral partitioning making it feasible to apply them to very large grouping problems. Our approach is based on a technique for the numerical solution of eigenfunction problems known as the Nystr{\{}{\"{o}}{\}}m method. This method allows one to extrapolate the complete grouping solution using only a small number of samples. In doing so, we leverage the fact that there are far fewer coherent groups in a scene than pixels.},
author = {Fowlkes, Charless and Belongie, Serge and Chung, Fan and Malik, Jitendra},
doi = {10.1109/TPAMI.2004.1262185},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Algorithms,Artificial Intelligence,Automated,Cluster Analysis,Computer Graphics,Computer-Assisted,Computer-Assisted: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Numerical Analysis,Pattern Recognition,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,Subtraction Technique,User-Computer Interface,Video Recording,Video Recording: methods},
month = {feb},
pages = {214--225},
title = {Spectral grouping using the {Nystr\"{o}m} method.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15376896},
year = {2004}
}
@article{Lloyd1982,
abstract = {It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likly to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quautization schemes for quanta, , are given numerically for Gaussian and for Laplacian distribution of signal amplitudes.},
author = {Lloyd, Stuart P},
doi = {10.1109/TIT.1982.1056489},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lloyd - 1982 - Least Squares Quantization in PCM.pdf:pdf},
isbn = {00189448 (ISSN)},
issn = {15579654},
journal = {IEEE Transactions on Information Theory},
number = {2},
pages = {129--137},
title = {Least Squares Quantization in {PCM}},
volume = {28},
year = {1982}
}
@misc{Sankaranarayanan2013,
author = {Sankaranarayanan, Aswin},
booktitle = {SIAM Journal on Imaging Sciences},
pages = {2109 -- 2133},
title = {Compressive Acquisition of Linear Dynamical Systems},
volume = {6},
year = {2013}
}
@unpublished{Franzese2001,
abstract = {Despite occasional constructive pedagogical treatises on the topic in the past (e.g., Friedrich 1982), a common methodology for employing and interpreting interaction terms in regression analysis continues to elude the field; and, partly as a consequence, their misinterpretation remains sadly rampant. This paper aims to redress these problems. We first document the widespread and expanding use of interaction terms in political science. We then elaborate and support our claim that, despite the increased use of interaction terms in regression analyses, many inherently interactive arguments are not being modeled as such. Finally, we note and review several inconsistencies and much confusion in the literature regarding the substantive interpretation of interaction terms and the statistical inferences from the coefficient and standard-error estimates surrounding them. After this review, we discuss three pedagogical themes. First, we offer a generic consideration of the process of writing empirical models that embody interactive hypotheses. Our second theme focuses more specifically on a set of statistical practices and rules of thumb when utilizing interaction models suggested by previous methodological treatments of the topic and frequently employed in current political science literature. We demonstrate that many of these can be misleading. Finally, we discuss the presentation of interaction effects. We show that, while the existing practice of reporting standard errors for individual coefficients remains useful, that practice is decidedly insufficient regarding coefficients on interactive terms. Assessment of interaction effects virtually requires graphical or tabular presentation of results, neither of which is currently commonly published. In this context, we strongly suggest the use of effect-line graphs or conditional-coefficient tables, complete with standard errors, hypothesis tests, and/or confidence intervals of those effects or conditional coefficients. We show how to construct these graphs and tables, giving detailed spreadsheet formulae for doing so in addition to the standard mathematical formulae for their elements.},
address = {Ann Arbor},
author = {Franzese, Robert Jr. (The University Of Michigan) and Kam, Cindy D (The University Of Michigan) and Jamal, Amaney A (The University Of Michigan)},
institution = {The University of Michigan},
keywords = {Interaction effects,Regression,Statistics},
mendeley-tags = {Interaction effects,Regression,Statistics},
number = {September},
pages = {1--13},
publisher = {Univ of Michigan Pr},
title = {Modeling and Interpreting Interactive Hypotheses in Regression Analysis},
url = {http://books.google.com/books?hl=en{\{}{\&}{\}}lr={\{}{\&}{\}}id=DO2joSlFdBMC{\{}{\&}{\}}oi=fnd{\{}{\&}{\}}pg=PA1{\{}{\&}{\}}dq=Modeling+and+Interreting+Interactive+Hypotheses+in+Regression+Analysis{\{}{\&}{\}}ots=k{\{}{\_}{\}}szg9guZB{\{}{\&}{\}}sig=KdNSnQPPD2xXtafwF3Hz-UQQNSU},
year = {2001}
}
@article{Jordan2004,
abstract = {Spectral clustering refers to a class of techniques which rely on the eigenstructure of a similarity matrix to partition points into disjoint clusters, with points in the same cluster having high similarity and points in different clusters having low similarity. In this paper, we derive a new cost function for spectral clustering based on a measure of error between a given partition and a solution of the spectral relaxation of a minimum normalized cut problem. Minimizing this cost function with respect to the partition leads to a new spectral clustering algorithm. Minimizing with respect to the similarity matrix leads to an algorithm for learning the similarity matrix. We develop a tractable approximation of our cost function that is based on the power method of computing eigenvectors.},
author = {Jordan, Frbmi},
doi = {10.1057/palgrave.ivs.9500158},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jordan - 2004 - Learning spectral clustering.pdf:pdf},
isbn = {0-262-20152-6},
issn = {14738716},
journal = {Advances in Neural Information Processing Systems 16 (NIPS)},
keywords = {Spectral Clustering},
mendeley-tags = {Spectral Clustering},
pages = {305--312},
title = {Learning spectral clustering},
url = {http://books.google.com/books?hl=en{\{}{\&}{\}}lr={\{}{\&}{\}}id=0F-9C7K8fQ8C{\{}{\&}{\}}oi=fnd{\{}{\&}{\}}pg=PA305{\{}{\&}{\}}dq=Learning+Spectral+Clustering{\{}{\&}{\}}ots=TGKsjZS705{\{}{\&}{\}}sig=mu4ZXa07k9MwtAa4V4sAKJ89ZhQ http://books.google.com/books?hl=en{\&}lr={\&}id=0F-9C7K8fQ8C{\&}oi=fnd{\&}pg=PA305{\&}dq=Learning+Spectr},
year = {2004}
}
@article{Baraniuk2011,
author = {Baraniuk, Richard and Davenport, M A},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baraniuk, Davenport - 2011 - An introduction to compressive sensing.pdf:pdf},
journal = {IEEE Signal Processing Mag.},
title = {An introduction to compressive sensing},
url = {http://www.cd3wd.com/data/133/An{\{}{\_}{\}}Introduction{\{}{\_}{\}}to{\{}{\_}{\}}Compressive{\{}{\_}{\}}Sensing{\{}{\_}{\}}electr{\{}{\_}{\}}physics{\{}{\_}{\}}maths{\{}{\_}{\}}cnx{\{}{\_}{\}}x11133{\{}{\_}{\}}.pdf http://www.cd3wd.com/data/133/An{\_}Introduction{\_}to{\_}Compressive{\_}Sensing{\_}electr{\_}physics{\_}maths{\_}cnx{\_}x11133{\_}.pdf},
year = {2011}
}
@article{Li2011,
author = {Li, Hanxi and Shen, Chunhua and Shi, Qinfeng},
doi = {10.1109/CVPR.2011.5995483},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Shen, Shi - 2011 - Real-time visual tracking using compressive sensing.pdf:pdf},
isbn = {978-1-4577-0394-2},
journal = {Cvpr 2011},
month = {jun},
pages = {1305--1312},
publisher = {Ieee},
title = {Real-time visual tracking using compressive sensing},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5995483},
year = {2011}
}
@incollection{Studenmund2005j,
address = {London},
author = {Studenmund, A H},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {13-15},
edition = {Fifth},
editor = {Clinton, Denise},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {434--519},
publisher = {Pearson Education, Inc.},
title = {13-15. Dummy Dependent Variable Techniques},
year = {2005}
}
@inproceedings{MacQueen1967,
author = {MacQueen, J.},
booktitle = {Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability},
issn = {0097-0433},
language = {EN},
pages = {281-297},
title = {Some methods for classification and analysis of multivariate observations},
url = {http://projecteuclid.org/euclid.bsmsp/1200512992},
year = {1967}
}
@article{Cramer2008,
author = {Cramer, R and Hooimeijer, M and Franzen, A},
journal = {Oil {\&} Gas Journal},
number = {38},
pages = {52--52},
publisher = {PennWell Publishing Co. Energy Group, Tulsa, USA},
title = {New software moves distributed-temperature sensing data},
volume = {106},
year = {2008}
}
@article{Wu2014,
author = {Wu, Sen and Feng, Xiaodong and Zhou, Wenjun},
doi = {10.1016/j.neucom.2013.12.027},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Spectral Clustering},
mendeley-tags = {Spectral Clustering},
month = {jul},
pages = {229--239},
title = {Spectral clustering of high-dimensional data exploiting sparse representation vectors},
url = {http://www.researchgate.net/publication/261291970{\_}Spectral{\_}clustering{\_}of{\_}high-dimensional{\_}data{\_}exploiting{\_}sparse{\_}representation{\_}vectors},
volume = {135},
year = {2014}
}
@inproceedings{Efros1999,
abstract = {A non-parametric method for texture synthesis is proposed. The texture synthesis process grows a new image outward from an initial seed, one pixel at a time. A Markov random field model is assumed, and the conditional distribution of a pixel given all its neighbors synthesized so far is estimated by querying the sample image and finding all similar neighborhoods. The degree of randomness is controlled by a single perceptually intuitive parameter. The method aims at preserving as much local structure as possible and produces good results for a wide variety of synthetic and real-world textures},
author = {Efros, A.A. and Leung, T.K.},
booktitle = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.1999.790383},
isbn = {0-7695-0164-8},
keywords = {Application software,Computer science,Computer vision,Filters,Histograms,Image sampling,Image texture analysis,Integrated circuit synthesis,Markov processes,Markov random field model,Pixel,Sampling methods,computer vision,conditional pixel distribution,image sampling,image texture,initial seed,local structure preservation,new image growth,nonparametric sampling,perceptually intuitive parameter,randomness,real-world textures,sample image querying,synthetic textures,texture synthesis},
pages = {1033--1038 vol.2},
publisher = {IEEE},
shorttitle = {Computer Vision, 1999. The Proceedings of the Seve},
title = {Texture synthesis by non-parametric sampling},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=790383},
volume = {2},
year = {1999}
}
@article{Guattery1998,
author = {Guattery, Stephen and Miller, Gary L.},
doi = {10.1137/S0895479896312262},
issn = {0895-4798},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {Spectral Clustering,graph eigenvalues and eigenvectors,graph partitioning,spectral partitioning},
mendeley-tags = {Spectral Clustering},
month = {jul},
number = {3},
pages = {701--719},
publisher = {Society for Industrial and Applied Mathematics},
title = {On the Quality of Spectral Separators},
url = {http://dl.acm.org/citation.cfm?id=294400.294413},
volume = {19},
year = {1998}
}
@book{Optimization2004,
author = {Optimization, Convex},
doi = {10.1016/B978-012428751-8/50019-7},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Optimization - 2004 - Convex Optimization.pdf:pdf},
isbn = {9780124287518},
pages = {803--818},
title = {Convex Optimization},
year = {2004}
}
@book{Bishop2006,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A frthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bishop, C.},
booktitle = {Zhurnal Eksperimental'noi i Teoreticheskoi Fiziki},
doi = {10.1117/1.2819119},
eprint = {arXiv:1011.1669v3},
isbn = {9780387310732},
issn = {1017-9909},
pages = {1--738},
pmid = {25246403},
publisher = {Springer},
title = {Pattern Recognition and Machine Learning},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:No+Title{\#}0},
year = {2006}
}
@article{Shinnou2008,
abstract = {Spectral clustering is a powerful clustering method for document data set. However, spectral clustering needs to solve an eigenvalue problem of the matrix converted from the similarity matrix corresponding to the data set. Therefore, it is not practical to use spectral clustering for a large data set. To overcome this problem, we propose the method to reduce the similarity matrix size. First, using k-means, we obtain a clustering result for the given data set. From each cluster, we pick up some data, which are near to the central of the cluster. We take these data as one data. We call these data set as " committee. " Data except for committees remain one data. For these data, we construct the similarity matrix. Definitely, the size of this similarity matrix is reduced so much that we can perform spectral clustering using the reduced similarity matrix},
author = {Shinnou, Hiroyuki and Sasaki, Minoru},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shinnou, Sasaki - 2008 - Spectral Clustering for a Large Data Set by Reducing the Similarity Matrix Size.pdf:pdf},
isbn = {2-9517408-4-0},
journal = {In Proceedings of the Sixth International Language Resources and Evaluation)},
pages = {201--204},
title = {Spectral Clustering for a Large Data Set by Reducing the Similarity Matrix Size},
year = {2008}
}
@article{Parks2008,
author = {Parks, Donovan H. and Fels, Sidney S.},
doi = {10.1109/AVSS.2008.19},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parks, Fels - 2008 - Evaluation of Background Subtraction Algorithms with Post-Processing.pdf:pdf},
isbn = {978-0-7695-3341-4},
journal = {2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance},
month = {sep},
pages = {192--199},
publisher = {Ieee},
title = {Evaluation of Background Subtraction Algorithms with Post-Processing},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4730412},
year = {2008}
}
@article{Mehranian2013,
author = {Mehranian, Abolfazl and Ay, Mohammad Reza and Rahmim, Arman and Zaidi, Habib},
doi = {10.1109/TNS.2013.2275919},
issn = {0018-9499},
journal = {IEEE Transactions on Nuclear Science},
keywords = {2D fan beam CT,3D cone beam CT,3D prior image constrained projection,3D projection completion,Computed tomography,Image reconstruction,Image segmentation,Implants,MAP,MAP completion,Metal artifact reduction,Metals,Three-dimensional displays,X-ray CT,X-ray CT MAR,X-ray imaging,biological tissues,clinical datasets,computerised tomography,convex programming,equality constrained convex optimization,gradient algorithm,gradient methods,image classification,image quality degradation,maximum a posteriori,maximum likelihood estimation,medical image processing,metallic implant,missing projection,prior image,prior potential function,prosthetics,residual projection,streaking artifact,tissue},
language = {English},
month = {oct},
number = {5},
pages = {3318--3332},
publisher = {IEEE},
title = {3D Prior Image Constrained Projection Completion for X-ray CT Metal Artifact Reduction},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6588999},
volume = {60},
year = {2013}
}
@misc{Dhanjal2011,
abstract = {Partitioning a graph into groups of vertices such that those within each group are more densely connected than vertices assigned to different groups, known as graph clustering, is often used to gain insight into the organization of large scale networks and for visualization purposes. Whereas a large number of dedicated techniques have been recently proposed for static graphs, the design of on-line graph clustering methods tailored for evolving networks is a challenging problem, and much less documented in the literature. Motivated by the broad variety of applications concerned, ranging from the study of biological networks to graphs of scientific references through to the exploration of communications networks such as the World Wide Web, it is the main purpose of this paper to introduce a novel, computationally efficient, approach to graph clustering in the evolutionary context. Namely, the method promoted in this article is an incremental eigenvalue solution for the spectral clustering method described by Ng. et al. (2001). Be- yond a precise description of its practical implementation and an evaluation of its complexity, its performance is illustrated through numerical experiments, based on datasets modelling the evolution of a HIV epidemic and the purchase history graph of an e-commerce website.},
author = {Dhanjal, Charanpal and Gaudel, R and Cl{\'{e}}men{\c{c}}on, S},
booktitle = {DISCML-3rd NIPS Workshop on {\ldots}},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dhanjal, Gaudel, Cl{\'{e}}men{\c{c}}on - 2011 - Incremental spectral clustering with the normalised laplacian.pdf:pdf},
keywords = {Spectral Clustering},
language = {en},
mendeley-tags = {Spectral Clustering},
month = {dec},
pages = {1--6},
title = {Incremental spectral clustering with the normalised laplacian},
url = {http://hal.inria.fr/hal-00745666/},
volume = {2011},
year = {2011}
}
@article{Sahay2007,
abstract = {Dynamic pricing, in which prices respond to supply and demand pressures in real time or near-real time, has long been used by airlines and hotels. Now dynamic pricing is making inroads in many different sectors including apparel, automobiles, consumer electronics, personal services, telecommunications and second-hand goods. These companies are making use of new findings on dynamic pricing and of increases in data-processing power to raise their average realized prices, thereby increasing revenues and profits. There are two mechanisms for dynamic pricing: posted prices that customers can see; and price- discovery mechanisms, in which customers determine prices through their own actions. These two mechanisms are employed in seven different forms: yield management (commonly used by airlines), demand-based pricing, three types of auctions, group buying and negotiations. The article describes eight situations for using the various forms of dynamic pricing. An important constraint in employing dynamic pricing is consumers' Latitude of Price Acceptance, which varies for different products and situations and which can be discovered through observation, surveys or analysis of demand elasticities. Customer participation in the pricing process decreases the chances of a consumer backlash. Customers also tend to embrace dynamic pricing in the following situations: where the price reflects intensity of demand for the product, there is communication between the seller and the consumer, and the price difference is explained by a difference in perceived value across channels through which the transaction occurred. The more the seller understands the buying cycles and habits of the customer, the more he is able to manage price margins to the rhythm of the customer's shopping, to segment customers and to develop price discrimination.},
author = {Sahay, Arvind},
doi = {1532-9194},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sahay - Unknown - How to Reap Higher Profits With Dynamic Pricing.pdf:pdf},
isbn = {1532-9194},
issn = {15329194},
journal = {MIT Sloan Management Review},
number = {4},
pages = {53--62},
title = {How to reap higher profits with dynamic pricing},
url = {{\textless}Go to ISI{\textgreater}://000248059400013},
volume = {48},
year = {2007}
}
@inproceedings{Huang2009,
author = {Huang, Ling and Yan, Donghui and Taft, Nina and Jordan, Michael I},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/rhian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2008 - Spectral clustering with perturbed data.pdf:pdf},
isbn = {9781605609492},
keywords = {Spectral Clustering},
mendeley-tags = {Spectral Clustering},
pages = {705--712},
title = {Spectral clustering with perturbed data},
url = {http://papers.nips.cc/paper/3480-spectral-clustering-with-perturbed-data},
year = {2008}
}
@incollection{Studenmund2005c,
address = {London},
author = {Studenmund, A H},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {4},
edition = {Fifth},
editor = {Clinton, Denise},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {4. The Classical Model},
year = {2005}
}
@article{Arlot2010,
abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplicity and its apparent universality. Many results exist on the model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
author = {Arlot, Sylvain and Celisse, Alain},
journal = {Statistics Surveys},
keywords = {cross validation,leave one out,model selection,phrases},
number = {0},
pages = {40--79},
publisher = {The author, under a Creative Commons Attribution License},
title = {A survey of cross-validation procedures for model selection},
url = {http://arxiv.org/abs/0907.4728},
volume = {4},
year = {2010}
}
@incollection{Studenmund2005a,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {2},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {34--62},
publisher = {Pearson Education, Inc.},
title = {2. Ordinary Least Squares.},
year = {2005}
}
@article{King1986,
abstract = {This article identifies a set of serious theoretical mistakes appearing with troublingly high frequency throughout the quantitative political science literature. These mistakes are all based on faulty statistical theory or on erroneous statistical analysis. Through algebraic and interpretive proofs, some of the most commonly made mistakes are explicated and illus- trated. The theoretical problem underlying each is highlighted, and suggested solutions are provided throughout. It is argued that closer attention to these problems and solutions will result in more reliable quantitative analyses and more useful theoretical contributions.},
author = {King, Gary (New York University)},
file = {::},
journal = {American Journal of Political Science},
month = {aug},
number = {3},
pages = {666 -- 687},
title = {How Not to Lie with Statistics: Avoiding Common Mistakes in Quantitative Political Science},
url = {http://www.jstor.org/stable/2111095?origin=crossref},
volume = {30},
year = {1986}
}
@incollection{Studenmund2005f,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {7},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {7. Specification: Choosing a Functional Form},
year = {2005}
}
@incollection{Studenmund2005d,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {5},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {5. Hypothesis Testing},
year = {2005}
}
@unpublished{Keele2008,
abstract = {Experiments have become an increasingly common tool for political science researchers over the last decade, particularly laboratory experiments performed on small convenience samples. The standard statistical paradigm used in political science is designed to connect samples to populations, while the inferential goal in an experiment is often about understand- ing whether an observed treatment effect occurred due to chance. In this paper, we outline an alternative derivation for statistical inference based on randomization of the treatment. While some standard tests approximate this form of inference, many do not and can produce incorrect inferences. These tests also have robust forms that are insensitive to the distribu- tion of the data. We outline common randomization tests, such as Wilcoxon rank tests and the Kruskal-Wallis test, and also develop a randomization test for two-way factorial designs as an alternative to the commonly used two-way ANOVA model. Finally, we reanalyze data from two political science experiments using randomization tests to illustrate the inferential errors that can be made when classical tests are used with data from the lab.},
author = {Keele, Luke (Ohio State University) and Mcconnaughy, Corrine (Ohio State University) and White, Ismail (Ohio State University)},
file = {::},
pages = {1--41},
title = {Statistical Inference For Experiments},
year = {2008}
}
@incollection{Studenmund2005e,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {6},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {6. Specification: Choosing the Independent Variables.},
year = {2005}
}
@book{Rumsey2009,
address = {Indianapolis},
author = {Rumsey, Deborah},
booktitle = {Director},
file = {::},
keywords = {Statistics},
mendeley-tags = {Statistics},
pages = {1--413},
publisher = {For Dummies},
title = {Statistics II for Dummies},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id={\_}UzkbN{\_}QRuUC{\&}oi=fnd{\&}pg=PA1{\&}dq=Statistics+II+for+Dummies{\&}ots=0CFwi7vheg{\&}sig=a1ee7gEns9jmxZ{\_}Mg5qfkDyZ6mM},
year = {2009}
}
@article{Cai2010,
author = {Cai, TT and Zhang, CH and Zhou, HH},
doi = {10.1214/09-AOS752},
file = {::},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {Covariance matrix,Frobenius norm,minimax lower bound,operator norm,optimal rate of convergence,tapering},
month = {aug},
number = {4},
pages = {2118--2144},
title = {Optimal rates of convergence for covariance matrix estimation},
url = {http://projecteuclid.org/euclid.aos/1278861244},
volume = {38},
year = {2010}
}
@article{Liu2005,
abstract = {This article reviews methodologies used for analyzing ordered categorical (ordinal) response variables. We begin by surveying models for data with a single ordinal response variable. We also survey recently proposed strategies for modeling ordinal response variables when the data have some type of clustering or when repeated measurement occurs at various occasions for each subject, such as in longitudinal studies. Primary models in that case include marginal models and cluster-specific (conditional) models for which effects apply conditionally at the cluster level. Re- lated discussion refers to multi-level and transitional models. The main empha- sis is on maximum likelihood inference, although we indicate certain models (e.g., marginal models,multi-level models) for which this can be computationally difficult. The Bayesian approach has also received considerable attention for categorical data in the past decade, and we survey recent Bayesian approaches to modeling ordinal response variables. Alternative, non-model-based, approaches are also available for certain types of inference.},
author = {Liu, Ivy and Agresti, A.},
file = {::},
journal = {Test},
keywords = {contingency tables,ordinal,statistics},
mendeley-tags = {contingency tables,ordinal,statistics},
number = {1},
pages = {1--73},
publisher = {Springer},
title = {The Analysis of Ordered Categorical Data: An Overview and a Survey of Recent Developments},
url = {http://www.springerlink.com/index/vj250ju52484xj03.pdf},
volume = {14},
year = {2005}
}
@incollection{Studenmund2005b,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {3},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {63--83},
publisher = {Pearson Education, Inc.},
title = {3. Learning to Use Regression Analysis.},
year = {2005}
}
@article{Elfenbein2007,
author = {Elfenbein, Hillary Anger and Foo, Maw Der and White, Judith and Tan, Hwee Hoon and Aik, Voon Chuan},
doi = {10.1007/s10919-007-0033-7},
file = {::},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
keywords = {IM,emotion recognition {\'{a}} accuracy,emotional intelligence,workplace {\'{a}} performance {\'{a}},{\'{a}},{\'{a}} decoding {\'{a}} negotiation},
mendeley-tags = {IM},
month = {aug},
number = {4},
pages = {205--223},
title = {Reading your Counterpart: The Benefit of Emotion Recognition Accuracy for Effectiveness in Negotiation},
url = {http://www.springerlink.com/index/10.1007/s10919-007-0033-7},
volume = {31},
year = {2007}
}
@article{Cook2008,
author = {Cook, Alex},
file = {::},
number = {August},
title = {Kaplan – Meier estimate of S ( t ) in R},
year = {2008}
}
@incollection{Studenmund2005i,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {10-12},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {345--433},
publisher = {Pearson Education, Inc.},
title = {10-12. Heteroskedasticity.},
year = {2005}
}
@incollection{Studenmund2005,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {1},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {1. The Basic Regression Model.},
year = {2005}
}
@incollection{Studenmund2005h,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {9},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {9. Serial Correlation},
year = {2005}
}
@article{Talavera2013,
author = {Talavera, Juan O},
file = {::},
journal = {Revista Medica del Instituto Mexicano del Seguro Social},
number = {Supl},
pages = {S10--S15},
title = {{I . Dise{\~{n}}os de investigaci{\'{o}}n}},
volume = {51},
year = {2013}
}
@incollection{Studenmund2005j,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {13-15},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {434--519},
publisher = {Pearson Education, Inc.},
title = {13-15. Dummy Dependent Variable Techniques},
year = {2005}
}
@incollection{Studenmund2005g,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {8},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {8. Multicollinearity},
year = {2005}
}
@article{King2000,
abstract = {Social scientists rarely take full advantage of the information available in their statistical results. As a consequence, they miss opportunities to present quantities that are of greatest substantive interest for their research and express the appropriate degree of certainty about these quantities. In this article, we offer an approach, built on the technique of statistical simulation, to extract the currently overlooked information from any statistical method and to interpret and present it in a reader-friendly manner. Using this technique requires some expertise, which we try to provide herein, but its application should make the results of quantitative articles more informative and transparent. To illustrate our recommendations, we replicate the results of several published works, showing in each case how the authors' own conclusions can be expressed more sharply and informatively, and, without changing any data or statistical assumptions, how our approach reveals important new information about the research questions at hand. We also offer very easy-to-use software that implements our suggestions.},
author = {King, Gary (Harvard University) and Tomz, Michael (Harvard University) and Wittenberg, Jason (Harvard University)},
file = {::},
journal = {American Journal of Political Science},
number = {2},
pages = {341--355},
title = {Making the Most of Statistical Analyses: Improving Interpretation and Presentation},
volume = {44},
year = {2000}
}
@article{Schwartz2011,
abstract = {Patterns of interaction in any social system are accompanied by counter-patterns of withdrawal, one highly institutionalized (but unexplored) mode of which is privacy. There exists a threshold beyond which social contact becomes irritating for all parties; therefore, some provision for removing oneself from interaction and observation must be built into every establishment. Such provisions subserve the action patterns for which they provide intermission. Privacy, which is bought and sold in social establishments, reflects and affirms status divisions, and permits "localized" deviation which is invisible to the group as a whole. Privacy thereby unsulates against dysfunctional knowledge. Rules governing entrance into and exit from privacy are most clearly articulated on the level of the establishment and are reflected in its physical structure and in proprieties concerning the uses of space, doors, windows, drawers, etc. The report ends with a discussion of identity and its relation to the freedoms of engagement and disengagement.},
author = {Schwartz, Barry},
file = {::},
journal = {The American Journal of Sociology},
keywords = {Privacy},
mendeley-tags = {Privacy},
number = {6},
pages = {741--752},
title = {The Social Psychology of Privacy},
url = {http://www.jstor.org/stable/2775779},
volume = {73},
year = {2011}
}
@article{Wickham2011b,
abstract = {The boxplot plot has been around for over 40 years. This paper summarises the improvements, exten-sions and variations since Tukey first introduced his " schematic plot " in 1970. We focus particularly on richer displays of density and extensions to 2d.},
author = {Wickham, Hadley and Stryjewski, Lisa},
file = {::},
title = {40 years of boxplots},
year = {2011}
}
@article{Braumoeller2004,
abstract = {When a statistical equation incorporates a multiplicative term in an attempt to model interaction effects, the statistical significance of the lower-order coefficients is largely useless for the typical purposes of hypothesis testing. This fact remains largely unappreciated in political science, however. This brief article explains this point, provides examples, and offers some suggestions for more meaningful interpretation},
author = {Braumoeller, Bear F.},
file = {::},
journal = {International Organization},
keywords = {Interaction effects,Multiplicative Models,Statistics},
mendeley-tags = {Interaction effects,Multiplicative Models,Statistics},
month = {oct},
number = {04},
pages = {807--820},
publisher = {Cambridge Univ Press},
title = {Hypothesis Testing and Multiplicative Interaction Terms},
url = {http://www.journals.cambridge.org/abstract{\_}S0020818304040251},
volume = {58},
year = {2004}
}
@article{Aguilar-Barojas2005,
abstract = {En la investigaci{\'{o}}n en salud, es muy dif{\'{i}}cil estudiar a toda la poblaci{\'{o}}n que presenta la variable de inter{\'{e}}s, por lo que es necesario realizar un muestreo que resulte representativo de la poblaci{\'{o}}n objetivo. El c{\'{a}}lculo de la muestra permite responder a la pregunta del investigador de ¿cu{\'{a}}ntos individuos se deben considerar para estudiar un par{\'{a}}metro con un grado de confianza determinado? o ¿cu{\'{a}}ntos individuos se deben estudiar para detectar en los resultados de los dos grupos, una diferencia que sea estad{\'{i}}sticamente significativa? El art{\'{i}}culo realiza las consideraciones previas sobre la profundidad del estudio y las variables. Presenta las f{\'{o}}rmulas para calcular muestras con variables cualitativas y cuantitativas para estudios descriptivos y explicativos. En estos {\'{u}}ltimos, cuando se utilizan las pruebas de contrastaci{\'{o}}n de hip{\'{o}}tesis m{\'{a}}s comunes, como son la Chi cuadrada, la t de student y el coeficiente de correlaci{\'{o}}n de Pearson.},
archivePrefix = {arXiv},
arxivId = {1405-2091},
author = {Aguilar-Barojas, S},
eprint = {1405-2091},
file = {::},
journal = {Salud en Tabasco},
keywords = {SRA,c{\'{a}}lculo de muestra,f{\'{o}}rmulas,investigaci{\'{o}}n en salud,muestra,representativa,s},
mendeley-tags = {SRA},
number = {1-2},
pages = {333--338},
title = {{F{\'{o}}rmulas para el c{\'{a}}lculo de la muestra en investigaciones de salud}},
url = {http://www.redalyc.org/articulo.oa?id=48711206},
volume = {11},
year = {2005}
}
@techreport{Deloitte2012,
author = {Deloitte},
file = {::},
institution = {Deloitte},
number = {November},
title = {Measuring the Economic Benefits of Mathematical Science Research in the UK},
year = {2012}
}
@book{Huff1954,
address = {New York},
author = {Huff, Darrell},
file = {::},
isbn = {0393052648},
keywords = {Statistics,Statistics as Topic},
pages = {1--141},
publisher = {W.W. Norton {\&} Company, Inc.},
title = {How to Lie with Statistics},
year = {1954}
}
@article{Bartels2013,
author = {Bartels, Christian},
file = {::},
month = {dec},
title = {Positioning Bayesian inference as a particular application of frequentist inference and vice versa},
url = {http://figshare.com/articles/Positioning{\_}Bayesian{\_}inference{\_}as{\_}a{\_}particular{\_}application{\_}of{\_}frequentist{\_}inference{\_}and{\_}vice{\_}versa/867707},
year = {2013}
}
@article{Reilly2012,
author = {Reilly, Barry and Rickman, Neil and Witt, Robert},
issn = {17409705},
journal = {Significance},
month = {jun},
number = {3},
pages = {17--21},
title = {Robbing banks: Crime does pay - but not very much},
url = {http://doi.wiley.com/10.1111/j.1740-9713.2012.00570.x},
volume = {9},
year = {2012}
}
@misc{Preacher2004,
abstract = {This web page calculates simple intercepts and simple slopes, the region of significance, and computes specific values to facilitate the plotting of significant three-way interactions in ordinary least squares (OLS) regression. The interaction can be between any combination of dichotomous and continuous variables. We assume that the user is sufficiently knowledgeable in the testing, probing, and interpretation of interactions in multiple regression (e.g., Aiken {\&} West, 1991; Bauer {\&} Curran, 2004; Cohen, Cohen, West {\&} Aiken, 2003). A more extensive treatment of interaction effects can be found here. We further assume that the user has read the descriptions provided in support of the web page for probing a two-way interaction.},
author = {Preacher, Kristopher J. (University Of North Carolina At Chapel Hill) and Curran, Patrick J. (University Of North Carolina At Chapel Hill) and Bauer, Daniel J. (University Of North Carolina At Chapel Hill)},
file = {::},
keywords = {3-Way Interactions,Interactions,Statistics},
mendeley-tags = {3-Way Interactions,Interactions,Statistics},
pages = {1--5},
title = {Simple Intercepts, Simple Slopes, and Regions of Significance in MLR 3-Way Interactions},
year = {2004}
}
@incollection{Studenmund2005k,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {16},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {16. Statistical Principles},
year = {2005}
}
@article{Bartels2014,
annote = {An algorithm is proposed to calculate confidence intervals and p-values for hypothesis testing that converge to exact values in the limit of investing a large amount of computation time. The frequentist hypothesis test procedure is generic, exact, efficient, conceptually simple, and fairly easy to implement. The procedure is generic in that no assumptions were made on the probability model or the test procedure. The procedure is exact in that independent of the model and the test, the procedure determines exact p-values in the limit of sufficiently large computational resources. The procedure is conceptually simple in that it uses only basic definitions of statistical concepts. With respect to computational efficiency, the proposed algorithm with the likelihood-ratio test is comparable to bootstrap with maximum likelihood estimation of parameters.},
author = {Bartels, Christian},
keywords = {confidence region,mcmc,p-value,statistics},
mendeley-tags = {confidence region,mcmc,p-value,statistics},
month = {jun},
title = {Efficient generic integration algorithm to determine confidence intervals and p-values for hypothesis testing},
url = {http://figshare.com/articles/Efficient{\_}generic{\_}integration{\_}algorithm{\_}to{\_}determine{\_}confidence{\_}intervals{\_}and{\_}p{\_}values{\_}for{\_}hypothesis{\_}testing/1054694},
year = {2014}
}
@unpublished{Franzese2001,
abstract = {Despite occasional constructive pedagogical treatises on the topic in the past (e.g., Friedrich 1982), a common methodology for employing and interpreting interaction terms in regression analysis continues to elude the field; and, partly as a consequence, their misinterpretation remains sadly rampant. This paper aims to redress these problems. We first document the widespread and expanding use of interaction terms in political science. We then elaborate and support our claim that, despite the increased use of interaction terms in regression analyses, many inherently interactive arguments are not being modeled as such. Finally, we note and review several inconsistencies and much confusion in the literature regarding the substantive interpretation of interaction terms and the statistical inferences from the coefficient and standard-error estimates surrounding them. After this review, we discuss three pedagogical themes. First, we offer a generic consideration of the process of writing empirical models that embody interactive hypotheses. Our second theme focuses more specifically on a set of statistical practices and rules of thumb when utilizing interaction models suggested by previous methodological treatments of the topic and frequently employed in current political science literature. We demonstrate that many of these can be misleading. Finally, we discuss the presentation of interaction effects. We show that, while the existing practice of reporting standard errors for individual coefficients remains useful, that practice is decidedly insufficient regarding coefficients on interactive terms. Assessment of interaction effects virtually requires graphical or tabular presentation of results, neither of which is currently commonly published. In this context, we strongly suggest the use of effect-line graphs or conditional-coefficient tables, complete with standard errors, hypothesis tests, and/or confidence intervals of those effects or conditional coefficients. We show how to construct these graphs and tables, giving detailed spreadsheet formulae for doing so in addition to the standard mathematical formulae for their elements.},
address = {Ann Arbor},
author = {Franzese, Robert Jr. (The University Of Michigan) and Kam, Cindy D. (The University Of Michigan) and Jamal, Amaney A. (The University Of Michigan)},
file = {::},
institution = {The University of Michigan},
keywords = {Interaction effects,Regression,Statistics},
mendeley-tags = {Interaction effects,Regression,Statistics},
number = {September},
pages = {1--13},
publisher = {Univ of Michigan Pr},
title = {Modeling and Interpreting Interactive Hypotheses in Regression Analysis},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=DO2joSlFdBMC{\&}oi=fnd{\&}pg=PA1{\&}dq=Modeling+and+Interreting+Interactive+Hypotheses+in+Regression+Analysis{\&}ots=k{\_}szg9guZB{\&}sig=KdNSnQPPD2xXtafwF3Hz-UQQNSU},
year = {2001}
}
@article{Arlot2010,
abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplicity and its apparent universality. Many results exist on the model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
author = {Arlot, Sylvain and Celisse, Alain},
file = {::},
journal = {Statistics Surveys},
keywords = {cross validation,leave one out,model selection,phrases},
number = {0},
pages = {40--79},
publisher = {The author, under a Creative Commons Attribution License},
title = {A survey of cross-validation procedures for model selection},
url = {http://arxiv.org/abs/0907.4728},
volume = {4},
year = {2010}
}
@article{Brambor2006,
abstract = {Multiplicative interaction models are common in the quantitative political science literature. This is so for good reason. Institutional arguments frequently imply that the relationship between political inputs and outcomes varies depending on the institutional context. Models of strategic interaction typically produce conditional hypotheses as well. Although con- ditional hypotheses are ubiquitous in political science and multiplicative interaction models have been found to capture their intuition quite well, a survey of the top three political science journals from 1998 to 2002 suggests that the execution of these models is often flawed and inferential errors are common. We believe that considerable progress in our understanding of the political world can occur if scholars follow the simple checklist of dos and don'ts for using multiplicative interaction models presented in this article. Only 10{\%} of the articles in our survey followed the checklist.},
author = {Brambor, Thomas (New York University) and Clark, William Roberts (University Of Michigan) and Golder, Matt (Florida State University)},
file = {::},
journal = {Political Analysis},
keywords = {Interaction effects,Multiplicative Models,STATA,Statistics},
mendeley-tags = {Interaction effects,Multiplicative Models,STATA,Statistics},
month = {may},
number = {1},
pages = {63--82},
title = {Understanding Interaction Models: Improving Empirical Analyses},
url = {http://pan.oxfordjournals.org/cgi/doi/10.1093/pan/mpi014},
volume = {14},
year = {2006}
}
@unpublished{Imai2009,
abstract = {In a highly influential paper, Baron and Kenny (1986) proposed a statistical procedure to con- duct a causal mediation analysis and identify possible causal mechanisms. This procedure has been widely used across many branches of the social and medical sciences and especially in psychology and epidemiology. However, one major limitation of this approach is that it is based on a set of linear regressions and cannot be easily extended to more complex situations that are frequently encoun- tered in applied research. In this paper, we propose an approach that generalizes the Baron-Kenny procedure. Our method can accommodate linear and nonlinear relationships, parametric and non- parametric models, continuous and discrete mediators, and various types of outcome variables. We also provide a formal statistical justification for the proposed generalization of the Baron-Kenny pro- cedure by placing causal mediation analysis within the widely-accepted counterfactual framework of causal inference. Finally, we develop a set of sensitivity analyses that allow applied researchers to quantify the robustness of their empirical conclusions. Such sensitivity analysis is important because as we showthe Baron-Kenny procedure and our generalization of it rest on a strong and untestable as- sumption even in randomized experiments. We illustrate the proposed methods by applying them to a randomized field experiment, the Job Search Intervention Study (JOBS II).We also offer easy-to-use software that implements all of our proposed methods.},
address = {Princeton},
author = {Imai, Kosuke (Princenton University) and Keele, Luke (Princenton University) and Tingley, Dustin (Princenton University)},
file = {::},
institution = {Princeton University},
keywords = {Mediation,Statistics,Structural Equation Modeling,causal inference,causal mechanisms,sensitivity analysis,sequential ignorability,struc- tural equation modeling,unobserved confounder},
mendeley-tags = {Mediation,Statistics,Structural Equation Modeling},
title = {A General Approach to Causal Mediation Analysis},
year = {2009}
}
@article{Szalkai2013,
abstract = {The original k-means clustering method works only if the exact vectors representing the data points are known. Therefore calculating the distances from the centroids needs vector operations, since the average of abstract data points is undefined. Existing algorithms can be extended for those cases when the sole input is the distance matrix, and the exact representing vectors are unknown. This extension may be named relational k-means after a notation for a similar algorithm invented for fuzzy clustering. A method is then proposed for generalizing k-means for scenarios when the data points have absolutely no connection with a Euclidean space.},
author = {Szalkai, Bal{\'{a}}zs},
keywords = {kmeans},
mendeley-tags = {kmeans},
month = {mar},
pages = {3},
title = {Generalizing k-means for an arbitrary distance matrix},
url = {http://arxiv.org/abs/1303.6001},
year = {2013}
}
@incollection{Studenmund2005c,
address = {London},
author = {Studenmund, A.H.},
booktitle = {Using Econometrics. A Practical Guide.},
chapter = {4},
edition = {Fifth},
editor = {Clinton, Denise},
file = {::},
keywords = {Econometrics,Regression},
mendeley-tags = {Econometrics,Regression},
pages = {616},
publisher = {Pearson Education, Inc.},
title = {4. The Classical Model},
year = {2005}
}
@book{Gujarati2004,
abstract = {This book covers some essential topics of econometrics. It covers from single regression to multiple regression. The second part of the book talks about how to detect a violation of assumptions (multicollinearity, heteroscedasticity, autocorrelation, model specification) made for running multiple regression and what the remedies are. The third part deals with three topics, including (a) regression on dummy variables, (b) regression on dummy dependent variables, (c) autoregressive and distributed lag models. The last part deals with simultaneous-equation model.},
author = {Gujarati, Damodar N. (West Point Military Academy)},
edition = {Forth},
file = {::},
isbn = {9780071276252},
keywords = {Econometrics,Statistics},
mendeley-tags = {Econometrics,Statistics},
pages = {1--1003},
publisher = {The McGraw−Hill Companies},
title = {Basic Econometrics},
year = {2004}
}
